{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the results of the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "from pathlib import Path \n",
    "from fastcore.xtras import load_pickle\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from gptchem.settings import TWO_COL_GOLDEN_RATIO_HEIGHT_INCH, TWO_COL_WIDTH_INCH\n",
    "from gptchem.data import get_photoswitch_data\n",
    "from gptchem.formatter import ClassificationFormatter\n",
    "from gptchem.evaluator import evaluate_classification\n",
    "from gptchem.baselines.photoswitch import train_test_photoswitch_baseline\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "\n",
    "plt.style.use(['science', 'nature'])\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_photoswitch_data()\n",
    "formatter = ClassificationFormatter(\n",
    "        representation_column=\"SMILES\",\n",
    "        label_column=\"E isomer pi-pi* wavelength in nm\",\n",
    "        property_name=\"transition wavelength\",\n",
    "        num_classes=2,\n",
    "        qcut=True,\n",
    "    )\n",
    "\n",
    "formatted = formatter(data)\n",
    "\n",
    "dummy_results = []\n",
    "for i in range(10): \n",
    "    for train_size in [10, 50, 200]:\n",
    "        train, test = train_test_split(formatted, train_size=train_size, test_size=100, stratify=formatted[\"label\"], random_state=i + 10)\n",
    "        dummy = DummyClassifier(strategy=\"uniform\")\n",
    "        dummy.fit(train[\"representation\"], train[\"label\"])\n",
    "        predictions = dummy.predict(test[\"representation\"])\n",
    "        metrics = evaluate_classification(test[\"label\"], predictions)\n",
    "        dummy_results.append({\n",
    "            \"train_size\": train_size,\n",
    "            **metrics,\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_results = pd.DataFrame(dummy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>acc_macro</th>\n",
       "      <th>racc</th>\n",
       "      <th>kappa</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>frac_valid</th>\n",
       "      <th>all_y_true</th>\n",
       "      <th>all_y_pred</th>\n",
       "      <th>valid_indices</th>\n",
       "      <th>might_have_rounded_floats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>((0, {0: 26, 1: 24}), (1, {0: 26, 1: 24}))</td>\n",
       "      <td>0.499800</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>((0, {0: 21, 1: 29}), (1, {0: 26, 1: 24}))</td>\n",
       "      <td>0.449505</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, ...</td>\n",
       "      <td>[1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.12</td>\n",
       "      <td>((0, {0: 28, 1: 22}), (1, {0: 22, 1: 28}))</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>((0, {0: 28, 1: 22}), (1, {0: 23, 1: 27}))</td>\n",
       "      <td>0.549955</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>((0, {0: 24, 1: 26}), (1, {0: 24, 1: 26}))</td>\n",
       "      <td>0.499800</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.14</td>\n",
       "      <td>((0, {0: 27, 1: 23}), (1, {0: 20, 1: 30}))</td>\n",
       "      <td>0.569613</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, ...</td>\n",
       "      <td>[1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.14</td>\n",
       "      <td>((0, {0: 26, 1: 24}), (1, {0: 19, 1: 31}))</td>\n",
       "      <td>0.568922</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>((0, {0: 27, 1: 23}), (1, {0: 27, 1: 23}))</td>\n",
       "      <td>0.499199</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>[0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>((0, {0: 24, 1: 26}), (1, {0: 28, 1: 22}))</td>\n",
       "      <td>0.459784</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.02</td>\n",
       "      <td>((0, {0: 24, 1: 26}), (1, {0: 23, 1: 27}))</td>\n",
       "      <td>0.509559</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>[1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.08</td>\n",
       "      <td>((0, {0: 26, 1: 24}), (1, {0: 22, 1: 28}))</td>\n",
       "      <td>0.539816</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, ...</td>\n",
       "      <td>[0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>200</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.04</td>\n",
       "      <td>((0, {0: 29, 1: 21}), (1, {0: 27, 1: 23}))</td>\n",
       "      <td>0.518266</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>((0, {0: 29, 1: 21}), (1, {0: 32, 1: 18}))</td>\n",
       "      <td>0.463508</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, ...</td>\n",
       "      <td>[1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>((0, {0: 24, 1: 26}), (1, {0: 29, 1: 21}))</td>\n",
       "      <td>0.449505</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>200</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>((0, {0: 27, 1: 23}), (1, {0: 27, 1: 23}))</td>\n",
       "      <td>0.499199</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, ...</td>\n",
       "      <td>[0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>((0, {0: 26, 1: 24}), (1, {0: 26, 1: 24}))</td>\n",
       "      <td>0.499800</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>50</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>((0, {0: 21, 1: 29}), (1, {0: 28, 1: 22}))</td>\n",
       "      <td>0.429943</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>200</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>((0, {0: 27, 1: 23}), (1, {0: 22, 1: 28}))</td>\n",
       "      <td>0.549955</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>((0, {0: 26, 1: 24}), (1, {0: 33, 1: 17}))</td>\n",
       "      <td>0.425345</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>((0, {0: 22, 1: 28}), (1, {0: 22, 1: 28}))</td>\n",
       "      <td>0.498193</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>200</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.04</td>\n",
       "      <td>((0, {0: 26, 1: 24}), (1, {0: 24, 1: 26}))</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.04</td>\n",
       "      <td>((0, {0: 28, 1: 22}), (1, {0: 26, 1: 24}))</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, ...</td>\n",
       "      <td>[0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>50</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.16</td>\n",
       "      <td>((0, {0: 27, 1: 23}), (1, {0: 19, 1: 31}))</td>\n",
       "      <td>0.579327</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>200</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.02</td>\n",
       "      <td>((0, {0: 23, 1: 27}), (1, {0: 22, 1: 28}))</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "      <td>[1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>((0, {0: 15, 1: 35}), (1, {0: 27, 1: 23}))</td>\n",
       "      <td>0.376006</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, ...</td>\n",
       "      <td>[1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>50</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.08</td>\n",
       "      <td>((0, {0: 21, 1: 29}), (1, {0: 17, 1: 33}))</td>\n",
       "      <td>0.533279</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>[1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>200</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>((0, {0: 22, 1: 28}), (1, {0: 26, 1: 24}))</td>\n",
       "      <td>0.459784</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, ...</td>\n",
       "      <td>[1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>((0, {0: 20, 1: 30}), (1, {0: 22, 1: 28}))</td>\n",
       "      <td>0.476651</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>50</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>((0, {0: 19, 1: 31}), (1, {0: 22, 1: 28}))</td>\n",
       "      <td>0.465672</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>[1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>200</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.06</td>\n",
       "      <td>((0, {0: 28, 1: 22}), (1, {0: 25, 1: 25}))</td>\n",
       "      <td>0.529577</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_size  accuracy  acc_macro  racc  kappa  \\\n",
       "0           10      0.50       0.50   0.5   0.00   \n",
       "1           50      0.45       0.45   0.5  -0.10   \n",
       "2          200      0.56       0.56   0.5   0.12   \n",
       "3           10      0.55       0.55   0.5   0.10   \n",
       "4           50      0.50       0.50   0.5   0.00   \n",
       "5          200      0.57       0.57   0.5   0.14   \n",
       "6           10      0.57       0.57   0.5   0.14   \n",
       "7           50      0.50       0.50   0.5   0.00   \n",
       "8          200      0.46       0.46   0.5  -0.08   \n",
       "9           10      0.51       0.51   0.5   0.02   \n",
       "10          50      0.54       0.54   0.5   0.08   \n",
       "11         200      0.52       0.52   0.5   0.04   \n",
       "12          10      0.47       0.47   0.5  -0.06   \n",
       "13          50      0.45       0.45   0.5  -0.10   \n",
       "14         200      0.50       0.50   0.5   0.00   \n",
       "15          10      0.50       0.50   0.5   0.00   \n",
       "16          50      0.43       0.43   0.5  -0.14   \n",
       "17         200      0.55       0.55   0.5   0.10   \n",
       "18          10      0.43       0.43   0.5  -0.14   \n",
       "19          50      0.50       0.50   0.5   0.00   \n",
       "20         200      0.52       0.52   0.5   0.04   \n",
       "21          10      0.52       0.52   0.5   0.04   \n",
       "22          50      0.58       0.58   0.5   0.16   \n",
       "23         200      0.51       0.51   0.5   0.02   \n",
       "24          10      0.38       0.38   0.5  -0.24   \n",
       "25          50      0.54       0.54   0.5   0.08   \n",
       "26         200      0.46       0.46   0.5  -0.08   \n",
       "27          10      0.48       0.48   0.5  -0.04   \n",
       "28          50      0.47       0.47   0.5  -0.06   \n",
       "29         200      0.53       0.53   0.5   0.06   \n",
       "\n",
       "                              confusion_matrix  f1_macro  f1_micro  \\\n",
       "0   ((0, {0: 26, 1: 24}), (1, {0: 26, 1: 24}))  0.499800      0.50   \n",
       "1   ((0, {0: 21, 1: 29}), (1, {0: 26, 1: 24}))  0.449505      0.45   \n",
       "2   ((0, {0: 28, 1: 22}), (1, {0: 22, 1: 28}))  0.560000      0.56   \n",
       "3   ((0, {0: 28, 1: 22}), (1, {0: 23, 1: 27}))  0.549955      0.55   \n",
       "4   ((0, {0: 24, 1: 26}), (1, {0: 24, 1: 26}))  0.499800      0.50   \n",
       "5   ((0, {0: 27, 1: 23}), (1, {0: 20, 1: 30}))  0.569613      0.57   \n",
       "6   ((0, {0: 26, 1: 24}), (1, {0: 19, 1: 31}))  0.568922      0.57   \n",
       "7   ((0, {0: 27, 1: 23}), (1, {0: 27, 1: 23}))  0.499199      0.50   \n",
       "8   ((0, {0: 24, 1: 26}), (1, {0: 28, 1: 22}))  0.459784      0.46   \n",
       "9   ((0, {0: 24, 1: 26}), (1, {0: 23, 1: 27}))  0.509559      0.51   \n",
       "10  ((0, {0: 26, 1: 24}), (1, {0: 22, 1: 28}))  0.539816      0.54   \n",
       "11  ((0, {0: 29, 1: 21}), (1, {0: 27, 1: 23}))  0.518266      0.52   \n",
       "12  ((0, {0: 29, 1: 21}), (1, {0: 32, 1: 18}))  0.463508      0.47   \n",
       "13  ((0, {0: 24, 1: 26}), (1, {0: 29, 1: 21}))  0.449505      0.45   \n",
       "14  ((0, {0: 27, 1: 23}), (1, {0: 27, 1: 23}))  0.499199      0.50   \n",
       "15  ((0, {0: 26, 1: 24}), (1, {0: 26, 1: 24}))  0.499800      0.50   \n",
       "16  ((0, {0: 21, 1: 29}), (1, {0: 28, 1: 22}))  0.429943      0.43   \n",
       "17  ((0, {0: 27, 1: 23}), (1, {0: 22, 1: 28}))  0.549955      0.55   \n",
       "18  ((0, {0: 26, 1: 24}), (1, {0: 33, 1: 17}))  0.425345      0.43   \n",
       "19  ((0, {0: 22, 1: 28}), (1, {0: 22, 1: 28}))  0.498193      0.50   \n",
       "20  ((0, {0: 26, 1: 24}), (1, {0: 24, 1: 26}))  0.520000      0.52   \n",
       "21  ((0, {0: 28, 1: 22}), (1, {0: 26, 1: 24}))  0.519231      0.52   \n",
       "22  ((0, {0: 27, 1: 23}), (1, {0: 19, 1: 31}))  0.579327      0.58   \n",
       "23  ((0, {0: 23, 1: 27}), (1, {0: 22, 1: 28}))  0.508772      0.51   \n",
       "24  ((0, {0: 15, 1: 35}), (1, {0: 27, 1: 23}))  0.376006      0.38   \n",
       "25  ((0, {0: 21, 1: 29}), (1, {0: 17, 1: 33}))  0.533279      0.54   \n",
       "26  ((0, {0: 22, 1: 28}), (1, {0: 26, 1: 24}))  0.459784      0.46   \n",
       "27  ((0, {0: 20, 1: 30}), (1, {0: 22, 1: 28}))  0.476651      0.48   \n",
       "28  ((0, {0: 19, 1: 31}), (1, {0: 22, 1: 28}))  0.465672      0.47   \n",
       "29  ((0, {0: 28, 1: 22}), (1, {0: 25, 1: 25}))  0.529577      0.53   \n",
       "\n",
       "    frac_valid                                         all_y_true  \\\n",
       "0          1.0  [0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, ...   \n",
       "1          1.0  [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, ...   \n",
       "2          1.0  [1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, ...   \n",
       "3          1.0  [1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, ...   \n",
       "4          1.0  [0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, ...   \n",
       "5          1.0  [1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, ...   \n",
       "6          1.0  [0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, ...   \n",
       "7          1.0  [0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, ...   \n",
       "8          1.0  [1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, ...   \n",
       "9          1.0  [0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, ...   \n",
       "10         1.0  [0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, ...   \n",
       "11         1.0  [1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, ...   \n",
       "12         1.0  [1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, ...   \n",
       "13         1.0  [0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, ...   \n",
       "14         1.0  [0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, ...   \n",
       "15         1.0  [1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, ...   \n",
       "16         1.0  [1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, ...   \n",
       "17         1.0  [0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...   \n",
       "18         1.0  [0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, ...   \n",
       "19         1.0  [1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, ...   \n",
       "20         1.0  [0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, ...   \n",
       "21         1.0  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, ...   \n",
       "22         1.0  [1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, ...   \n",
       "23         1.0  [1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, ...   \n",
       "24         1.0  [0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, ...   \n",
       "25         1.0  [1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, ...   \n",
       "26         1.0  [0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, ...   \n",
       "27         1.0  [1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "28         1.0  [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, ...   \n",
       "29         1.0  [0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                           all_y_pred  \\\n",
       "0   [0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, ...   \n",
       "1   [1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, ...   \n",
       "2   [0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, ...   \n",
       "3   [1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, ...   \n",
       "4   [0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, ...   \n",
       "5   [1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, ...   \n",
       "6   [1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, ...   \n",
       "7   [0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, ...   \n",
       "8   [0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, ...   \n",
       "9   [1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, ...   \n",
       "10  [0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, ...   \n",
       "11  [0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, ...   \n",
       "12  [1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, ...   \n",
       "13  [0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, ...   \n",
       "14  [0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, ...   \n",
       "15  [1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, ...   \n",
       "16  [0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, ...   \n",
       "17  [0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, ...   \n",
       "18  [0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, ...   \n",
       "19  [1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, ...   \n",
       "20  [1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, ...   \n",
       "21  [0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, ...   \n",
       "22  [1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, ...   \n",
       "23  [1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, ...   \n",
       "24  [1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, ...   \n",
       "25  [1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, ...   \n",
       "26  [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, ...   \n",
       "27  [1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, ...   \n",
       "28  [1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, ...   \n",
       "29  [1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, ...   \n",
       "\n",
       "                                        valid_indices  \\\n",
       "0   [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "1   [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "2   [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "3   [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "4   [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "5   [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "6   [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "7   [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "8   [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "9   [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "10  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "11  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "12  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "13  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "14  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "15  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "16  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "17  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "18  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "19  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "20  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "21  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "22  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "23  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "24  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "25  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "26  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "27  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "28  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "29  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "\n",
       "    might_have_rounded_floats  \n",
       "0                       False  \n",
       "1                       False  \n",
       "2                       False  \n",
       "3                       False  \n",
       "4                       False  \n",
       "5                       False  \n",
       "6                       False  \n",
       "7                       False  \n",
       "8                       False  \n",
       "9                       False  \n",
       "10                      False  \n",
       "11                      False  \n",
       "12                      False  \n",
       "13                      False  \n",
       "14                      False  \n",
       "15                      False  \n",
       "16                      False  \n",
       "17                      False  \n",
       "18                      False  \n",
       "19                      False  \n",
       "20                      False  \n",
       "21                      False  \n",
       "22                      False  \n",
       "23                      False  \n",
       "24                      False  \n",
       "25                      False  \n",
       "26                      False  \n",
       "27                      False  \n",
       "28                      False  \n",
       "29                      False  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤═════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │   value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪═════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ 0.47702 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 3.62097 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │ 0.25495 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧═════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │  0.81221 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 29.3874  │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.04251 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ -0.9064  │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 32.402   │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.02384 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ -1.16546 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 33.0884  │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.0276  │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ -0.79575 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │  4.84634 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.38351 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ -1.09079 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 29.4913  │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.03262 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │  1.09508 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 60.1489  │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.0059  │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ -0.94155 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 44.1039  │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.02543 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤═════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │   value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪═════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ 0.81193 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 7.61499 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │ 0       │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧═════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤═════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │   value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪═════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ 0.12013 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 7.82695 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │ 0.38949 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧═════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ -0.04397 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 50.1568  │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.03299 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ -0.00288 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 44.8467  │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.04599 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤═════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │   value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪═════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ 0.24386 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 3.71232 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │ 0.28631 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧═════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤═════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │   value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪═════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ 0.10554 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 2.51235 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │ 0.5998  │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧═════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ -0.93336 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 39.6608  │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.0658  │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ -0.61522 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 36.7257  │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.04219 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤═════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │   value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪═════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ 0.07402 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 3.01051 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │ 0.49778 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧═════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤═════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │   value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪═════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ 0.90568 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 7.29544 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │ 0.39371 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧═════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │  0.24262 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 37.3377  │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.00928 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │  0.64317 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 55.1318  │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.01495 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤═════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │   value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪═════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ 1.13673 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 8.90032 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │ 0.31658 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧═════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ -1.05336 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 39.2268  │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.00196 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │  0.64271 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 35.2242  │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.04776 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ -2.06849 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 41.0821  │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.04324 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤═════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │   value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪═════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ 0.15817 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 4.25599 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │ 0.36674 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧═════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │  0.831   │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 21.8851  │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.05456 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ -0.66814 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 45.9918  │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.022   │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ -2.20267 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 35.9396  │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.01237 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤═════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │   value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪═════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │      -0 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │       0 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │       1 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧═════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤═════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │   value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪═════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ 0.57019 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 6.52304 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │ 0.25984 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧═════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │  0.07814 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 37.8713  │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.00602 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ -3.4248  │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 44.9672  │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.03653 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤═════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │   value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪═════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ 0.20858 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 3.54627 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │ 0.17932 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧═════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ -0.03441 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 37.0554  │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.00241 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ -0.99622 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 33.5377  │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.02625 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ -1.1815  │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 42.9171  │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.02972 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤═════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │   value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪═════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ 2e-05   │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 0       │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │ 0.99983 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧═════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │  0.20399 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 10.1086  │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.34238 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │  0.1366  │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 44.6927  │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.06472 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛\n",
      "╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕\n",
      "│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │\n",
      "╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡\n",
      "│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ -0.84329 │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 39.6299  │\n",
      "├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤\n",
      "│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.04493 │\n",
      "╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛\n"
     ]
    }
   ],
   "source": [
    "gpr_baselines = []\n",
    "\n",
    "for i in range(10):\n",
    "    for train_size in [10, 50, 100, 200]:\n",
    "        res = train_test_photoswitch_baseline(\n",
    "            data,\n",
    "            train_size=train_size,\n",
    "            test_size=100,\n",
    "            formatter=formatter,\n",
    "        )\n",
    "        res['train_size'] = train_size\n",
    "        gpr_baselines.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpr_res = pd.DataFrame(gpr_baselines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpr_baseline = gpr_res[['train_size', 'accuracy', 'f1_micro', 'f1_macro', 'kappa']].groupby('train_size').agg(('mean', 'std'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_out = glob(\"out/**/*.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_out = [load_pickle(p) for p in all_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_res = []\n",
    "\n",
    "for out in all_out: \n",
    "    res = {\n",
    "        'base_model': out['base_model'],\n",
    "        'train_size': out['train_size'],\n",
    "        'test_size': out['test_size'],\n",
    "        'n_epochs': out['n_epochs'],\n",
    "        'learning_rate_multiplier': out['learning_rate_multiplier'],\n",
    "        'frac_valid': out['frac_valid'],\n",
    "        'accuracy': out['accuracy'],\n",
    "        'f1_macro': out['f1_macro'],\n",
    "        'f1_micro': out['f1_micro'],\n",
    "        'kappa': out['kappa'],\n",
    "    }\n",
    "\n",
    "    extracted_res.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_res = pd.DataFrame(extracted_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = extracted_res.groupby(['base_model', 'train_size', 'n_epochs', 'learning_rate_multiplier']).agg(['mean', 'std']).sort_values(('f1_macro', 'mean'), ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_size</th>\n",
       "      <th colspan=\"2\" halign=\"left\">frac_valid</th>\n",
       "      <th colspan=\"2\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1_macro</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1_micro</th>\n",
       "      <th colspan=\"2\" halign=\"left\">kappa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model</th>\n",
       "      <th>train_size</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>learning_rate_multiplier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">davinci</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">50</th>\n",
       "      <th>8</th>\n",
       "      <th>0.20</th>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.68</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0.20</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.007071</td>\n",
       "      <td>0.824581</td>\n",
       "      <td>0.006479</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.007071</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.014142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>curie</th>\n",
       "      <th>10</th>\n",
       "      <th>8</th>\n",
       "      <th>0.02</th>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.809064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.62</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>davinci</th>\n",
       "      <th>50</th>\n",
       "      <th>4</th>\n",
       "      <th>0.20</th>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.807673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.62</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">curie</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">10</th>\n",
       "      <th>4</th>\n",
       "      <th>0.10</th>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.799920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.60</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0.02</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0.05</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.02</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>babbage</th>\n",
       "      <th>10</th>\n",
       "      <th>2</th>\n",
       "      <th>0.02</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <th>10</th>\n",
       "      <th>1</th>\n",
       "      <th>0.02</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        test_size       \\\n",
       "                                                             mean  std   \n",
       "base_model train_size n_epochs learning_rate_multiplier                  \n",
       "davinci    50         8        0.20                         100.0  NaN   \n",
       "                      2        0.20                         100.0  0.0   \n",
       "curie      10         8        0.02                         100.0  NaN   \n",
       "davinci    50         4        0.20                         100.0  NaN   \n",
       "curie      10         4        0.10                         100.0  NaN   \n",
       "...                                                           ...  ...   \n",
       "                      2        0.02                         100.0  0.0   \n",
       "                      1        0.05                         100.0  0.0   \n",
       "                               0.02                         100.0  0.0   \n",
       "babbage    10         2        0.02                         100.0  0.0   \n",
       "ada        10         1        0.02                         100.0  0.0   \n",
       "\n",
       "                                                        frac_valid       \\\n",
       "                                                              mean  std   \n",
       "base_model train_size n_epochs learning_rate_multiplier                   \n",
       "davinci    50         8        0.20                            1.0  NaN   \n",
       "                      2        0.20                            1.0  0.0   \n",
       "curie      10         8        0.02                            1.0  NaN   \n",
       "davinci    50         4        0.20                            1.0  NaN   \n",
       "curie      10         4        0.10                            1.0  NaN   \n",
       "...                                                            ...  ...   \n",
       "                      2        0.02                            0.0  0.0   \n",
       "                      1        0.05                            0.0  0.0   \n",
       "                               0.02                            0.0  0.0   \n",
       "babbage    10         2        0.02                            0.0  0.0   \n",
       "ada        10         1        0.02                            0.0  0.0   \n",
       "\n",
       "                                                        accuracy            \\\n",
       "                                                            mean       std   \n",
       "base_model train_size n_epochs learning_rate_multiplier                      \n",
       "davinci    50         8        0.20                        0.840       NaN   \n",
       "                      2        0.20                        0.825  0.007071   \n",
       "curie      10         8        0.02                        0.810       NaN   \n",
       "davinci    50         4        0.20                        0.810       NaN   \n",
       "curie      10         4        0.10                        0.800       NaN   \n",
       "...                                                          ...       ...   \n",
       "                      2        0.02                        0.000  0.000000   \n",
       "                      1        0.05                        0.000  0.000000   \n",
       "                               0.02                        0.000  0.000000   \n",
       "babbage    10         2        0.02                        0.000  0.000000   \n",
       "ada        10         1        0.02                        0.000  0.000000   \n",
       "\n",
       "                                                         f1_macro            \\\n",
       "                                                             mean       std   \n",
       "base_model train_size n_epochs learning_rate_multiplier                       \n",
       "davinci    50         8        0.20                      0.838384       NaN   \n",
       "                      2        0.20                      0.824581  0.006479   \n",
       "curie      10         8        0.02                      0.809064       NaN   \n",
       "davinci    50         4        0.20                      0.807673       NaN   \n",
       "curie      10         4        0.10                      0.799920       NaN   \n",
       "...                                                           ...       ...   \n",
       "                      2        0.02                      0.000000  0.000000   \n",
       "                      1        0.05                      0.000000  0.000000   \n",
       "                               0.02                      0.000000  0.000000   \n",
       "babbage    10         2        0.02                      0.000000  0.000000   \n",
       "ada        10         1        0.02                      0.000000  0.000000   \n",
       "\n",
       "                                                        f1_micro            \\\n",
       "                                                            mean       std   \n",
       "base_model train_size n_epochs learning_rate_multiplier                      \n",
       "davinci    50         8        0.20                        0.840       NaN   \n",
       "                      2        0.20                        0.825  0.007071   \n",
       "curie      10         8        0.02                        0.810       NaN   \n",
       "davinci    50         4        0.20                        0.810       NaN   \n",
       "curie      10         4        0.10                        0.800       NaN   \n",
       "...                                                          ...       ...   \n",
       "                      2        0.02                        0.000  0.000000   \n",
       "                      1        0.05                        0.000  0.000000   \n",
       "                               0.02                        0.000  0.000000   \n",
       "babbage    10         2        0.02                        0.000  0.000000   \n",
       "ada        10         1        0.02                        0.000  0.000000   \n",
       "\n",
       "                                                        kappa            \n",
       "                                                         mean       std  \n",
       "base_model train_size n_epochs learning_rate_multiplier                  \n",
       "davinci    50         8        0.20                      0.68       NaN  \n",
       "                      2        0.20                      0.65  0.014142  \n",
       "curie      10         8        0.02                      0.62       NaN  \n",
       "davinci    50         4        0.20                      0.62       NaN  \n",
       "curie      10         4        0.10                      0.60       NaN  \n",
       "...                                                       ...       ...  \n",
       "                      2        0.02                      0.00  0.000000  \n",
       "                      1        0.05                      0.00  0.000000  \n",
       "                               0.02                      0.00  0.000000  \n",
       "babbage    10         2        0.02                      0.00  0.000000  \n",
       "ada        10         1        0.02                      0.00  0.000000  \n",
       "\n",
       "[82 rows x 12 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_size</th>\n",
       "      <th colspan=\"2\" halign=\"left\">frac_valid</th>\n",
       "      <th colspan=\"2\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1_macro</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1_micro</th>\n",
       "      <th colspan=\"2\" halign=\"left\">kappa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>learning_rate_multiplier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">curie</th>\n",
       "      <th>8</th>\n",
       "      <th>0.02</th>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.809064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.62</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>0.10</th>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.799920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.60</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.05</th>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.719888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.46</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">babbage</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">8</th>\n",
       "      <th>0.02</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.120208</td>\n",
       "      <td>0.709220</td>\n",
       "      <td>0.141202</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.120208</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.240416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.120208</td>\n",
       "      <td>0.708524</td>\n",
       "      <td>0.140218</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.120208</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.240416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">curie</th>\n",
       "      <th>2</th>\n",
       "      <th>0.02</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0.05</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.02</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>babbage</th>\n",
       "      <th>2</th>\n",
       "      <th>0.02</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <th>1</th>\n",
       "      <th>0.02</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             test_size      frac_valid       \\\n",
       "                                                  mean  std       mean  std   \n",
       "base_model n_epochs learning_rate_multiplier                                  \n",
       "curie      8        0.02                         100.0  NaN        1.0  NaN   \n",
       "           4        0.10                         100.0  NaN        1.0  NaN   \n",
       "                    0.05                         100.0  NaN        1.0  NaN   \n",
       "babbage    8        0.02                         100.0  0.0        1.0  0.0   \n",
       "                    0.10                         100.0  0.0        1.0  0.0   \n",
       "...                                                ...  ...        ...  ...   \n",
       "curie      2        0.02                         100.0  0.0        0.0  0.0   \n",
       "           1        0.05                         100.0  0.0        0.0  0.0   \n",
       "                    0.02                         100.0  0.0        0.0  0.0   \n",
       "babbage    2        0.02                         100.0  0.0        0.0  0.0   \n",
       "ada        1        0.02                         100.0  0.0        0.0  0.0   \n",
       "\n",
       "                                             accuracy            f1_macro  \\\n",
       "                                                 mean       std      mean   \n",
       "base_model n_epochs learning_rate_multiplier                                \n",
       "curie      8        0.02                        0.810       NaN  0.809064   \n",
       "           4        0.10                        0.800       NaN  0.799920   \n",
       "                    0.05                        0.730       NaN  0.719888   \n",
       "babbage    8        0.02                        0.725  0.120208  0.709220   \n",
       "                    0.10                        0.725  0.120208  0.708524   \n",
       "...                                               ...       ...       ...   \n",
       "curie      2        0.02                        0.000  0.000000  0.000000   \n",
       "           1        0.05                        0.000  0.000000  0.000000   \n",
       "                    0.02                        0.000  0.000000  0.000000   \n",
       "babbage    2        0.02                        0.000  0.000000  0.000000   \n",
       "ada        1        0.02                        0.000  0.000000  0.000000   \n",
       "\n",
       "                                                       f1_micro            \\\n",
       "                                                   std     mean       std   \n",
       "base_model n_epochs learning_rate_multiplier                                \n",
       "curie      8        0.02                           NaN    0.810       NaN   \n",
       "           4        0.10                           NaN    0.800       NaN   \n",
       "                    0.05                           NaN    0.730       NaN   \n",
       "babbage    8        0.02                      0.141202    0.725  0.120208   \n",
       "                    0.10                      0.140218    0.725  0.120208   \n",
       "...                                                ...      ...       ...   \n",
       "curie      2        0.02                      0.000000    0.000  0.000000   \n",
       "           1        0.05                      0.000000    0.000  0.000000   \n",
       "                    0.02                      0.000000    0.000  0.000000   \n",
       "babbage    2        0.02                      0.000000    0.000  0.000000   \n",
       "ada        1        0.02                      0.000000    0.000  0.000000   \n",
       "\n",
       "                                             kappa            \n",
       "                                              mean       std  \n",
       "base_model n_epochs learning_rate_multiplier                  \n",
       "curie      8        0.02                      0.62       NaN  \n",
       "           4        0.10                      0.60       NaN  \n",
       "                    0.05                      0.46       NaN  \n",
       "babbage    8        0.02                      0.45  0.240416  \n",
       "                    0.10                      0.45  0.240416  \n",
       "...                                            ...       ...  \n",
       "curie      2        0.02                      0.00  0.000000  \n",
       "           1        0.05                      0.00  0.000000  \n",
       "                    0.02                      0.00  0.000000  \n",
       "babbage    2        0.02                      0.00  0.000000  \n",
       "ada        1        0.02                      0.00  0.000000  \n",
       "\n",
       "[64 rows x 12 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.loc[:, 10, : ,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsQAAAGzCAYAAAAomgFnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAADJwUlEQVR4nOydeXxU5b3/32cmy2SfJOwBIRNAERBJQKngnojawm0lgVJtvS0a6u+2tb1tRW/vre1tK43VVlt7r8GlrVRRgtqrra0mYlVwgyAaFlkS1rCTlWwkM8/vj5OZzJrMJJkt+b5fr0lmznOe53zPnE+++Z7nPM/30ZRSCkEQBEEQBEEYphjCbYAgCIIgCIIghBMJiAVBEARBEIRhjQTEgiAIgiAIwrBGAmJh2KJpmserqKgo3GYNKVatWkVNTY3LNvfPg8FArttgXfNt27ZRUFAQkuOtWbOGnJwcNE0jJyeHVatWuZS76zonJ4eKigoACgoKvGo/JyenX7asXLmSvLw8ANLT0wd2Yk4E+2/R3+s1kPbz8vJIT08nPT2dlStX0tDQAOh/A5qmeVw3gJycHJdrkZOTw7Zt22hoaEDTNK/H6ut69mbLhg0b2LBhw+CduCBEK0oQhimAqq+vD7cZQ5b6+npVWFjosd1sNrt8Li8vVxaLRZnNZnXPPff0ud0b7m0GwkDqulNdXR3045WUlKjc3FxVWVmplFKqsrJS5ebmquLiYsc+7touKSnxetze/gbsdcxms9fraMe5XbtNg8FgXhdvVFZWqvz8/KC1bzabVVlZmVKq52/Bfo2qq6sVoCwWi0sdb9stFouqrKxU9fX1yte/7L58WW+2KKWC+j0IQrQgPcSCECA1NTUUFBRQVFREeno6BQUFbNiwwdGzY++JA3jwwQcdvTIFBQWOXhl7D196erqjl2jbtm0UFRWxatUqR++YvV17r44v7Lakp6ezZs0ax3Zvx/HVrrfjV1RUeD2+r+M5s3r1apc6q1atIj093fEdOLdVXl5OfX09FRUVjt4qX9u9nXtDQ4Ojty8Qm93rOlNRUcGDDz5IQUGBx/Xz9v01NDQ4rr1dI6tWrSInJ4eCggJqamo8jufP9+hMQ0MDq1ev5s033yQ3NxeA3NxcysrKqKur81mvuLiYhoYGj+/eF9u2baO0tJQDBw5QX19PQ0MDDz74oMd+9u/Efj7XX399r+cPvq+PM87fk3tP7oYNG1i5cmW/jmH/e8zJyeGFF17o9Tvwdo17O6YzNTU1NDQ0UFhYCIDZbOaJJ57AbDY79jGbzZjNZpf6GzZscNQZLPyxxe7DBGFYE+6IXBDCBf3sIbb34th7w8xms6OHpbS01PG+urpamc1mxzHy8/NVaWmpqq6uVhaLRdXX16v6+nplsVhUeXm5qqysVGazWZWWlrrUt/c65ufnq5KSEg97ysrKVG5urlJKOdqw1/d2HF/tuh+/vr7eZb/CwkJ1zz33+DyeO87nbm/P/t052+7cO2X/7Gu7L+w29MdmX/aXlZW5XOfi4mJVXFzc6/fnfO0BR6+cva7z8fz9Ht1t8qc3z13bgfYQV1ZWOmxXSql77rnHZy+9t+/S1/n7uj69tevek1tWVua4DoEcw/7Ewf73kJub6/O79HWNe7uu7lgsFpWfn6/Ky8t9tl9SUuLyN52bm6vKysoGvYe4N1uU0p/G9PYUQBCGA9JDLAxr0tPTXcbd+Tu+1WKxOHro8vPzHT2q+fn5jjYsFgsHDhzAbDY7euYaGhooLS1l5cqVjh6isrIyLBaLo+3i4mJA7y0qLi52lJWUlHjt1bK3v23bNnJzc6mvrwfweZy+2rUff/369eTn5zv2u++++9iwYYPP4zljP1/3HjHn8wS998p5m8Vioa6uzuf2vhiIzd7Iz893XOeSkhLWr1/v93UBHL1yBQUFHvb3xyb376WiosLRw5yens62bdscZfZtmqZRWlpKWVmZX+cMeq9zYWEhFRUVFBUVUVFRwX333ed3fTvu5+/r+gwEf49RVlbm8vfQ2/n0dY17u652qquryc3NZdWqVWia5rU3ubCw0NGuvQff/W/EX9x9mXOvel+2zJkzx+XJliAMRyQgFoY19fX1KKUcL+d/Rr09wnYO9ACf/8TswwSuv/56xz/OhoYGl/q5ubmO+s7tVFdXk5mZ6XIMbwF7fn4+hYWFXH/99S6P3n0dp7d23Y9fUVFBXl4eeXl53HnnnVgsFp/Hc6auro6MjAyv30lf+Hqs78/j/oHY7A3n78MewPp7XeyBtL2uO/2xyWKxsHXrVpc26uvrqa+v99CgfbtSiurqavLz8322ax9aY5/AZWfOnDmO4QL+fmd2vJ2/r+sTCM4BaCDHqKur87jJ8kVv17iv6+pMSUkJlZWVjutjn3zo3K49EF6/fj2FhYV9tukLd19WXl7uty3ON+2CMFyRgFgQ3GhoaKCoqIjS0tIBtbNhwwa2bt1KfX09lZWVjoDE/Z9PRUWFSxBiJycnh7Nnzzo+u/cOOtt73333UV9fz5tvvunI7ODrOP62m5OTQ3FxMZWVlY5XaWmpz+M542+Prvt+dlt8be+LgdjsDed97NfI3++vL/pjU35+Ptu2bfPYz97T3F+Ki4uprq529CRWVFRQUVGB2WwmPz+/117wQPB1fQKhurq6X8fIyMhw+d56+64Heo3XrFnj0kNrNpsdOvTWS7x+/XrKyspYtmyZ38cYTFsG0jMtCEMFCYgFwQ378IL+9nDacf4n2tDQ4Hg0vGzZMsc/pIaGBlauXOk1eCwsLGTNmjWOoHbVqlVe/2GuWbOGO++8E8DleL6O42+7+fn5rFmzxvFPs6ioiJKSEp/HcycjI6PPXqf8/HwqKiocxygtLaWoqMjndl/Yj9Mfm3uz0flmpbS0lMLCQr+/v75s7et79Bbgms1m7rnnHsdkM8AxWa+/PYu+bFy1apXDHvdhPf3F1/XxZYOdrVu3ukxo7M8x7De59nZWr17ts42BXuOlS5d6TARds2aN42bPGfvfaU1NjUvv82Dhjy1bt24NyrEFIZqQgFgQgoR9LG5OTo4je8Pq1asxm82sWrWKvLw8srOzKSws9Po422KxUFJS4sgfarFYuOeee7wep6GhgfT0dLKzs7nvvvvIzc11jBl0P46/7VosFp544glHlgXQg0Jfx3OnsLDQ5fG+N+w3HwUFBeTk5JCbm0txcbHP7b7Iz88nLy+vXzbb6/pq1z7spaamhieeeMLv768vW/v6HvPy8rwGxSUlJY5MIOnp6Q5tlZSUDFpQbNeK/Rzr6up44oknBtyur+vjDfvxc3NzWbp0KdnZ2eTl5Tm++0CPkZ+fz8qVK8nOziYnJ4eVK1f6DAIHeo3NZrOjZ9o+lrusrMxjGAPoQzBqamp6HdLijPOYcbsuvW23Z3Txx5Zt27YFpXdaEKIJTSmlwm2EIEQiBQUFXv+BCf7R0NDAnXfeGdBkrkhiw4YNlJeXD3jozECO7zy+XBCChfg6QZAeYkEQgoTZbGbu3LlBWZluOOA+CUwQgsGGDRu8rpgnCMMN6SEWBEHwQkNDgwSlgiAIwwQJiAVBEARBEIRhjQyZEARBEARBEIY1EhALgiAIgiAIwxoJiAVBEARBEIRhjQTEgiAIgiAIwrBGAmJBEARBEARhWCMBsSAIgiAIgjCskYBYEARBEARBGNZIQCwIgiAIgiAMayQgFgRBEARBEIY1EhALgiAIgiAIwxoJiEPEtm3bKCgocHwuKiryur2vuv7sLwiDiWhXiHaGioZramrCdmwhPAwV7UYDEhCHiYqKCgByc3MpLS31u16g+/trS05ODunp6axatSqgfTZs2ODYXlBQQENDw6DaJkQeQ0W7eXl5aJrmePmqLww9ok3DdvLy8gb12EL0EW3ajaYYQQLiAKipqaGgoICioiLHxbVf7JycHCoqKjzuwjZs2MDKlStd2ikqKqKhocEhDrvAKyoqePDBBykoKPApHuf97XXsYrMfZ9u2bRQVFbFq1SrH3WRvFBUVUV5eTn19PRUVFWzYsMGvfWpqarjzzjsd2y0WC3feeaff36cQOkS7nvvU1NSglHK8SkpK/PsyhbAwnDW8atUq0tPTIzqYEHwzXLUbdTGCEvymurpaAaqyslIppZTZbFb5+flKKaVKS0tVfn6+qqysdGxTSqmysjJVXFzssd1sNiullMv2srIyl/aLi4s96jq/r6+vV2azWVVXVyullCosLFT33HOPqqysVGazWZWWlvZ5TmVlZR72On/ubZ/y8nJ1zz33OLZXVlYqi8XS5zGF0CPadf1sP74QPQxXDduPZT9/IfoYrtqNthghJmyReARRU1NDRUUFDQ0NWCwWAMrLy70+XrBYLOTm5gKQn5/vuKPLz88flB6m/Px8R/slJSVkZ2d73CXaWb9+Pfn5+Q6b77vvPoqKili2bBkAxcXFfR6vpqbGUR/086urq/Nrn/z8fPLz8x3bV61aRWFhoZ9nKgwGot3+adc+FjMnJ4e6ujrmzJlDWVkZZrPZ/xMWBgXRcO8aBjCbzaLNCES027t2oy1GkIAY/cLaBVpdXQ3A6tWraWho8HBC7p+dBeENb86tN5zbM5vNvT4iq66upqKiwmVcmb2+czsbNmzwOr6nvLzca7v+PJZz3sfefmFhoTx2DjGiXVf81a7ZbOa+++7jnnvuoaGhwfGI0Fe7QvAQDbsiwyKiB9GuK76OGS0xggTE6Hcxa9ascbmb8ibo/mD/I/EX51nE27Zt63XfnJwciouLXQRWU1PjIcrCwkKfd2UWi4UtW7a41Hf/Q+1tn5UrV1JTU0N5eXmff+DC4CPa7Z92LRYL99xzD6D/81i5ciXXX3997ycoBAXRcO8aFiIX0W7f2o2mGEEm1XVTXl7u6NqvqKhw6eYPlK1btzqE5W2CBPi+k7IPrgcoLS3t9fGC/Y/R/odQVFTk9e7LefC+88t+d1tRUeFoo7S01CWti/043vapqKhg69atUSH0oYxoN3DtrlmzxqV3pLS0dEDfmzAwRMO+NSxENqJd39qNthhBAuJuGhoaHONvysvL+52vLzc3l6VLl5KdnU1eXh4lJSVeU+Xk5+f73G6fUVxTU8MTTzzh81gWi4UnnnjCMbMU8Dp2qbCwkOrqao+XxWLBbDZTVlZGQUEBOTk55ObmOsYP5eXlsW3bNp/7lJeXs23bNpfUVTk5Of363oT+I9oNXLvFxcUsW7bMMcu6rq6uV3uF4CIa9q1hIbIR7frWbrTFCJpSSoXbiEgjLy+PN998M+STGDZs2OBzQL4g+INoV4h2RMNCtCLajW6kh9gLgzUGSBBCjWhXiHZEw0K0ItqNbqSH2AvhEnVDQwN1dXVRMdZGiExEu0K0IxoWohXRbnQjAbEgCIIgCIIwrJEhE4IgCIIgCMKwRgJiQRAEQRAEYVgjAbEgCIIgCIIwrJGAWBAEQRAEQRjWROzSzdOnT/eawLm2tpasrKyA2orUOpFqV3/qhNuu6upqdu7cGVBbwcCXbiH6vtPBrBOpdvWnzmAfI9K1O1yuQzjrRKpdvdUR3YauTqTaFao6IdOtilAWLVoU0Pb+tBXuOpFqV3/qhNuu/rQVDHqzI9q+08GsE6l29afOYB8j0rU7XK5DOOtEql291RHdhq5OpNoVqjqh0u2wGDKxfPnyiKzTn2P0h0g9l1Cdf7QSqbrtb51QHCNStT7ciNTrEKk+N1K1PtyI1OsQqboNVZ2Q6TbgsDtERPpdabgYiudvs9l6Xlb9ZbVa9VdXz6v+VKO69Yu3q8YzzR5tRMr3Eg09geFgqJ67T906abfuZINP3SoVOd+N+FzvDMXzd9etT597Onp9bqTYFy6G6vkP1Of29r1E7BhiXwznO1xlUyxbtgyb1aZ/dltTxfHRabtyK/S2DIujHacyhes293Zc33pp21HPS9v9WAtm5/v72LjuQ6YlzeOx7z7LzSuu4tJrpgXcTjgZrtpVqnfd6ttc3ygvhe7VXNrxobe+23Hb5t6O87Z+6/YD0W0UopRy0a4/uoX++VyvevM4SC8+tzff3c+1t6Ld5w5X3UIAsYLTh4B061QhMJ/rRctBiRX653OHTECsbAqbzYZm0NA0/RXJ2J2tsnW/lEIpnN7by3v2ba5vYfbkeZw4dIaU9KRwn0KvKKWwWW3dL4XVasNmszm2Wbu639uc97Pp+3XXsXXXaWlqY/Nftrm0/drT72CZOYHUzOQwnmVg+NKutcvq0KxmiCLdKpze+9CwLfp0q7o1afWiT1eNOmnb+dVdp6WpjU0vV7q0PZR0a7PZ9H9eGtHhc9106cvn2rp9MhBd2rV5+lmHH/XQrQ2rU5mLb7YqWptb2fyXj3vajkLt+owVuv83aQYNjSHgc21DIFbw4mddfKvNhq3LTcM2T223NrcPyOdGbEBcW1vL4sWLWb58uV93el2dXbS3nnfZ5nDSdodt0NDAJfDoCaA99/eX/gQJgVK1aS//XP+hflelwdwbZjDp4izfTq3L/ll5cYY9waYjMHVqw6VNX4Gq1YbV5mVb9+/+nGMgKJui/mQjf3vjVdatW0dtbW1Qj+cvgeoWoLW53WNbb7p02e6h48Cce3+ChEDY8d4+3nr+AyfdzmTS9KxenZrXf9guGu92lA6Ne9enQ6NdPWVWm82zTbe/kWBi121qZjLr1q2Lau2eb++ks6PLZVvPjR3QHWzo0u15j7uG+3Ej2J8gIVA+fXcPb5d95NDunIIZrtr1cjPky8/2lPnWu1eNdnn3sz36Vo79+tsT7C9Dxecqm/LwuT79q7f4weDpjwPBl8+12WyDEivs2LyXt1740KfP9dbp5NJJ5eSXPTWqsFqt3v2s+zZvfwsucUPP9mASiG41Fey/on6yePFiXnnlFb/37+zo9AiIB0rPHaT9D0b/g/DWe9sflE3R1tJBa3MbrU1ttDS109rURmtz9++mNlqa22hpaKOjrX/nphk0DEYDBqMBo9P7npe+zei23WjoKXPZ7lbX8dng1l6M8zbnupqPtgwYDN5taW1u408/ednlEY5m0PjWb2513PUFqpdg0R87mutbBtUGr0EJemee6xOJ/v/pd3Z06np11263Ztua2mlubKG10TPY9xdDjF2HPrRo12iMUdeim958atte5rG/875e6jr/LcW46t5d27pu23nmp73rFqJXu+2tHR4B8UDxdiPo0O0AggQ7NquNtnPtTr62jZamNlq7P7c06+9bmlrpbO/fuWkGzdO32fVkcN1mNBp9+FknfcYYfPpZ7/p2as/gY7sXX+5cp625jT8OUZ9rf3ozmPj0uYMVKyjF+bZOXavNvrV7rqGN9nP99LkaPmIBb3GDd5/n7q+9xQHe4gaHP3Xzs+7H8fy76qlj7Pa5f+rD5/aml4jtIY4ElE3p41q6b2Ca61toON2MeWSKz8cQSinOt3c6RNvSHSS0OoKH9m6nqwvb3bnHJcSSlJJAYmoCiSkmMsaa6Tzfya73qz2OlX/r5xhnGeXTqRmNhoh/HOSM/a4b9B6l7jfEJ8SSf+sVVDz3Psqm0AwaN3/jqqh5dBdqHI7X6cbbH+1au6y6br1o16HZbh27B0IGo4HEVJNDuyOy0jGPSmXP1gMex7n+K/PcdOvq1Azduo30R/B2HHY6a1eD+IQ40W2AOHxuN/763PbW844bstbmdh/abaOtpcNtkCOYkuId2k0xJzH6ghF0dnSyY/M+j2Pl33YF4ywjPfyss++NFt2C+NzBwt3n+qNbgK7zXW5BrrN222hx6hyzdrn2pMbEGvU4ITWBpBQTYyeNpLPTymcfeokVvjKPsTmjfXY62TsIogVnn+us27gB+lwJiP3EPlDb/hjiwjnZmEek9AjYSbhdnVaXusYYA0ndwk1MTWDMxBEkpJj0bSkmXdDd72PiPC9Jc30Luz+odr3r0TQmXDi2z/FBvhxej8/ufuSu4dio9Wx2qeNoz9G2W53uje7/D3zb4P8/jstuvISL5lqoP9lI+ug0ccwBsOO9fWx8/gNHIDD50gtISU/q7mHo0a3HExYNEpLtQa6JtBEpjLOM8qrd+MQ4j+vZXN/C3soDHrq94KJx/um22wZPDfZ8cBxS03CTtCMwdWnPZx239vq0wT/tim77j7vPnZqXTVpmsktPrj2IcH/sGhsf0x0o6NpNH5Xa7YNNJDp1OCSmmDDGGD2O3Vzfws739nn63KljetWu15uj7s/OPtdZg47d/fCR/vjc3m0Qnxts3HU77TIL5lGpHk8hWpvaON/e6VLXYNBIsPvVlAQyx6QxYeqYnvih2/cmpJiIM8V69bl7PvISKwzA5/YZK3ip49IeRI3PlYDYD47sOc6bz33Qs0HBni0HSEg2kWxOJDHVRMboVMZPHu3icJNSdWF7E25v2McrGQz67xHj0ll4+wJef2az467npn+9kjGTRuj799PhRRupmcnilAPgfHsnn7zzGe+/ut1l+/7th0nLTCY5PYnEVBMjxpldg4Ru7SYkmzAYA+s1MBgMDu1mjjFzw9cW8MZaN91OHDEghxdtiG4DQynF/u2HPXzu3q0HSEwzkZKWRGJqAiPHp5OUOs7D3yammIiNjw3omA5/qzn73Ct5/ZlNvn3uENctiHYD5dSRsx663f1hDfGJcSSnJZKYYnI8hejRa492TYnxAT3VdR6DbzBoZI41S6xA/3UrAbEPrF1Wqj85zKeb9nJs/ymv+9z0jSsZP2VMQO32BLoGDPaB+k7Br69B+nn5M5gye5LcrQt9cuZYPVXv7uWzrQfodOuBsHP9rZ8LSLvuN2ma5qRjp0DCnTkFM5iaK7oV+qaj7TyfbTnAjk17OXu8wes+N94euM+136RpBs3hcx06Nvh+VJyXP50psyeKdoVeUUpRu/8kVe/uZf/2Q173+fwdV/c/VtB6dOrqeyVWGGwkIHaj6ew5dmzex84P9tPW3E7W5NFcUzSXtzds8XgMkTYixaWuc++Yu3DtZQNB7tYFX3R1Wtm//RBVm/ZyvOY0iakJXHr1RWRPz6LsN//oVbv9vUnzF9Gt0Bunj9ZRtWkve7YcoKvLimXmBObcMIM3ntnUu26dg1uXQLf3m7RAEO0KvuhoPc/uj6qp2ryP+hONpI9K5bIbL+Gjf3zqZ6yAi8/15ybNX0S3/UMCYvR0J4d2HaNq014O7qolLj6WaZdbmDF/KpljzQAYY41sXPchSumPIRZ+bT6jJmT2eqcmCMGm4XQzOzbvZdeH1bSf62D81DHc9I2rsFwyAWP3cIfrls9zjGnTNFh4+wJGX5A5KDdpgtAfus53se/jQ3y6aS8nD54hyZxI7vUXM/2KKSSbE/V9OrvY+PyHjke/C7+m6zZacs0LQ5OTh89S9e4e9lYexGa1YZl1AdcUXcb4KaPRNI3k9ESvsYKmIT43wonYtGt5eXlkZWX5nVuwP2nXWpva2Pn+fna8t4/muhZGTshg5oKpXJg3yWMMmqZpdJ7vpOnMOXkMEUE453KtrKzsu0KQCVS3EHjaNZvVxoGdtVRt2svh3ceIT4hj2uUWZi6YSvroNI/9Ta//mbZf/Qf1sZmkd54l9UcPwi0rAjqmMPhEu3b7k3at4VQTVZv2svvDatpbz3PBRWOZuWAq2TPGe4xXNxgMdHZ20niqWXxuBBHtuu1P2rXO813srTxI1aa9nDp8lpT0JGbMn8LF83JISkv03L+9k+b6FtFtBOGPbiM2IA5WHmJ9vM8pqjbtofqTI2gGjQvzJjFj/lRGT8z02utgMBhISI4PeIKREDqiNScm+B8Qn2tsZdf7+9mxeR/nGloZPTGTmQsuZGruRK/ZSQDim04Rt3gy2Jxm4RuM8PpBGDM+IDuF4BCt2vU3ILZabRyoOkrVpj0c2XMCU2IcF39uMjPmT8E8MtVrHWOMgYQkk/SmRTDRqttAAuK6E43s2LyX3R/W0NF+nonTxjFzwVQmTc/yOawhIdlETKxn5hIhMpA8xOjjfT7bUkPVpr3UdY/3mf8vuUy73IIpMd5nPXHMQjhRSnF07wk+3bSXA58ewRBj4MK8bGZeOZVREzJ7rZuQFE/MvoOuwTCAzQpH9ktALAQVPXXZfna+v4+WxjbGZI+k4KvzmTJ7Yq8BQ0xcDCYvafwEIRRYu6xUf3qEqk17qd13koTkeGbMn8KM+VM8xgI7oxk0EpLi9TR+SoHVCjHDJsQaEgz5q3Xq8Fk+3bSXvZUHsHXZsFwygasL5zJ+6pg+HW5MrBFTUrw4ZiHktLd0sPtDfcJGw6kmMsakceUtc7joMgvxCXG91tU0jYTkbsd8wRTPHQxGmDA5SJYLwxllUxzec5yqTXs5sOMoMbFGLpprYcb8KYwcn9Fn/bj4WOITe9e3IASD5roWdry3l53v7ae1uZ1xOaNYePsCcmZd0GePr8FgICElHgNA3Wk4exJGjYO0vjUvRA5DJiBurmvhxOGzmEemYEqKZ2/lQXZs2svJw2dJTk9kTsEMpn9ustfxPt6IjY/ptedYEAaDprPnOLr/JOaRKSSbEzl56AxV7+5l78eHUDbF5FkXcP3yeYzLGeXXjZlm0Eh0zh98cI+9AJRND4bvL5XeYWFANJ09x4lDZ0g2J5KSnkTbuXZ2fVDNjs37aDzTTOY4M1cXzuXCOdl93sDZiU+II84UWP5gQQiUprpzHKs5jXlkCklpCRzefZxPN+3h0M5jxMTHMG2uhZkLppA5Lt2v9owxBhJMsWhnT0LdKega3OXMhdAxJALi7f/czWtPveNYJzwm1khXl5WJF43jC8XXMOnirIDG/4pjFkKBu26T05M4V99CSkYSl904k+nzJpOYmuB3ewajgcRkt+E9a38DoyfAH/4JJw7rPcMSDAsDwEW3GoyeOIIzR+tQwJTZEyn46hWMzR4Z0JO1hKR4n+PgBWGwcPe5pqQ42lvOM2J8Otcuu4ypc7KJC2BRlxjNhulcHdrRM55D04SoI+o9UNPZc7z21Nsuef+6Oq0Ufm8h4yyjAm7PlBRPrDhmIcjouu1xzADn6lsouO0KLpybHXAeSq/Dew7tg03/gLvuhwkW/SUIA8BDtwpOHjzDnBtmMPvaaSQkmwJqz2V4jzdsNhhgTlZBAO8+t73lPF8ovobsGeMDGxrZ0UHsubOYzjdDZOYlEPpBxHqa2tpaFi9ezLp163rdr+5ko1c9uq9t7w8JySYJhqOMdevWsXjxYmpra8NtChCobj2Fm5KRFHAwHBsXQ0KyydOhP/NrMCXA8m8F1J4QGqJRu750e8FFYwMPhg0aiSkm38EwQP2ZgNoUgk806hZ8azfOFOt/MNzWAscOEn98P6aOJgmGowh/dBux0V9WVpZfqVQyRqehaZqL0L2tDNMbLrNDhajCnnty8eLF4TYFCK1uQXfmXsdonmuCvz0LN30Z0vwbCyeElmjU7mDp1uvwHndsNn1MZmbgT/qE4BGNuoUBavdckz5Zrr0FU3wMsXESK0Qb/ujWa0C8ceNGGhoavFa45ZZbBsW4wSI1M5mbV1zFa0+/o69opGlct/xyUtKT/KrvmB0qj+WEEDJQ3QKYEuM8FpBx8ML/QmsL3P6DQbJYEAZHt8YYIwnJfmTvqTsNVpmgJAwOAWtXKWhqgPrT0NGuD+9JiHGsACoMPbwGxPX19RQXF1NcXExGRk/akEhNP3bpNdO44MKxnDxylrQRKX47Z8kxLISTS6+ZhmXmBGqrTwakW+gj+bvNpgfE8xdC9oWDZK0g6Nh1e/LwGZLSEgPSbWxcDKYkP7L3KKWnrhKEQeTSa6YxaXoWxw+c9u1zbTZorNMD4c5OoHt4T0IMBokVhjReA+IlS5ZQXl7OfffdR2qq95WEIo2UjCRiA8gMIcnfhUggNTM5oBsyv4b3vLEBjh+Cnz45CBYKgiepmcnEJcQGtHSzz+E93mg4C12dYJRH08LgkpqR7N1/dnXpums865I6zWDUSDBJMDwc8DmG+PHHHw+lHSFFkr8L0Yjfw3uefRSmzIR514fGMEHog16H97ijFJw5ob8/exI+ektfYEbSBQrBoLNT7w1urPNInWY0GkhIMErH2TChz8EwTU1NLr+jnfiEOAmGhajDGGMgMcXUdzC8cytsfw9u/Q6IExcigIRkk//BMEBTPZzvgI1/gbtughXXwcKJ8NJTQbNRGIZ0tMPxw3DgMz2biVswHBsrwfBwo8+A+M4773T5Hc0kJMXLghtC1BFjT6vmzyO7P/wKMkfDoq8F3zBB6AVN09Oq9bXsrQdnTug9w0880JPWymaDn66EE0cH31BheNHVBbUH4eBefdKct1RscUZMphgJhocZfk+X9Ja/L5j4m1vQHxyOWXIMDzmiNSemv8TGx5DgvuCGL06fgDdfhiV3Qpw8BYl0hrJ2DQYDial95Bj2RnMjtLfBiSP6UuPO2KxwZP+AbRMGRtTrtqtTT6PmA5PJSHy8jF0fagyLPMR9oRk0EpNNAS3dLEQP0ZoT0x8CXkJ87W/0SUhf/e6gHF8ILkNVuwPK3nP6uP47LcOzzGDUlx4XwspQ1S0aJJhiiImRWGEo0u88xM6Eumd4MPEr+bsgRCABLyHe0a6PsVy4DMyZwTNMEHrB6xLi/tLSrK8EBrDp72CM0XuJbTY9GL6/VCbWCUFBzzFslBzDw5w+/+MuW7bM5Xe04Hfyd0GIIDRNIyG5H6sm/t8f9XRB/yoLcQjhITY+BlOiHzmGfWHPLHHmBPztOVj0VbhxGcTF6z3DEgwLQcBg0BfckLRqQq8BcVNTE0uWLOHgwYNRFVj6nfxdECKIfg/vUQr+/Chcdh1MmREc4wShFwIe3uNOW2vPuM4X/gcSk+Bf/hWSU+GiSwfDREHwwGjUg+FBj2/OnoRTR2FantzIRRE+//PeddddrF69msbGRvLz8/noo4/87iVetWoVeXl5FBQUeF0CWtM0cnJyyMnJYdWqVf023htxplgJhoWow2DsTqvWn0d2772hpw6S3mEhDJgGI3vPme6xwzW74d3XoGglJPi/Ap4gBEpMjCE4wfDGv8C3FsF3vijpAqMMnz3EW7duZcuWLTz00EOsXLmSH/7wh9xwww19NlhRUUFNTQ2VlZVs2LCB1atXU1JS4iivqamhsLCQsrKywTkDJwJK/i4IEcKAxl0C/PEhmHQhLLjR9z7njkLjPkibAsnSYyEMHHv2noCH97jT0d6T/mrtb2C8Ba79l0GxURC8ERtrwGQaxJwCTfVwYA/s2qoPX7NjTxd4xULpKY4CfCoiOzubJ598kscff5yKigrefPNNvxrctm2boye5sLCQ1atXu5TX1NTQ0NBAUVERGRkZlJSUYDab/Tb4+PHjHD9+3GVbeno62dnZtLe3U7WtyqNObm4uAHv27KGlpcWlbNKkSWRkZHD69GmOHDniUpaSksKUKVOwWq188sknHu3OnDmT2NhYqquraWxsdCnLyspi9OjR1NfXc+DAAZeyhIQEpk2bBsDHH3/sMXFx2rRpJCQkcOjQIc6ePetSNnr0aLKysmhubmbfvn0uZbGxscycOROAqqoqOrvXYbczZcoUUlJSqK2t5eTJky5lmZmZTJw4kba2Nnbv3u1Spmkas2fPBmD37t20tbW5lGdnZ5Oens7Jkyc9UpqkpaWRk5NDZ2cnVVWe12bWrFkYjUb27dtHc3OzS9mECRMYOXIkdXV1HDx4EICxY8cyduxYj3aigb60u2vXLo86fWq38TSnN1Vw5Gur4OOPHWUu2n35p7D154DSF+vI+09m/st/iXYJnXaHsm4/+dTTNwbkc08d09Ot7dpKyvZtTPnxo1jR+GTXZ3r6wNae9Gvic3XE5/aNT92OHQOalW27PFP45V58EQB7Dhykpa3dpWxS1lgyUlM5Xb2XI9u3wLFDcOwg1B4i5VwdU+LBGhPHJ23urVqZeeAzYseMF91Gum6VDxoaGtSvfvUr9fHHHyullLr33nsd73ujuLhYlZeXOz5bLBaX8vLyclVSUqLq6+tVSUmJKiws9NpObm6uWrRokeP13HPPKaWUuv/++xXg8rr11luVUkrt27fPo8z5FOfNm+dRtnbtWqWUUo899phH2Q033KCUUqqxsdFru6dOnVJKKbVo0SKPsocfflgppdT69es9ymbPnu2wKS4uzqN8x44dSimlVqxY4VF27733KqWUeuuttzzKsrKyHO1mZWV5lL/11luOa+letmLFCqWUUjt27PAoi4uLc7Q7e/Zsj/L169crpZR6+OGHPcoWLVqklFLq1KlTXr/DxsZGpZRSN9xwg0fZY489ppRSau3atY5t999/v1JKqeeee85FH7m5uV51FGp86VapIGn3xyvUY5Yk39qt3eVduzXblVKi3VBp165bpaJPuyH1uWPSlKraoho/+Kd33YrPDalunbU7ZHTb1qr2vfayd93u2KrUjq1q3qyZnrqdZ1Hqc2nqsbGe9W64eIpS5S+pxr++4F23VeJvo0G3mlLe86pt376dBx54wPEYVymFpmm88MIL3nZ38OCDD2KxWCgsLAQgLy+PyspKn/unp6dTX1/vsX3x4sVecwsGpZdNeoij/q7Pl15CTW92DLp2M8xkFM7g9L/cwZHP/6tLmUO71f/HJ0980aPdmd8sJ3ZSvmg3AnqII127QfW52z7Sh0u89zr8dS0p9/yaKVdcpfvcE2dhxGiXuuJzdcTn9m2HT90aumh/93V2tdsgrTtFpbULTh4lN+Y8HPiMPVWf0HLkEJzv7iU2ZzJp6oVkXDST0xlZHDGlQWqG/sQNSElKZMrEC3Td/nkNvPw0KAWaAVb+iJl3yxM5iHzd+gyI586dS0lJCXl5eR5G90ZFRQWlpaWUlZWxYcMGtmzZ4jKG+MEHH8RsNlNcXMy2bdtYtWoV5eXlARktCO5Eil5CakfpL+Dxn0L5YRgxxvs+/yiCmg2u2zQjfPWgjCWOEIaldgE6O2FflZ5d4rtfhDnXwMr/0sviTWCZBgbJCxupRKVuX3oKflqsj+3VNJg6Sw96j1TrK9hpGoy9QJ+TkX2R/nvShZBiDsyosyf1IHtarowdjjB600uvY4ivu+66gA+Wn59PWVkZBQUFAJSVlVFTU0NBQQHV1dUUFxdTVFREaWmpo1wQhADp6oIXfg/5S3wHw9Uv6sHwRV+HPc+AsurB8NWlEgwL4afulN6L9vLTcP48LL2rp2zcJAmGhcHlxNGeYBh07e3ZDvPy4epFkH0hTJwKpsSBHytzNIzP9r7iohCxeATEDz30kOP93Llzyc/PJzOzZ+WrH/yg79RO9mDXjtlsprq62vHeW4+wIAgB8I8X9GVuv3GP9/KW4/D2SrDcAtc+BZf9NzTuh7TJEgwL4cdqhfrTcKoW/vE8fOkbkD5CLxsxRs9DLAiDyeF9PcGwMwWFMH1O6O0RIg6PgDg7O9vltyAIEcgzv4ZL58O02Z5lSsFb3wBDrN4brGl6ECyBsBAp1J3Sg+LnHtMfR3/+Nn27KQFGjQuracIQ5YIp+lMH56DYYIAxE8JnkxBReDyTWrJkCUuWLCE/P5/6+nrH+wMHDjiGQQiCEEa2vw+7t/leiGPn/8Lhf8C1T0PCiNDaJgh9YbPpAfHeT+GDclj2//RAWNP0oRJRtCqqEEWMGQ/3r+kZimMwwB3/oQ9vEAR6Walu6dKljlXm0tLSUEpRVFQUKruora1l8eLFrFu3LmTH7JMTR+Gjt/TfQkSwbt06Fi9e7DFjNVyERLd/eBCysuHaxZ5l9XvgvR/A9Ltg4k3Bs0EYMMNSuwD1Z/QJdWt/A5OmwlU369tHjIGEQRi/KQSVqNbtRcBtChYDtyqYFmzrhEjBH936zDIxZ84ctm7d2ue2YBEpM1gdOM9ONRj0O81bVoTbKqGbSNFL0O04fhhutMAPH4bb7nYts3bCS1dAZxMUbYNYGYcZDQwb7YI+nGdvlb4886P3wY/+B2ZepgfC2RdJ73AUEXW6PXcU1k4E5TyO2ADzXoX4IPQSy6S6iKRfWSYsFgv33XcfBQUFZGRk8Pzzz2OxWIJmZETjPjtVlmMUwsUzv9EnHHm7Gav8OZz5GG55T4JhIagcP/sJJ059xJhRlzE2c5b/FRvOQlsLrHsMZi/Qg2EZKiGEgsZ9bsEwgA3ajgQnIBaiDp9DJtavX4/FYqG0tJTVq1czYsQI1q9fH0rbIgdvs1NtVjjiufSjIASN1nPw8lPwxW9AYrJr2YkPoPIXMOfHMPqy8NgnDAve3fxdRr1wKbPfKmbUC5fy7ubv+ldRKThzQs+QcuZEzxOOUeP0McSCEEzSpmDD9abLigYJMqlO0PEZEDc1NVFeXk5lZSWVlZVs2bLFsQLIsOOz9zy3aUCm9MIJIeSlp6CtFb72Pdftnefgza/CqDmQ9x/hsU0YFhw/+wlXfPIoxu7PRuBznzzK8bOeK3l60NQAZ07qN3XXf0kfB5+QJJOahJCw5ZyNO0dOo6v7cxdQPGIaW9qMvVUThhE+A+KioiJWrlzJ/v372b9/v+PzsGPTP+CRn0ImOG4uNeBqIL7Fdz1BGExsNvjzo/pEurEXuJZt/gG0HIPr14LB5ygoQRgwJ059hHv4EAOcPLWl78pnjsNLT+o9xYXF+hCJrEkyVEIICZuPVfN0WhaTJl3JNePymDTpSp42Z/F+06lwmyZECD7/e549e5brr7/e8bmwsJA1a9aExKiIYft78O9FkD0Brq6BdqARSANSjPoiB4IQCt7+K9QegJLnXLcf/CvsKoWrHwfzlPDYJgwbxoy6DCu4BMVdwOhRc3uv2NwINZ9BeZm+Il1aBozK0pdoFoQQMH9cDpzWqI0xURvTrTubxudSR4XXMCFi8NlDbLFYuOuuu9i4cSMbN27km9/8JmazOYSmhZm9n8K/fQFGZ8LVh2BMrh4EZ6H/luVvhVDyx4f01ZRmzevZ1nYa3loBEz8PFxeHzzZh2DA2cxbvzbrb5bHz+7Pu7nti3ZkTsO53kD4Sblquj4HPlEBECB1zx1zA12NvBVv3EwmbxtdbFjLXLLnaBZ1eJ9Xl5uZSVlZGWVkZc+bMCemkurDmIT68H4pvgOR4uO4IXFQISz6Arx6Ef3lL/32xpFyLBKI6J6a/fLYdtr3ruhCHUvDPO/VZ09c+KY+do5Bo1e6V8x/h9LLtbL/2CU4v286V8x/pveHWc7D1bdjyT/jyt/QJdDJUImqJVt0CPH3d1/ho+v/waGwxH438T56etRBiZJjZcGBAeYi3b9/OHXfcQU1NDQA5OTk8+eSTzJoVQIqdARC2HIenjsFtV0BnM3y+AWZ9Ga7/k4zNjHCiLidmINz3VfhoI7x+qMd5735a7x2+8WWwfHFwjyeElCGtXYADe+C7X9ID4J/9EcZNlN7hIcCQ0q1S+lLi1i791dXl+r6r07PMPfOUO5KHOCLpVx7iO++8kyeeeILZs2cDsG3bNu644w62bPFj8kS00lgHd1wPrfWwqBkuvQ2u+wMYZBaqECbOnIDX18O//XdPMNxYA5vuhou+IcGwENm0ter6rdkNP3kSUtIkGBYiD03T/WsgvcU2m/fg2f4+Ni549gpBwefVV0o5gmGA3NxcfHQmDw1az8GdBXDqMHyhFeZ+Ha55QoJhIbys+z0YY/RZ+aDnv37zq5AwEhY8ElbTBKFPag/C87+Hy66Fi3P1oRKCMBQwGMAQJ4HvEMJnQJyfn8/ChQspKCgAoLy8nJycHF566SUAbrnlltBYGArOd8D/+zzU7IAvnIcFd+qz9jWfQ6wFIfh0tMP6/4XFX4O0dH3bxw/CyQ/gi+9AXEp47ROE3uho14PhhrPwle/AmAkSPAiCELH4DIhzcnLIzMwE9N7i/Px8AKqrq9GG0mSIri743hL4ZDPcbIVr74KrHpNgWAg/f3tWH8bztX/XP5/eBlt+DLNXwdj54bVNEPpiXxX83x/hhiKYPB3SZTa/IAiRS689xCtXrqSyspKzZ8+ydOlSHnzwQSZNmhRC84KMzQY/uh02/R0W2uDGb8OCR2X2sxB+lIJnfg0LboKJU6CrDSpug4yZMPcn4bZOEHqn8zw8VQJGIxSt1CfSCYIgRDA+u0GXLl1KSUmJY3GO4uJiioqKQmZY0NOuKQUPfBv+/hxca4PF35VgOAqJ5hRAvfLBm1C9C27/vv75/XuhqQby/wxGeew8FBiy2gWofAfefBluWQFTZshQiSHEkNatMGTxS7fKB3l5eUoppZYuXeqxLRQsWrQouAf47X8qNQOl7kKpzT9QymYL7vGEoBJ0vfjJoNnxzZuU+uIMXZeH31Dq9yi1/ZHBaVuIKIacdjs7lfrqfKWuy1Jq/47BaVOIOIacboVhQW968TlkYs6cOdx1113U1NSwceNG1q9fz5w5c4IRuIeeP/0a1vwcLge+ei/Me0B6hoXI4cAefRjPz/4AHfWw8V9hfD5c8u1wWyYIffNGGXy8Gb7/K7hgaritEQRB8AufAfHjjz/Oiy++iFKKN954g4KCApYsWRJK24LDS0/DQ9+HS4E7fgSX/0yCYSGyWPtI9xK3X4Z/3g5drXo+bJnoKUQ658/D7++HC2fBF78OsbHhtkgQBMEves1CvWTJkqERBNspfxF+cgdcDHz7frjsJ+G2SBBcaayDV5+Br/8QDr0I1euh4HlIHh9uywShb9Y9Bof3wa9fBHNmuK0RBEHwm+GzHvF7b8APl0KOgu//FC77cbgtEgRPNjyhL77x+cVQfh1M+QpMWRZuqwShb841wZOrYf6NcO3icFsjCIIQEMMjIN7+Hnz785Blg/t+Bpf9Z7gtEgRPOjvh2d/CTcth+w8gNgWu+n24rRIE/3j8v6GlCb5XEtgSuIIgCBHA0B+UuOcTKL4OMrvgv34hwbAQuZRvgNPH4PIRUPsWXP8niDeH2ypB8KC2rpV3dp2ktq5V33DiqL7M+L/8K1x4SVhtEwRB6A8RGxAPSm7Bg3vh65+DpA746QMw7z8Gz0AhIhgyOTHtC3HMvgxqfwuzvgfjrwuOkUJEEK3a/dPb1Vz8vb/w+V++ycXf+wt/ersafrMKTAnwnQdCZK0QLqJVt8Lwxh/dakopFUKb/Gbx4sW88sor/W/g+GFYNh3UOfjlAzD/vsEzTog4BqyXcNux/T346nxYNgkmJ0HhVogxDbp9QuQRTdqtrWvl4u/9BZvTf41L2w/xzmc/Qvv3B+FffxBkK4VIIZp0Kwh2etPL0BzodfYk3HYJdJ2D1b+QYFiIfJ75NYxKh8yjkC/BsBCZVJ9odgmGUYr/PvIsbaMmknjr3WGzSxAEYaAMvYC4qR5umw7NjbD6Z3C1DJMQIpxjh/RlbufbYF4JjJgVbosEwSs5Y1IwaDiC4oVN27n23E7O3vsCiZJzWBCEKCYoY4hXrVpFXl4eBQUFNDQ0BFzeH3Z+9CrvPnYHnUstcOos/PdP4HqZQCdENjs/epWj93weFWODq6+AWd8Pt0mC4JOsjER++43LmdBVxzVNVfyy9s8cz7mMzMVF4TZNEARhQAx6QFxRUUFNTQ2VlZWsXLmS1atXB1TeHzb96EouvmMxV5Y+RUxtA4dyx8ON9w+4XUEIJnbdjv9kJ5yHLdvPg8EYbrMEoVduP/tPdu68m1erf0lOxwnGFtwoq30KghD1DHpAvG3bNpYt0xcSKCwspKKiIqDyQNn50avMf3UTWvcjPA244MOj7Pzo1QG1KwjBxJtu5/xtq+hWiGxOHIWfFqPZbICuW9b8Qt8uCIIQxQz6GOLq6mpyc3Mdn92HRPRVbseeSsXO8uXLWb58ucd+Zz7+uyOosKMpOPPJ63DZosBPQIgK1q1b55JmJ9JSANkR3QruRLV2D++D7mDYgc0KR/bDGFlefCgT1boVhi2B6HbQA+KcnByXINdsNgdUbicrK8uvVCojZt+E0v7XJbhQGoyYtTAAq4Vow93pOTvEcCK6FfoiqrV7wRQwGFyDYoMRJkwOrnFC2Ilq3QrDlkB0O+hDJnJzc3nhhRcA2LBhA/n5+QGVB8r0yxaxedECVPcQNqXB5kULmC69bEIEI7oVopIx4+H+NT1j3Q1GuL9UeocFQYh6Br2HOD8/n7KyMgoKCgAoKyujpqaGgoICqqurvZYPlAW/eJed//IqZz55nRGzFrJAggohChDdClHJLSvgioX6MIkJkyUYFgRhSBCUtGulpaWUl5dTXl6O2WzGYrFQXV3tszwQfC3POP2yRVx952NDvodtuC9PGc3n78120e3wIJrP36vtY8bD3GuGRTAczdduMIjW849WuwcLOf/Azz8oAXEwkYss5x+tRLPtA2U4nztE9/lHs+2DgZx/dJ5/tNo9WMj5D4OAuD/054sJRZ1QCTZSz2W4/8H2RaTqtr91QnGMSNX6cCNSr0Ok+txI1fpwI1KvQ6TqNlR1QnX+EhCHsc5QErk458EnUnXb3zqhOEakan24EanXIVJ9bqRqfbgRqdchUnUbqjqhOn9NKaX63i30TJ8+nZycHI/ttbW1ZGVlBdRWpNaJVLv6UyfcdlVXV7Nz586A2goGvnQL0fedDmadSLWrP3UG+xiRrt3hch3CWSdS7eqtjug2dHUi1a5Q1QmVbiM2IBYEQRAEQRCEUDAshkwIgiAIgiAIgi8kIBYEQRAEQRCGNRIQC4IgCIIgCMMaCYgFQRAEQRCEYY0ExIIgCIIgCMKwRgJiQRAEQRAEYVgjAbEgCIIgCIIwrJGAWBAEQRAEQRjWxITbAF/I6jPRVSfcdkX6qkkQfd/pYNaJVLv6U0dWquubaLwO4awTqXb1Vkd0G7o6kWpXqOqETLcqQlm0aFFA2/vTVrjrRKpd/akTbrv601Yw6M2OaPtOB7NOpNrVnzqDfYxI1+5wuQ7hrBOpdvVWR3QbujqRaleo6oRKt8NiyMTy5csjsk5/jtEfIvVcQnX+0Uqk6ra/dUJxjEjV+nAjUq9DpPrcSNX6cCNSr0Ok6jZUdUKm24DD7hAR6Xel4WKonr/NZtNf1p6X1WrVX136q/5Uo7r1i7erxjPNHvUj5XuJhp7AcDBUz92hW1v/dKtU5Hw34nO9M1TP3y+fezp6fW6k2Bcuhur5D9Tn9va9ROwYYl8M5ztcZVMsW7YMm9XWs00p132U+xtQboVuVVzbcfxy2sm1yLVt5bpTz/Gdq7u17c2APtj5/j42rvuQaUnzeOy7z3Lziqu49JppAbcTToardpXq1q3N5lMDLh/tOvVS6C4dl3bcteuuW+e23XTrss1HO97s7gtdtx+IbqMUd5/r7fq7+9ze9eZcFLjPdW1HfG5vDGvdqgBiBacP/YkV9Lc+fK4/sYJLvfD63CETECub0r84DTRNQ9O0EFsWGErp9up24/Reub639ezbXN/C7MnzOHHoDCnpSeE+hT6x2WzYrAqb1eZ4We3vbfp2a5f9s81pP9Wzn9VGa1Mb775c6WhXKcVrT7+DZeYEUjOTw3iGgeFLu9YuK5pBQ0NDM0S2bgEPndqcPyvPcoduD0aHbpVSnlp006eLlt213V3e2tzGOy9udWl3KOnWfoOjaZrD70YyLr7V5kOvQ8HndnVr0ebqe3t0qrBZrR5+1tkvDwWf6zNW6P771gza0IgVevO5UaJb+zVx1aPy9K02ha3L2q1hz9ihpamdd1/qv8+N2IC4traWxYsXs3z5cr/u9Lo6u2hvPe+yzS52zQB0Bxu673Z6r//Q3w8gKAk0SAiUHZv38tYLH+p3VRrMXTiT7Onjew0kfQnM0wl61vXYx1mc9mN22T97c7yqX70S/qJsivqTjfztjVdZt24dtbW1QTtWIASqW4DW5naXz84Bhqb16NRlu0FDA1en3o+gpD9BQiDseG8fbz3/gUO3ly2cSfbMCb1o1Obq7Pq4gXIPQn1p12pzP4ZnPedjBQu7blMzk1m3bl1Ua/d8eyedHV0u23p8qJtvddOyi8/tR1DSnyAhUKo27eWf6919blYfftbzH7XVsd1HEGr3y7Yen9rjZ310KHira7VB8KQ7ZHyusimvPterf9V64oEerTrHFgOPFXrzuTabre8G3fDqc2eM9/Stdn26+FTvgam1W7uevrK7zS6rVz/bm192jhv68/fpL4HoVlPBjFoGwOLFi3nllVf83r+zo9MjIB4IvoISYMBBgh2lFB1t52ltaqelqY1W+6vZ6XNzO+caWmlv6ej3uRgMGgajwe2lYTQaMRhdy4wGg8s2o5d63rY7PrsdyxhjwGDws66zLQb7do3Wcx0889OXXR6xaAaNb/3mVsddX6B6CRb9saO5vmVQbfAVlAxGkGCn63wXrc3ttDa30dLU7lW75xpaONfQ1v/z0DQPfeoa1TDE9GjXaOhbnz3bNIcejTE9WnPXn3eNuurTtQ3P47Y2t7P2Z3/pVbcQvdptb+3wCIgHgofP7Q5KYBB9rk3R1tLe43ObnbXbo+WWhlY62jv7fS4eenLWaIynn/Xll40uetO8+FRnjWpeNOvpl43dNjg07K7tbu0OVZ+r9yT23y95w93n2rXs8LlOfre/nO/o7Naqp3ZbmvXt5xpaaG1q77uxXs7Dxc/60pOvuCHGqOvQiz69xRwu//t9+uU+tO1U1trUt8/tTS8R20McbpRSoFzHdTXXt9BwuhnzyJReH0N0dnTqjrVbpD3OtudzS7MuaFuX6x1gTJyRpNREElNNJKYmMHZkCl3nrez+sNrjONcvn8dYyyifgaQhxojBEPmPhOw47HT80p1KfGI8+bdeQcVz76NsCs2gcfM3roqaR3ehRtmUrlsnafmjXZvVRtu59p4A165fL9o93+YaLGgGjcRkXbOJqSYyxqSRmpnM3sqDHse5bvk8xmaP9BlIOjvIaMH+DxC6dQuYkkS3gdBfn6uU4ny7Hiy0uPnbNscNWvf2c+0eN4JxCbEkpSQ4tDtinJnOji52vr/f41jXf2UeY7NH+QwkjUaDoycxGnD2uVqPgIlPiBPtBoC7z/U3VujqtNJ2rtuvNnnxt04xROd515tPQ4yBxBSTQ7sjx6eTMTqVz7Yc8DiO3ef6DGoNPdqNBrzGCoBpgLGCBMR+Yh+obX8McdFcC+aRKU53ae3dd2ltHr0mBqMuXIfDzUrngtRxJKYmkJRqIjElwREAx8XHehy7ub6Fzz6qdr3r0TQumDauz/FBvoJMvcyxV8/77jeazzo9fzDe62hubfdlg39/gJfdeAkXzbVQf7KR9NFp4pgDwP0R2uRLJ5KakeTQbJv997l2j0eupqR4h3aTzQmMmpDRrWNX7ZqS4j0C2Ob6FvZtO+ih24l+6Na+r7vD03sQHXt074dv3TrquOrMo073Rnc5+rZBdBts3H3uhXOySRuR4tQr1k5b929rp9WlrjHWSJJdpykmxkwa4eSDu7WbmkBiSgIxsUaPYzfXt7Drg/2ePveiwHyus2b0sp4Pzv7TTdJ++VzNbaMvn+tpg2g3mLjoFrh4Xg7po9NcngK3dMcNHe5PtTWcOhYSMI9IYZxllJt2dZ8bnxDncS2b61vYs/VAUH1un7GCo07gPjfcsYIExH5wdN8J3nzug54NCj77qAZTUjzJaXpvbuqIZMZkj+gRbLeAk1ITiE/0FG5v2B8X2nt3M8eaWXj7Al5/ZrPjruemf72SMRNHDEg40UZqZrI45QDo7Ojkk3f38N7/fdyzUcH+jw+RkpFEijmJxFQT6aNSXfSaaNdvigljjGew0BsGg0F/bGgwkDnGzA1fW8Aba3t0e+PtCzx1q78R3QqA3uNbU3XUw+fu2XKAhBQTyeZEklISyByTRuLUMa6a7f4dZ4rtv881aIwYl96rz+1vkBltiHYD4/TROt587n2cQj52fVBNnCmWpDT7DVoCI7LSPf1tagIJSfEYjIE9GdN9rq5dbz5XYgX/kYDYB1arjZpPj1C1aS9H957wus/NK65i/JQxAbXb43QNaJqrmHubYJKXP4MpsyfJ3brQJ2ePN1C1aS+ffVTDeR/jIAtuuyIg7TrGdGo9WvWmY3fmFMxgaq7oVuib8+2d7Nl6gKpNezlTW+91n5u+fuWAfK7BrmODs469ByDicwV/UEpxrPoUVZv2sv/jgzgHw3YWFc0g67IZAbXrfpPW43sNLtvcEZ/bfyQgdqO5voUdm/ex8/39tDa1Mc4yiqsL5/LOi1s8HkOkjUhxqWsPCjSD5nC8DuH24nj9Re7WBV90dVqp/uQwVZv3cmz/KRJSTFxy1YVkTx/Phkf+0at2nZ9G2HXqvm0gPQmiW6E3ztTW6zdwW2roOm8le0YWuddfTPnazb3rVtM8ggZvOh4Iol3BFx1t5/lsywGqNu2h7ngj5pEpzJ2ZykfbG1Baz/96TVlJP3/KpW5fN2kDTQcnuu0fEhCjD4g/tPsYVZv3cnBHLTHxMVw0N5uZC6YyYlw6oE92s48L0jRYePt8Rk3IdHHAghBqms6eo2rzXna9v5+2cx1kTR7Njf96JTmzJjiGO1y3fB4bn//Q8Qht4dcWMPqCzEG5SROE/tDVaWX/9kNUvbuX4wdOk5SawOxrpzH9iin6WEebDeuZU2z8+z4nn7ugx+dG0cQ1YWhx6kgdVZv2sHfrQbq6rFhmTuCqW+YyYeoYDGeOkfnXb/D38ctRmhFNWbmp9nkyL12LlmIalJs0IXhEbEDcn3yugdLa3M6uD/azY/M+ms6eY0RWOtcsvYwL52QTZ3Kd3HZp3ftM2/WfNMRmkt55ltSmByE2sEcgwuAT7blc+4PNZuPQrmNUvbuXg7triYuPZdrlFmbMn0rmWLPH/rOvuZiLLx1PfUOHPEKLIIajdhtON7Nj8152fVBNe0sHE6aO4eYVV5E9cwJG+9jJzk44dojZx99k2q5SN587PSh2Cf4zHHXbdb6LfR8f4tNNezl58AxJ5kRy86cz/XOTSTYnOvbTmuq4tOEDLOd20RA7gvTOOlJ/VAITJgXFLsF//NHtsMtDrJTieM1pqjbtYd/2w2jAlNxJzFwwlTGTRnjtdTCcOUZi4UVozkmyDUZ4/SCMGe+3jULwiNacmOB/HuKWpjZ2va/fwDXXtzBqQgYzr5zK1NxJxHrJTgJ6+qQ4I1B/GkaNC8guITREq3b9zUNss9o4sOMoVZv3cXj3MeIT45h2eQ4z508hfXSaW6NtcOwgMWeOYfrhl9CU+NxIJVp1G0ge4vpTTezYtJddH1bT0XqeCy4ay8wFU8meMd5z8tv5DhLvWKA/wXjsFThxBCZMFr1GGJKHmJ7xPjs27eXs8QbSRqZwxRdmM21eDglJ8T7rGYwGEs8ecQ2GAWxWOLJfxC4EFaUUtftPUvXuXqo/OYzBaGBqnn4DN3riiF7rJiTFExMXA6ePw6laOLgHLpgimhVCwrnGVna+t5+d7+3jXEMroydmkn/rFUzNnajr0p3mJjhxmBgDmBqOuQbDID5XCAlWq40DVUeoencvR/aewJQUz/TPTWbG/CmYR6b6rBf/1M8wHN2P9vwWmJCjv4SoYsgHxKeP1lG1aS97thzQx/vMGM+Vt+QxYerYPsfyxMQaMSXFo02aimOpLzsGo373JwhBoKP1PLs/qqZq8z7qTzSSPiqVBV/K46LLLJgSfd/AgT7ZKCE5Xh9DrBSUlULpz8BmA4MB7l8Dt6wI0ZkIwwmlFEf3nuDTTXup+fQIxhgDF87R52OMmpDpu2LdKTh9gthYAyZTDNTs9txHfK4QRJrrWxw3cC1NbYzNHskNX5vP5Esnes1V7UxM1QfEPv8o2rd/DhfOCpHFwmAzZALi5roWThw+i3lkCglJ8ez7+BBVm/Zy4uAZktISyL3+YqZfMcVlvE9vxMbFYLL3HI8ZD1nZcLRG/2wwwv2l0lMhDJims+c4uv+kY0Wjk4fPUvXuHvZWHsRmtWGZdQHXFF3G+Cmj/ZpEZF8xzvE4b/8OePxnYO9ts9ngpyvhioWiX6HfNJ09x4lDZ0g2J5KSnkR7Swe7Pqxmx+Z9NJxqImNMGlfdMoeLLrMQnxDnuyGl4ORRaKwnPt5IXJwRPnoL1j0G03Jhz/buGznxucLg0FR3jmM1pzGPTCE5LZHDe45TtWkvB3YcJSbWyEVzLfqE+qx0v9ozdrRg+vkKtJmXwTdWBdl6IZgMiYB4+z9389pT7zjWCY+JM9J13sqEi8by+Tuu9j7epxfiTLGuTnzHFj0Y/skTcMFkGRckDAruuk3JSKK5roXk9ETm3DCD6Z+bTFKafzdw0D28J9nk+uRj17aeYNiOPHoWBoCLbjUYO2kEp47Wo2yKybMu4Prl8xiXM6rvG7iuLjh2CNpbMJliiI01wM6t8Nv/gMuvh+/8HJrqIS5efK4wKLj73ITkeNrOdTBiXDrXFHmfUN8bMbFGTL+5D63+NDz1JhgDW8hIiCyiPiBuOnuO155622U0Q9d5K0vuvoGsyaMDbs+UGOc5QWntb2DcJPji10XwwqCg67bHMYP+lOP6r8xj2uU5AadDM8YYSUiOdw1C2lohOc1zZ3n0LPQTD90qOH7gDHn505l93TQSUxL8a6ijA44dQOvsJCEhRs8wUbMbHvq+3jP8rf/WdTr1Ehg5NngnJAwbvPnctnMdfP6Oq7FcMiHgNH6x8TGYtlbAy0/Djx+XMcNDgIhNQmpPpbJu3bpe96s72Yi3PBn9SZ6RkGzyDIZPHYPXy+C2uyUYjkDWrVvH4sWLIy4FkH+69dRo2oiUgIPh2LgYElNMng69/rT+dAP0scMgj54jiGjUri/dTrx4nP/BcEszHNmP1tVJYmJ3MHzsIKz+tt7x8P1fQUwsJKfCiMBWpROCTzTqFnxrNz4xLuBgOD4hDlNHM/zXN2D+jVBYHFB9IfT4o1uvPcTbt2/njjvuQNM0HnzwQa699loAFi5cyOuvvx4ca93IysryK5VKxug0NE1zEbq3VeR6QzNoJCTFOxYycOH530N8AnzpG363J4QOe+7JxYsXh9sUILS6BS/De+x0dekB8V/X6o+fv7sa2lrk0XMEEY3aHbBuG87CqWMYDJCQEIPBoMHZk/DAtyA1He59FEyJekCcla1PZhYiimjULQyezzUlxRMba4R7i6GrE372tOg0CvBHt167ooqKinjyyScpLy/nhz/8IYcOHQKguro6OJYOgNTMZG5ecZVj3KSmaVy3/HJ9tSM/MBgMJKaYvAfD7W2w/nH40tf13gpBGCQGqlvQh/f4nLDUcAY+3Kjnwlz8NRg5DuZeI8GwMCD6rVul9KdtJ2sxGjQS7cFwc4MeDAP8x2OQYtbfT7BATNSP6BMiiIH6XD17j4nYuBj467Pw5svw41IZ0jOE8Opx0tLSuPTSSwFYv349xcXFvP766xG7VOal10zjggvHcvLIWdJGpPgtcGOMgYQkk+/0a397Vp/Ucet3BtFaQdC59JppWGZOoLb6ZEC6BX14j89UQErB2VPwyp/g4jzImd4TaAjCALHr9uThMySlJfatW6sVjh+GluaetGoA7a3wy7v1oPgnT0Jm95yP0VmQKKspCoPPpddMY9L0LI4fOB2Qz3XJ3nPiCDzwb3DTl2FhUZAtFkKJ14B4zpw53HXXXaxatQqLxUJ+fj5Lly6lrq4u1Pb5TUpGErGBzA6Ni8HU29ghpeCZX8PVX5DB8kLQSM1MDmhte5ccw75oboRPP4DqXbDqUUhJg0T/g21B6IvUzGTiEmL7Xqnu/HmoPQDnO4iLMxIf363bzvPw8A/1scP/9TiMm6hvl3HDQpBJzUju3X+6YTAaSEiO1+d22Gzwo9shIRl+9D9BtFIIB14D4scff5wXX3yRhoYGAH74wx+yYcMGMjIyQmlb0IiNj+lzcQM+eFOf9fyfInohMjAYDCSkxPc96a7uFLz6jJ4i8NIr9OESghBq2lr0tGpdXZhMRn3cJehp/37/Y/jsY7j3t2CZpm+3jxsWhAjBI3vPusf0PNmlb0Caf3mKhejB5yCtJUuWANDU1ERqaio33HADhYWFITMsWMQnxPmXZ/CZX8OUmTDn6uAbJQh90OfwHjsd7bD7Y/h4M/zbf+tOO8H/XMaCMCg01usLbqBISIghJqb7Jk4peLpEH9/+7w/C9Dn6dk2TccNCROHxFLnmM/j1Kvjyv8EVBeE1TggKfeZ3uvPOO11+RzOmpHj/guGDe2HT3+Fr/y6zR4WwExNrJMF9wQ1f2HuHM0fD526AETLhQwgxp0/AiSNoQKJzMAz6JOWKl2Dlf+qTPO2MGifjhoWIIS4+loQkp57hzk6471YYM0G/kROGJH4nPO1PXt+B4G9uQX/QNI3ElO7Zof7w50chfaQ+aF6IaKI1J6a/xMbH6MGwPzdmVqu+VPN7r8Pnb4WMEdI7HMEMOe3abPqY4LpTGAxaT45hO689By8/BbfeDdc4pT5KSZNxw1HEkNOtG/EJccQnumXvefIB2PMJ/PLP4lOjlH7nIY4E/M0t2Bcus0P9obEe/u+P8K8/gHjTgI8vBJdozYnpD34P77HTcFZPB2RKguu+KGOHI5whpd3OTj0Ybm/DaNRISIhxvYl752/6MLTFt8Oir/Zsj43TF+MQooYhpVs3EpLiiXHvONu5FUp/BnfcBzMvG5TjCKHHH932GRCHumd4MHGZHeovLz8F1i5YdlfwDBOEPjAlxfv/RMPO4X16bsybl8OoLDD5uXKYIAyE9jaoPQhdncTEGDCZjK7BcOU78Ph/w7X/Asu/1bNd02B8towbFsKOz+w97W1w720w5RJY+ePwGCeEjD490bJly1x+Rwses0P9oasLnv0t3PhleYQnhAW/0qp541yTnjfbZtX1K8nihVDQ3AQnDoPN5ppj2M7uj+GR+yDvKr2Hzdkfj5J8w0L4MRi6O868PUV+5F79ycf6bRAbwNM6ISrpNSBuampiyZIlHDx4MGIX5fBGbFwMpqQ+0qp5Y+Nf9KTbX/3uYJskCH0S8PAeZ44fhn+8AFcv0tOtSe+wEGwa6/VgAYiPNxIX53YTd3APPPhdmDoTvv1zMDr9u0lJgxGjQ2aqIHij1+w9H27UO8ju+Q3kXBx644SQ4/M/71133cXq1atpbGwkPz+fjz76yO9e4lWrVpGXl0dBQYEjl7EzmqaRk5NDTk4Oq1at6rfx3ogzxfYvGAZ9jFveVTBt9qDaJAh9YTDqS4j3Kxg+36FPWGqqhy/cJr3DQvA5dxTD0Qq0zlOYTDGewfCJI7D6OzD2Avj+QxDn5JNl3LAQAfSavaepQV+AY87VslLtMMJnD/HWrVvZsmULDz30ECtXruSHP/whN9xwQ58NVlRUUFNTQ2VlJRs2bGD16tWUlJQ4ymtqaigsLKSsrGxwzsAJU2IcsfH9fKyxYwt88j488vLgGiUIvXC0/TRVLQeYkTmJCYZ+9uqePgF//TNcdh1cOEsmgwrBZddTqH8WE4eNWAxoU/8Dxn6xp7z+DDzwLX11xHt/6zosQtNgvOQbFsJLn4tz/fI7+jC0X/wJApmDJEQ1Pr1SdnY2Tz75JI8//jgVFRW8+eabfjW4bds2R09yYWEhq1evdimvqamhoaGBoqIiMjIyKCkpwWw2+23w8ePHOX78uMu29PR0Jk2aREdHB1Xbqjzq5ObmArBnzx5aWlpcyiZNmkRGRganS3/JkeSxkJoF27YBkJKSwpQpU7BarXzyySce7c6cOZPY2Fiqq6tpbGx0KcvKymL06NHU19dz4MABl7KEhASmTdNXZ/r44489Ji5OmzaNhIQEDh06xNmzZ13KRo8eTVZWFs3Nzezbt8+lLDY2lpkzZwJQVVVFZ2enS/mUKVNISUmhtraWkydPupRlZmYyceJE2tra2L17t0uZpmnMnq33mu/evZu2tjaX8uzsbNLT0zl58qRHSpO0tDRycnLo7Oykqsrz2syaNQuj0ci+fftobm52KZswYQIjR46krq6OgwcPAjB27FjGjo3OHlB37f7l5GZ+froMNcaEdl7xn8bFfHH0fJc6fWrXbOb0i3/gyIEjcPOdUHsSTtWLdruJFO0OGd22nsT21zvJTFRkj4COThs7Kn6BYeZIiMuE1nPwxM/JNXbBj0vZc7aRlqNO1ytjFJPGdJCRmMTp06c5cuSIy7FEtzqRoluIXp/rK1bIzs4Gg2Jb9/95Z3Jzc6HiJfZsWEvLN38CJ87qL5xiBdHt0NWt8kFDQ4P61a9+pT7++GOllFL33nuv431vFBcXq/Lycsdni8XiUl5eXq5KSkpUfX29KikpUYWFhV7byc3NVYsWLXK8nnvuOaWUUvfff78CXF633nqrUkqpffv2eZQ5n+K8efM8ytauXavUyVr1WJbBo+yGG25QSinV2Njotd1Tp04ppZRatGiRR9nDDz+slFJq/fr1HmWzZ8922BQXF+dRvmPHDqWUUitWrPAou/fee5VSSr311lseZVlZWY52s7KyPMrfeustx7V0L1uxYoVSSqkdO3Z4lMXFxTnanT17tkf5+vXrlVJKPfzwwx5lixYtUkopderUKa/fYWNjo1JKqRtuuMGj7LHHHlNKKbV27VrHtvvvv18ppdRzzz3noo/c3FyvOgo1vnSrlHftct0YxesFiqfn90+7Z06qx2aOEe2qyNauXbdKRZ92vfrcuSj1e9S++z2/F0Cp18uU2rFVzZs107tulVKPPfaY6FZFtm6dtTskdNtXrHD6uFLzM9W8MemiWzX8dKsp5T2v2vbt23nggQcck+mUUmiaxgsvvOBtdwcPPvggFovFscxzXl4elZWVPvdPT0+nvr7eY/vixYu95hbs7a6vvb2dXbt2edTps5ftzw9z+o+PcuS3r7k83pO7Pp1ouOvzpZdQ05sdztrd0riHb+56FFJiYUwCnLfCoRZKL/4uc9KmOur0qd13XuH0fV/nyG33QP6X9PGZiHbtRIp2e+utiHTtOuu2avdnXFx1KyMSIXsEtHfCp8c1Phv5ADPeXKdPpLvjPnIXfgGAPQcO0tLWrg+RyNJTrElPm0406Bai1+cGHCsoRe7T98OOLex58C+0xLoOqRDd6gxp3fqKlOfMmaPefPNN1dDQ4PLqi/Lyckevb1lZmbrnnntcyktKSlRpaalSSqnKykqVn5/vtR373ULQaWtVan6mUqu/E5rjCUEhZHrpA3/tONJ2ShleX6j3Dne/jK8vVEfaTvl/sHNNSt12hVI3T1bq6IH+GSyEnWjS7tGzLerfvn+n6nzMoNTvUZ2PGdS3//0O1fKNG5SaFaPUut8rtWOr62tnpVIt50JwBkIoiSbd+sWLTyo1A6U2/t/gtCdEJL3ppdcxxNddd52vYp/k5+dTVlZGQUEBAGVlZdTU1FBQUEB1dTXFxcUUFRVRWlrqKA8rf3sWmupkJqkQUsabRrLm4rtZuetRrNgwYqD04rsZbxrpfyOV78D29+BbP4NRsiqdEHyyMhKZu2gVl/z5EibGn+BQ+yhe7NpI4rZyuHs1zLzcs9Lo8foEO0GIAGrrWqk+0UzOmBSyMrqXYT56AEq+C1/8OlwbGSvwCaHHIyB+6KGHHO/nzp1Lfn4+mZmZjm0/+MEP+mzUHuzaMZvNVFdXO96Xl5f32+BBRSlY+xs9d+uEnHBbIwwzVoy/iYUj5rC/9RiTE8cFFgx3nod1v9cXkLnpy46hEoIQbG6/OocbRi/k9Oa3yd65kZTy/4M7/gPm5XvunGqGzFEht1EQvPGnt6v55Z9fIzv+BAc6xnDvbTdz+4JJ8KOvgXkErHok3CYKYcQjIM7Oznb5PaT54E2o3gU/+n24LRGGKeNNIwMLhO3s/hjee0NfRGbsBYNulyD45KWnGPvTYsbabPrnuddA/i2e+0m+YSGCqK1rZcurJey49EmMmsKqNL77ahVf3DmJtI83w1NvQXJquM0UwohHQLxkyRIAGhsbKSsr44477qCxsZEnnniC4uLikBsYVNb+BqZeoiffFoRowWaD534HCUlwywrpHRZCx4mj8NNiXYN2Kt+Bsych02nlOXu+YWOAS5ALQpA4cnAPj2brwTCAUVP8JvVJDE/EwFe/B3MlDhju+Mw4vXTpUscqc2lpaSilKCoqCpVd1NbWsnjxYtatWxecAxzcC+++pv8hRNGy1IIr69atY/HixR4zVsNF0HULcLQGKl6ChUUy1CeKiUrtHt7nGgyD/vmE66x7GTc8dIlK3QI5CSccwTAAVojZqLCNGQff+UWQrRTCjT+69Zl2bc6cOWzdurXPbcEi6CldfvFv8MYGeOOQrOw1BIj0FEC+8DrBoy9+eTesL4Vn35dlxocAUaXdE0dh4UTXoNhggN+92tNDnJoOEyzBM1SICKJKtwDnjmJ7ZiIGurX7AahPQHv675B3Y3CNFCKG3vTis4fYYrFw3333sXHjRrZv3869996LxTJEnFxjPfzlj7DsLgmGhbDxp7erufh7f+Hzv3yTi7/3F/70dnXflerOwKtr9ZnQk2cE30hBcGbMeLh/DcqgD4VQBoM+oc4eDMfFw7iJYTRQEHyQPB7DNWtQLQaoAvUxaEu/JMGw4MBnQLx+/XosFgulpaWsXr2aESNGsH79+lDaFjxefgqsXbD0m+G2RBim1Na18p2nP8TW/XzGpuDuP3xEbV1r7xXLHofmRvjKtyE2NviGCoIbT102jok/WsA1d+Ux8UcLeOryLL1Axg0LEc6771dhW2uDTd2fR40Pr0FCROEzIG5qaqK8vJzKykoqKyvZsmWLYwWQqKarC579rZ6qasSYcFsjDFOqTzQ7gmE7Vpui5mSz9woA7e1QVgqXXw+XzAuugYLghaPtpyne9ShHzHG8PTmDI+Z4Vja8zFFrI4yZAAl+DvsRhBBz/NAnXPHooxi7/a4GfO53v+P4Ic+V5YThic+AuKioiJUrV7J//37279/v+Bz1bPyLPgHktu+G2xJhGJMzJgWDBuPiznJl6k7GxZ3FaNCwjE7xXemva+HkUbjtO9I7LISFfa212HCdVGdFsT+uAzL6kT5QEELEiX0fOYJhOzEKTu7fEh6DhIjD50p1Z8+e5frrr3d8LiwsZM2aNSExKqis/Q3kXSWTkYSwkpWRyGtfOsS82h85cmJ+kPUL3xPrbDZ49lGYPgfmy5g3ITxMSczCgMElKDaiMXmC+FMhshkz5TKsGi5BcZcGoyfPDZ9RQkTR66S6u+66i40bN7Jx40a++c1vYjabQ2haENixRV/q9qvfC7clwnDn3FHmH/9Pl5yY84//F5w76n3/t1+F/Tv1JxsxPu9jBSGo2JccN3b/6zCiUTrl/zE+SYafCZHN2ImzeO/uu+nqzrLapcH7d9/N2ImzwmuYEDH0OqkuNzeXsrIyysrKmDNnTkgn1QUln+vaRyBrElyzaPDaFMJKtObEpHEfKLd8rsoKjfu97//Hh2HiFFi4dHAMFcJOtGp3xfibOHjVWt7K/gEHL3mUFdn/EiILhUggWnULcOWKRzj96na2P/IEp1/dzpUrHgm+gUJEMKA8xNu3b+eOO+6gpqYGgJycHJ588klmzQrN3dSg5zg8dQxumAjf/5W+3K0wpIjGnJisnegaFGtG+OpBSHab+fzph3DrPLjvt3p2CWFIEXXatdPSDEm9jHkXhjRRq1thWNOvPMR33nknTzzxBHV1ddTV1VFaWsodd9wRNCODzvP/A6YE+NI3wm2JIOhB79Vr9CAY9N9Xl3oGwwBPl+gZUb4UxX9/wtBDgmFBEIYQPgcjKqWYPbtnokRubi4+OpMjn/Y2PX/rF78OyanhtkYQdC5eARcs1IdJpE32Hgwfroa3XoFv/hgSEkJvoyAIgiAMA3wGxPn5+SxcuJCCggIAysvLycnJ4aWXXgLglltuCY2Fg8HfnoXGOrj1O+G2RBBcSR7vPRC28/QvITFZhvkIgiAIQhDxGRDn5OSQmZkJ6L3F+fn5AFRXV6NpWmisGwyU0ifTXbMIJuSE2xpB8J/6M/DXP+srKsqTDUEQBEEIGr32EK9cuZLKykrOnj3L0qVLefDBB5k0aVIIzRsEPngTqnfCjx4LtyWCEBhrH9HXdP76PeG2RBAEQRCGND4n1S1dupSSkhLH4hzFxcUUFRWFzLBBS7u29jcwdRbMuXpwDBMiimhOAdQr7W2w/n/1JcZHjh0c44SIYshqVxjSiG6FaMQv3Sof5OXlKaWUWrp0qce2ULBo0aKBN3Jgj1IzUOrlPwy8LSGiGRS9DAKDZsefH1XqEoOuYWFIM+S0KwwLIkUvkWKHEB30phefQybmzJnDXXfdRU1NDRs3bmT9+vXMmTMnGIF78Hj2t5AxSu9lE4RowWqFPz0MV30BJk0NtzWCIAiCMOTxGRA//vjjvPjiiyileOONNygoKGDJkiWhtG1gNNbDX/4AX/8hxJvCbY0g+M8bG+D4YXi4LNyWCIIgCMKwwGdADLBkyZLoCoKdefkpsHbpM/QFIVpQCp5cDbMXwMzLwm2NIAiCIAwLeg2Io5auLnjud3DTcn2FL0GIFrb8E/Z+Av/zWrgtEQRBEIRhg88sE1HNxr/oj5xvuzvclghCYKz5BeRMhwU3htsSQRAEQRg2DM0e4j8/oqdZmza7z10FIWLY8wl8+CasXgvRtPiNIAiCIEQ5EdtD3O/cgju2wMeb4bbvBsUuIbIYUjkxn/oljJkAC5cNvmFCxDGktCsMG0S3QjTij241pZQKoU1+s3jxYl555ZXAK957G2x/D/62D4zGwTdMiEj6rZdIsePYIbgpB37wMHxVhvoMJ6Jeu8KwJFL0Eil2CNFBb3qJ2B7ifnHqGLz+Atz6HQmGhejimV9DciosuSPclgiCIAjCsGNoBcTP/w/EJ8CXvhFuSwTBfxrOwotPwvJvQWJSuK0RBEEQhGFHUALiVatWkZeXR0FBAQ0NDQGX94ddm8o4v/YhznzuWr2nTRCigRNH4aEfgM0KX/l2uK0RBEEQhGHJoAfEFRUV1NTUUFlZycqVK1m9enVA5f1h04+uZNpdS4lr7yCz4hU2/ejKAbcpCEHnpadg4UT4vz/C+fPwTxkHJwiCIAjhYNAD4m3btrFsmT5LvrCwkIqKioDKA2XnR68y/9VN2JNUacD8Vzex86NXB9SuIASVE0fhp8Vgs3VvUPDTlfp2QRAEQRBCyqDnIa6uriY3N9fx2X1IRF/lduypVOwsX76c5cuXe+x35uO/o7nlydAUnPnkdbhsUeAnIEQF69atc0mzE2kpgOz40i2H9zkFw93YrHBkP4wZH2QrhXAS9doVhiWiWyEaCUS3gx4Q5+TkuAS5ZrM5oHI7WVlZfqVSGTH7JpT2vy5BsdJgxKyFAVgtRBvuTs/ZIYYTf3XLBVPAYHANig1GmDA5eMYJEUHUa1cYlohuhWgkEN0O+pCJ3NxcXnjhBQA2bNhAfn5+QOWBMv2yRWxetADVPWZCabB50QKmS++wEMmMGQ/3r9GDYNB/318qvcOCIAiCEAYGvYc4Pz+fsrIyCgoKACgrK6OmpoaCggKqq6u9lg+UBb94l53/8ipnPnmdEbMWskCCYSEauGUFXLFQHyYxYbIEw4IgCIIQJoKSdq20tJTy8nLKy8sxm81YLBaqq6t9lgeCr+UZp1+2iKvvfGzI9wwP9+Upo/n8vdo+ZjzMvWbIB8PRfN0Gg2g+/2i2fTCQ84/O849WuwcLOf/Azz/qFuaQiyznH61Es+0DZTifO0T3+Uez7YOBnH90nn+02j1YyPkPg4C4P/TniwlFnVAJNlLPZbj/wfZFpOq2v3VCcYxI1fpwI1KvQ6T63EjV+nAjUq9DpOo2VHVCdf4SEIexzlASuTjnwSdSddvfOqE4RqRqfbgRqdchUn1upGp9uBGp1yFSdRuqOqE6f00ppfreLfRMnz6dnJwcj+21tbVkZWUF1Fak1olUu/pTJ9x2VVdXs3PnzoDaCga+dAvR950OZp1Itas/dQb7GJGu3eFyHcJZJ1Lt6q2O6DZ0dSLVrlDVCZVuIzYgFgRBEARBEIRQMCyGTAiCIAiCIAiCLyQgFgRBEARBEIY1EhALgiAIgiAIwxoJiAVBEARBEIRhjQTEgiAIgiAIwrBGAmJBEARBEARhWCMBsSAIgiAIgjCskYBYEARBEARBGNbEhNsAX8jqM9FVJ9x2RfqqSRB93+lg1olUu/pTR1aq65tovA7hrBOpdvVWR3QbujqRaleo6oRMtypCWbRoUUDb+9NWuOtEql39qRNuu/rTVjDozY5o+04Hs06k2tWfOoN9jEjX7nC5DuGsE6l29VZHdBu6OpFqV6jqhEq3w2LIxPLlyyOyTn+O0R8i9VxCdf7RSqTqtr91QnGMSNX6cCNSr0Ok+txI1fpwI1KvQ6TqNlR1QqbbgMPuEBHpd6XhYiifv81m019W/WW1WnteXVZVf7pR3frF21XjmWaPupHyvURDT2A4GMrn7q5bF+12WVX9Kd+6VSpyvhvxud4Zyuc/lH1upNgXLoby+Q/E5/b2vUTsGGJfDOc7XGVTLFu2DJvNBqp7m1Ke+ynXN8pLoXs1l3bsbeNtW2/tuG3rrR0vdvfGzvf3sXHdh0xLmsdj332Wm1dcxaXXTAuojXAzXLWrlKdu7dtd93N/05fe3NpxkZnrNvd2XN96163Xdvql2w9Et1FK2Hyup6S9tONFy+JzHQxr3Xrxuf7oFvrnc/2JFVzfRqbPHTIBsbIplFJomgYa+u8IRindXt1unN7bXz3nZP/dXN/C7MnzOHHwDCnpSeE+hT5RSmGzKWxWm9tLYXXb5vLZqY7VaqO1qY13Xtzq0u5rT7+DZeYEUjOTw3iGgeFLu9YuK5pBQ9O0iNct4KpTm6debW7l0aZbAJtN16lXjXbr09pl/+xd261Nbby9YYujzaGmW/s/W03T0AxRoFtfPtfF7yqUrWffaNOuUspTi2769PC3Lp/18tbm6Pe5PmOF7utujxOizefaPDTr6ZOjTbfQ7XO7urXoNW6wYbUqbFar1xjCZlMD9rkRGxDX1tayePFili9f7tedXldnF+2t5122aQYNDQ3N0B0gaxqa0x+B/b1j+wCCkr6CBJdAwRbYHQ/Ajs37eOuFD/Q7Kg0uv/ESsmeM9xpIevtHbfX1z93ZEdqcyrrbsHoJDHqcrdWlzOrF8QYLZVPUn2zkb2+8yrp166itrQ3asQIhUN0CtDa3u3x2aFDrCTY0XAOPHq066bkfQUmvN2Y270FCINjv1h26vekSsmdM8B5Idlk9bob6+kduD1ytfWnbXaMOfXvXdqDn6ff33a3b1Mxk1q1bF9XaPd/eSWdHl8s2b7rEi8+17zeQoMTd59r6CBICZcfmvbz1wocO7V62cCbZMyf06kfd/Wxvftk9CPWlXRe/2uXsZ70fK1gMFZ+rbIqWpjaXbT0+FMCuT7rjB/097hoeDJ/rI1YYiM/d8d4+3nre3eeO97hh93Uz5KnRXoJQXzdYvXUouNftPhZBkm4gutVUsDz/AFm8eDGvvPKK3/t3dnR6BMQDwcORdwclaM49t/0TrB2lFOfbO2ltbqe1qY2WpjZam9pobWqntbn7c3M75xpaaXMLmgI7GTAYDRgNBgxGAwaj1v2752V0+aw57etax+i1nobB0Ht7HtsMGsYYo6stBrc2u7e3Nbez9uf/5/LoRjNofOs3tzru+gLVS7Dojx3N9S2DaoP7jaBdy4MRJNixdll13XrRbkuz/v5cfeuAz81g8NSqQ092zcUYnD5703a3PmPctOnl78FT3576NBgNGGN6dOxL763N7Tz7i1d61S1Er3bbWzs8AuKB4CsoQTHgIMGOUor21vPdWtX9qzfttjS0Duz/iYaHlnSNam768tRNz749+vblZw1GzYdPdtWntzKjl78Ve52h7HNtVptHQDxQnDvTejraBtfndp3vcsQEDp/b/b61qY2W5nbONbTQ0jCwc/PwiQbvGvXUt2fcYIyx+00fOrT7zxhn/fmOG3z+vRj0stbmNv7ch8/tTS8R20McbpRSuiN2um1prm+h4XQz5pEpvT6G6Drf1eNonQTr6nx1AVs7rS51jTEGklITSExNIDHFxOgLMskca+azj2o8jnPtl+cxLnuET6dmtAcLhuhJJuLoKeq+OwdISDaRf+sVVDz3Psqm0AwaN3/jqqh5dBdqlE3punXqoPdHu8qmaGtp1wMDJ83qv9toaerRskewoOnXKSklgcRUE2mZKSSnJXoNiK9ddjljs0f6dGrO26LhcSa46lb/pZGYksD1X7mCN9eJbv3BEegGqFuA8x2dPUGtQ7vOQW67Q8/uT65i42NITE1waDd9VCpd57vY9UG1x3GuWz6vR7teb4Z6AtdowR68gfjc/uLwud34q1ur1UbbuXav2m3p7hiza/d8e6dLXc2gkZhicmg3c0waaSOS2bv1oMdxrl12OWMtI312OjnHDdHscxNSTAPyuRIQ+4n7o99pl1kwj0qlzRHkdt+1Nbdxvs1NuFqPcBNTTWSMSSNrymg98E3Rg9+kVL08zhTrIcjm+hb2bKlxvevRNCZdPM6v8UHeHJ7e++3Yo3s/HBudi5zrONpztN3zRnPb6Hwavmxwb88Xl914CRfNtVB/spH00WnimAPAXbtTZk8kNTPZJUhobWqj9Vy7Rw9GXEJsd6Cga3fEODMJKSYP7SYkmzAYXYOA5voW9m8/5Knb6Vn+6xZcdePQTE+BswYdW73W8a7bnjo+dOtHe764/KZLmHaZ6LY/uOv2ojkWzKNSXPytXbud5117qg1GA4mpJod2R45PJyl1nEOziamm7vcm4uJjPY7dXN/C7g+rPbQ7cVqQfa7XOq468+6nNdzl6NsG/wIe8bn9w123F8+bTMbotJ6nvk5PI9rPdXjUNyXFO7SbYk5i9AUjHPFBYkq3v01JICEp3mPIRnN9C/sqDw6Kz/X8P93zwfv/ffuvvn1un7GCTxuC63MlIPaD2uqTvPncBz0bFOz+sIZ4UyxJ5kQSUxNINicwakKGo2dXDxR0h2tKig+ox8B5mIbBoJE51szC2xfw+jObHXc9N96+gDETRwzI4UUbqZnJ4pQDoPN8F1Wb9rDp5W09GxXs23aIZHMCyeYkElMTGDNpRM8Nm7N2U0zExAXmIuya1QwGMseYueFrC3hjrRfdQr8dXrQhug0MpRQHdhz18LmfbanBlBRPclqi/hRiZArjckY5dTb06DY+MS4gLTn7W018rgPRbmCcPlbvodtd7+8nJj6GZEcngon00WmO+EAPcnX9JqSYMBoDe7pgMBj0IRsGTXxuN/3VrQTEPrBZbRzYcZRPN+3lyGfHve7z+eJrGD9lTEDt2sca2R2vQ8xO27wJNC9/BlNmT5K7daFP6k82UrVpL7s/rKGjzfs4yBu+tiBg7dq16qxTdx27M6dgBlNzRbdDjnNHMZzciWbKRiUGtqSqLzo7OtlTeZCqTXs5faTO6z43r7iqXz7XfpNmsM8HcdOx+FyhvyilOHHwDFXv7mVv5QGv+yxeeW3gunW+SXO5YTO4bHNHfG7/kYDYjXMNrex8bx873t9PS0MrYyaN4Mov5bHpL5UejyHSRqS41NWDAlwcr8PpGgY+rkzu1gVfWK02aj49QtWmvRzdewJTUjzTr5hM9swJvPTIP1A4PbpCuWjXvXfMYDB0Z10x9HqT5i+i2yHGrqfg7WLilI1YDHRc9js6c27vd3NnjzewY/Nedn9Uw/n2TiZdnMWsWz/Hm8+976fP9RY0+L5JCwTRruCL8x2d7NlygKpNezlTW09qZjK5n7uAyk0HUFrP/3pNWTFrrnMpPDXrqWPxuaFHAmL0AfFH9h6natM+aqqOEBNj5MK52cyYP5VREzIAfSzlxnUf6rmODRoLvzafUeMzBs3xCkJ/aK5vYcfmfex8fz+tTW2MtYzkhq/NZ/KlE4mJNaKdPMpNR5/l71nLUZoRTVm5qfZ5RsffjJY2ot8pr4Rhyrmj8HYxKH1imoaN+C3foWtsfkA9xdYuK9WfHObTTXs5tv8UCSkmLllwITPmT3H8I1dKsfH5Dx2Pfhd+bT6jJmQOyk2aIPSXM8fqqXp3L59tPUBXRxeTZmRxxeLZTLxoHDHb32H088/y2vivOPztzUefY1TnRZAyfVA6xoTgEbEBcX/yuQZKW0sHuz+oZsfmvTScbiZjbBpXLZnLRXOziU+Ic9l3xhVTuXCiiaY91aRfPJXUi6YExSYhMKI9l2t/UDbFod3HqHp3Dwd31RITa+SiWVnMzB3HiBEm6OqC2mqwdmH49D1mn91MTtNO6uNGkn7+NKmdDXDsAGRNDIp9gn9EpXYb9zmCYTuasmJorsbqR0DcdPacfgP3wX7amtvJmjyaG/91ATmzLsAYY3TZd+b8C7koO4HG3fvF50YQUanbAdLVaWX/9kNUbdrL8ZrTJKYmcOnVFzHjiimkZPRMVlOmRGbVvYeleVePv7U2g+VCcNO3EFr80e2wy0PsGO+zaS/7th1EAVMuvYAZ86cyLmeU114HzaCRWP4shp99E2w2MBjg/jVwy4pATkkIItGaExPc8hArpQe0XZ36b2sndHaCVU8rtXv7Mao+PUlT43lGjDAxc8YILpxqJi7Oi7NtaSLpf+/FsGe763aDEV4/CGPGB3x+wuATVdo9dxTWTnQJipVmpGXxLp89xDabjUO7jlG1aS8Hd9USFx/LtMstzJg/lcyxZq91jDEGEl5/Fu1nK8XnRihRpVsnAslD3Him2XED136ug/FTxzBzwVQsl0zwmPxmqN5Bwg+/hNZ5Hq25vlu3Rri/VHQbQUgeYpzG+2zey5mj+nify2+excXzckhMSfBZz2A0kNhyBs0eDIP++6cr4YqFElQIA6f2IHSeB2uXHgQ7oZTi+PEWqnacZd/+RjQNpkw2szD/AsaMSfT52Fg7eYikx+5BO9ekO+O//BFs1h4HLboV+kPyeLh6Dby9EpQVpRnpmPtbr8Fwa1MbO9/fz4739tFc18LICRlc9+V5XJg7idgYDaxWaGvRf1utuv6tVmIMNkxNJ9H+e2VP4C0+VwgRNquNAztrqdq0l8O7jxGfGMe0y3OYOX8K6aPTvNYxbnubhB8thwk5aP/7mu7Hj+yHCZNFr1HEkA+Izx6r59NNe/lsS/d4n+lZXPGF2UycNq7Pcb/GGCMJyfFon+3vCYbt2Ky64EXswkA4dxTj8bewxU9AxY1ybO44b2XPnnqqqs5ytq6dtLQ4rvjcGKZdlEFCQu9/tjE7P8S05r/Q0kfC6rUw/0a46yfioIXB4eIVcMFCzp/cxfm4C1DxY6C9DWxWVGcXtTWnqPrwENW7T6IZNC6cNpIZN2UzepQJzXYeDu322XRsrAET52HDEx5DM8TnCsGkpbFVv4HbvI9zDa2MnphJ/q1XMDV3Yq/pJ2Pe3IDpgWLIuwrtkZcgqXvip+g06hgyAXFzXQsnDp/FPDKFhGQT1Z8cpurdvRyrOeVzvE9vxMbFYEqK1z9cMEXPHO08usRg1IMLQegvu56i6Y17qGsbQbrpDPFTVnJM5VO14wx79jbQ1WXDkp3GlQvGMWFCct+TiJQibuN64l74HdqlV8C3fw45F0NsrO6cxUELg0RTh5kTBzNIVidJSa6no8PK7s/qqNpxlvr6DtLN8cy/YizTLkrHZOr+N9PZ6btBpTAd20fsu/8H772h9xy7Iz5XGAT21pym6tOjTM4ZSc4FGRzde4KqTXup+fQIhhgDF+ZlM/PKqYyakNlnW7HrH8P02L2oz9+G9rOnIDauzzpC5DIkAuLt/9zNa0+941jfPiY+hq6OLsZPGc1N37jK63if3ogzxbpOqjNnQnwidLTqQbE8dhYGyrmjbF//B17b/zMUBsCGecdZGjr2kpQUw+xLRzJjeibJyZ6raHml8zym5x4idtNfYdFXYfm3IDkNMkYG9TSE4Ye7vx07NonTp9uw2fQbuGuuzmJ8lh83cACtzcR+9Abxm15FO7QXMkbDzV+BqxdB9Q743X/JUB9h0Pif0nc4++4uDMAewBAfi+roJGNMGlfeMoeLLrN4TKj3is1G/P/8iLj1v0OtWIV292rX5daEqCTqA+Kms+d47am3XTpvuzq6+NK3C5gwNbBE2ACmxDhi3Zfy/L8/6sHwn97RxwbJY2dhgDQd2sVr+7/SHQwDGGjoGEH+PCsXzr4EozGAVbaa6kh4/EcYDuyC//cTuOoLunMeJ1kkhMFF97c9wTDA8eMtzL50JLmzR5KU5McNnFIY939K7LuvEFO5Ebq60HIXwLL/B5d+DmJiYcwEuHYRfOGrMtRHGBT2Vp92BMOgL9Rm6+jkc1+ex9wrJvufxu98B6bVK4nZ+CLc9zu0r3wrWCYLISZiE+LZU6msW7eu1/3qTjbiLU9Gf27WEpJNnsGwUvDMb2DBTTB7Acy9RhxzBLFu3ToWL14ccSmA+tRt+yinYNiORtqIkQEFw4Yj+0h64A4Mp46g3b9GD4YBRo2DeFOA1guhJBq1q/tbT4ebPSm1z2BYa64n9o3nSPzxV0h88C6M+z9FfWkF2u//Bj94GHIX6OMvLdMgvXup2THjxedGGNGoW4DP9pz04nGh7rzN/2D4XCMJP/wSMe++ivZwGUgwHDX4o1u/eogXLlzI66+/PmiG+UNWVpZfqVQyRqfpqnb20RoeKxr1hqZpJCTHe+TBBGDT3+HwPvjJGr/bE0KHPffk4sWLw20KEIBuJ00G7X1QTo5YU6SOGO33sWK2vY3pqZ+iZU2C7z8EI7qfiCQkQqb/7QjhIRq1mzE6DU3TXIJiTYM0s4/HzDYbxs8q9d7gj98GTaNr9lWcv+37xF96OQZnnztijH4jJ4+eI5po1C3ARReO5hNcewFtwGTLCL+Oo505TsIPv4Th1FG0NeWQd2W/7BXCgz+69QiIDxw4QE5ODunp6WRkZKCUoqamhsmT9UcK+/btC6rRgdKU1MZf5n3M4g9mYVAGbJqNV+d9wpKkm0ih7wl0BoOBhJR436vH/OFXMGUmzLl6kC0XhjO6bre76XY7SxKzSaGPMWxKEfe3PxL/f0/AvAK46/6e3mBNg7ETJagQgkJqZjLmBdMcj55tQOqFI0hJdtWs1nCa2M1/I3bTXzGcOYZ17CQ6lvw/uubdiMGcQUKCsadXLiYWxmf3zM4XhCAwNWckmVde7Krdy6cweWLfk+cMBz/Tcwyj0J7ZBJOnB91eIfR4BMTZ2dns37+fb37zm9x7771cd9113HDDDbzxxhvhsK9P9rXWsnXKAfaOO0FmcxJnU1poSmqjpv0EWXG93/kZYwwkJJl8p1/bvxO2/BN+/kcJMIRBxadubXVkGbznugSgox3Tn35B7JY3oeibeo5hZ21mjtZ7iAUhCNTWtXLfe0exdHVyYWc9e2LTObDvPDfO62JcAhh3fKD3Ble9DzExdM25nvYVP8aaMxM0jZgYAyaTUzCcatZv4GKifjqLEAX8v5VXse9zadR88injplzEpAsv7rOO8dP3SLhvGYzOQvvfv8vwnSGMVy9ksVh44403+OY3v0l5eTn19fWhtstvpiRmYcBAU1IbTUn66jNGDFhMvU+oi4k1YkqK733s0B8ehIxRcHNwloMUhi9TErPQ0Fx0a1AaFkOGzzpa3SkS/udeDCcOwvdK4PLrXXeIi4eRY4NotTDcqT7RzG1n/slvDz+JEYUVjZ+MXUbMyzEkffoPDA1nsF4wlY7l36PzshsgMdlRNy7OSHx89xAJg0GfOJfu3+NqQRgUdj3F5M3FTFE21DYDHTG/ozPndp+7x7zzCqb//gZcMg/t0Zf1GzhhyNLrpLrHH3+c66+/nvT09FDZEzDjTSNZc/HdGLtPxYiBRyfd1WvvcGx8DAnJpt6D4brT8Pfn4cv/JrkFhUFHa00i/oPPga1bgzaN+A8/h9bqfZiPoWYniQ+swHCuHu2nT3kGw6BnlfA19EcQBoEphiZHMAxgRPHfx59n0gcb6Jp1JS3/+TSt//VHOq+5xSUYjo93CoYTEl0nzglCKDh3FN4uRute8EXDRvyW76C1ep9kFfvyGkz/dStcsxit9B8SDA8D+nxOddlll/HGG2/Q1NREampqKGwKmBXjb+K61EvZXX8Yi2lMr8FwfEIccSY/UgOte0wPLpb/2yBaKgg61Seaidk/lcRjWdhSmjA0p2JoTeLg9E7GJbv+WcZ88A9Mf/olWC5C+/df6Xmx3UkfIWMwhaAztukorjOY9TnNHd/8BdaZn/OsoEGCKYaYmO4bNZk4J4SLxn0eqx9qyoqhuRqr89LjShH3xE+J//NDqNvuRvvhr6WjYZjQ51W+8847XX5HKuPjR3Bl6oxeg2FTUrx/wfD5Dnjhf+Hzt3oPPgRhgOSMScGggaE1iZiTYzG0JmHUYFKakz5tVuI2/J6Ep/4b5i9E+6/HvesxJhZGy7g2IQRcMMUjOFAGA7asHI9dNU0jMaE7GI6JhUlTYXSWBMNCeEibApqbdjUjthQn7XZ1YnpgJfF/fgh+8BDaqkckGB5G+H2lveWeDCb+5hb0Bz2tmonYXtYjd+Gvz0L9afjXHw742EJwidacmFkZifz2G5dj7J7QadSg5OoRPb3DbS0kPLaKuDfWwVe/h/bNH/seujP2AjB6SRkoRDRRqd0x4+H+NfrKcejBcMdtq1AZo1x2Mxg0EhNj9BVCU9P1JcTlCcaQICp1C5A8Hq5eg9K6tasZ6Zj7W5S9d7i1mYR7i4h5swxKnoPbvx9ky4VQ4o9uNdVHpLts2TJeeOEFli5dyvr16wfdSF8sXrzYr9yCdjo7OmlvPe+xXTNoJCabMPi7dLNS8KUZMCoL1kRmZg3Bk0D1Eil21Na1suOtD5iUFusIhrXTtST87h4MDaf0JUEvvcJ3A6npMMEyULOFMBKV2j1xlPMfvs352GSPYNho1EhIiEEzGvWbNXnKNiSJSt0CtsbDtB/fiS0lxxEMa3UnSVhViOHofrRH/wKXXxcka4Vw05te+uwyDXXP8GBiMBpISO4lx7A3PtwI1btg1SNBs0sQ7GRlJJKaleD4bPyskoTHfwTJaWg//xNkTfJd2WjUZ+oLQqgZMx7bzHmoU6dcNjvSqiUmwXiLnvlEECKJ5PFYR/fcpGlH9pP4gy+idXag/elduHBWGI0TwkmfAfGyZctcfkcLxhgjCcl9pFXzxh9/pc+AnpcfHMMEwQex/3yZ+Od/jZqWh+G7qyG5l3zEoAfDsX6MiReEEBAba8BkipGJc0LUYNi1lcR7CyF9BNof/6ln6hGGLb0GxE1NTSxZsoSDBw8GHliGkZi4GEyJcYHbfHAvbH4dfvKkOHMhNJw4inHnR8R88A/iPvgHthuWYrj938HYx71qcqo8ihYihvh4I3FJCfoTDRkrLEQyJ49i3L0D7eRRTL/5Hlx0Kdpjr0Ka7xzwwvDA51iCu+66i9WrV9PY2Eh+fj4fffSR373Eq1atIi8vj4KCAhoaGjzKNU0jJyeHnJwcVq1a1W/jvREXH0tCXwtu+OKPD4F5BHzh1kG1SRC88tJTsHAiiY98l9gP/oHtypsxfOOevoNhg0F6MoTIQAOTyUjciBEycU6IfF56Cu2mbBK/+3lMq1fCpKloT1RIMCwAvQTEW7duZfXq1TzxxBOsXLmSX/7yl36tWFdRUUFNTQ2VlZWsXLmS1atXu5TX1NRQWFhIdXU11dXVlJSUDPwsuolPiCM+sZ+LaDTWwV//DMvugnjToNkkCF45cRR+Wgw2e5J4MGz+B5w92XfdUVmyWIwQdjQNEhLjiJ2Uo0/slEwnQiTT7XM1J5+r7a2ChrPhtUuIGHx2RWVnZ/Pkk0/y+OOPU1FRwZtvvulXg9u2bXP0JBcWFnoNiBsaGigqKiIjI4OSkhLMZrPfBh8/fpzjx4+7bEtPT2fSpEl0dHSwbVuVR53c3FwA9uzZQ0tLi0vZpEmTyMjI4PSTD3PkXCdcfBVs2wZASkoKU6ZMwWq18sknn3i0O3PmTGJjY6murqaxsdGlLCsri9GjR1NfX8+BAwdcyhISEpg2bRoAH3/8scfExWnTppGQkMChQ4c4e9b1j3X06NFkZWXR3NzMvn37XMpiY2OZOXMmAFVVVXR2drqUT5kyhZSUFGprazl50jXwyszMZOLEibS1tbF7926XMk3TmD17NgC7d++mra3NpTw7O5v09HROnjzpkdIkLS2NnJwcOjs7qaryvDazZs3CaDSyb98+mpubXcomTJjAyJEjqaur4+DBgwCMHTuWsWOjc3liF+3u2AItNtKNkB0H7TbY1WaD9zbrPW3d5F58EQB7Dhykpa1dv1lrBw4d7dHu6dMcOXLE5ViiXZ1I0e6Q0W037Yk22hNauGD0eJpqDgGHXMr98rmi24jXLUSvz/XQ7Y4tpLfbevxtB4AVyl+D6XMA0a2dYatb5YOGhgb1q1/9Sn388cdKKaXuvfdex/veKC4uVuXl5Y7PFovFpby8vFyVlJSo+vp6VVJSogoLC722k5ubqxYtWuR4Pffcc0oppe6//36FvlSS43XrrbcqpZTat2+fR5nzKc6bN8+jbO3atUqdP68em5LqUXbDDTcopZRqbGz02u6pU6eUUkotWrTIo+zhhx9WSim1fv16j7LZs2c7bIqLi/Mo37Fjh1JKqRUrVniU3XvvvUoppd566y2PsqysLEe7WVlZHuVvvfWW41q6l61YsUIppdSOHTs8yuLi4hztzp4926N8/fr1SimlHn74YY+yRYsWKaWUOnXqlNfvsLGxUSml1A033OBR9thjjymllFq7dq1j2/3336+UUuq5555z0Udubq5XHYUaX7pVyod201BqBmrfFM/vBlBqx1aldmxV82bN9K5dpdRjjz0m2lWRrV27bpWKPu160y3XjVW8XqC0pxd41203Pn2uEt1Gg26dtTsUdPsVcx/+thvR7VtKqeGnW595iLdv384DDzzgGIurlELTNF544QVvuzt48MEHsVgsFBYWApCXl0dlZaXP/dPT070OxfCVK85XD3F2djbt7e3s2rXLo06fd33v/Z3TP7yNIw88DxOnOMrkrk8nGu76oiEnpod2N/6F9Kd+QXaMjXY0dt30DZh7rUsdlx5iUzJkjHSUSY+FTjRot7feikjXrrNuT3bU8/lt/4VKMcKYBDhvxXCojb/m/ozR8emOOtLTphPtuoXo9bnu/vZkRz1/KruLP1fso8sKn56H1fkWir+2xqFd0a3OcNWtz4B47ty5lJSUkJeX52F0b1RUVFBaWkpZWRkbNmxgy5YtLuOEH3zwQcxmM8XFxWzbto1Vq1ZRXl4ekNGDilKwNA9SzfDUxuAfTwgKke6cfXLiKLzzNz2FWuZo3/vFm/ShFJL9ZMgRTdp9q2471229x3P7nF9xTcasYJkmRCDRpFvo0W5WQzuTz7Syf0QitWaTaHeY0a+FObKzs7nuusBXa8nPz6esrIyCggIAysrKqKmpoaCggOrqaoqLiykqKqK0tNRRHla2bYLPPob/eS28dgjDkzHjHePXemXcJAmGhbAzJTELAwZs2BzbjBiYnDgujFYJQt/YtVtrNlFr1ifOi3YFZzwC4oceesjxfu7cueTn55OZ2ZPv9Ac/+EGfjdqDXTtms5nq6mrHe289wmHjjw/pwyTmLwy3JYLgncxRkJgUbisEgfGmkay5+G5W7noUKzaMGCi9+G7Gm0b2XVkQwohoV+gLj4A4Ozvb5feQ5kgNvP0q/Of/6LldBSHSiI3T06wJQoSwYvxNLBwxh/2tx5icOE4CCiFqEO0KveEREC9ZsgSAxsZGysrKuOOOO2hsbOSJJ56guLg45AYGlbWPQIoZFn0t3JYIgnfGTZSbNSHiGG8aKcGEEJWIdgVf+PxPu3TpUscqc2lpaSilKCoqCpVd1NbWsnjxYtatWxecAzQ3wl+ehqKVkJAYnGMIQWfdunUsXrzYY8ZquBhU3Zoz9SWahSHJkNauMGQR3QrRiD+69ZllYs6cOWzdurXPbcEi6DNY//QwPHIfvH4QRsmg+mgn2mY8u7DTS1rCmBjIma7/FoY0Ua1dYdgSKXqJFDuE6KBfWSYsFgv33XcfBQUFZGRk8Pzzz2OxWIJmZEjp6tKHSywskmBYiEzGXCDBsCAIgiCECJ9DJtavX4/FYqG0tJTVq1czYsQI1q9fH0rbgsebL8PJo3B73xkzBCHkpKRBWnrf+wmCIAiCMCj47IJqamqivLycbdu2ObYdPHiQSZMmhcKu4PKnhyB3AUybHW5LBMEVoxHGXhBuKwRBEARhWOGzh7ioqIiVK1eyf/9+9u/f7/gc9Xz6IVR9JL3DQmQyKktPtSYIgiAIQsjwGRCfPXuW66+/3vG5sLDQYx3tqORPD0NWNlz9hXBbIgiuJCZDhqQDEgRBEIRQ0+ukurvuusuRam39+vWYzeZQ2RUcjh+GN1+Ce36jP5oWhEhB0/Scw4IgCIIghJxeJ9Xl5uZSVlZGWVkZc+bMCemkuqDkFnz2t5CQDF/8+uC1KYSVIZMTc9Q4iDcFxyghIhky2hWGFaJbIRoZUB7i7du3c8cdd1BTUwNATk4OTz75JLNmzQqOtW4Mem7B1nNwfRYUFsP3fzV47QoRQaTkouyXHTW7IfsivZdYGHZEtXaFYUuk6CVS7BCig9704rOH+M477+SJJ56grq6Ouro6SktLueOOO4JmZNB5+Q/Q1gK3fifclgiCK2MnSjAsCIIgCGHEZ0CslGL27J60ZLm5uZE9qe7cUah9S//tjtUKf34Err8FxkwIuWmC0CuydLggCIIghBWfk+ry8/NZuHAhBQUFAJSXl5OTk8NLL70EwC233BIaC/1h11PwdjEoG2gGuHoNXLyip/ztv8LRGnhQxhgJgiAIgiAIrvgMiHNycsjMzAT03uL8/HwAqqur0SLp8e65oz3BMOi/314JFyyE5PH6tmcehkvmwczLwmenIAiCIAiCEJH02kO8cuVKKisrOXv2LEuXLuXBBx+MvJXqGvf1BMN2lBUa9+sB8a5tUPkuPFwWHvsEQRAEQRCEiMbnGOKlS5dSUlLiWJyjuLjYkZM4FPidSiVtij5MwhnNCGmT9ffP/FpfCve6LwbFTiG8SAogIVoR7QrRiOhWiEb80W2fk+rswyPy8/NDOqkuKyuLV155heXLl/e+Y/J4No/9OV1KP5UuZWDz2J/pvcOnjsE/XoBb74YYn53hQhSzfPlyXnnlFbKyssJtChCAboVhj2hXiEZEt0I04o9ufUaJc+bM4a677qKmpoaNGzeyfv165syZExRDB0JtXSs3vzyRMbGPYDGdpKZ9NCe3jGDnVa1krXtMX+zglhV9NyQIgiAIgiAMS3wGxI8//jgvvvgiSineeOMNCgoKWLJkSSht84vqE83YFBw7n8mx85ndWxUHD58ka32pHgynpIXVRkEQBEEQBCFy6XUcwZIlSyIyCHYmZ0wKBg1sTqM5jAaNi7f/Fc416MMlBEEQBEEQBMEHPscQRwtZGYn89huXYzToY52NBo1Hb59D+ou/h2v/BcZnh9lCQRAEQRAEIZIZEjPNbr86h/yZY6k52YxldApZO/4JB/fAT58Mt2mCIAiCIAhChDMkAmLQe4qzMrqXwH3m13BxHsyeH16jBEEQBEEQhIgnYodM9Du34N4q+PBN+Nq/QyStqCcEBcmJKUQrol0hGhHdCtGIP7rVVCiTCwfA4sWLeeWVVwKv+ONvwOY34B8HIDZ28A0TIpJ+62WI2iFED5GimUixQ4gOIkUvkWKHEB30ppeI7SHuF2dPwd+eg698W4JhQRAEQRAEwS+GVkC8/n/BYITC4nBbIgiCIAiCIEQJQQmIV61aRV5eHgUFBTQ0NARc3i8O74dnfgMFhZCWPjhtCoIgCIIgCEOeQQ+IKyoqqKmpobKykpUrV7J69eqAyvvFS0/BF6bCuUb465/1z4IgCIIgCILgB4MeEG/bto1ly5YBUFhYSEVFRUDlAXPiKPy0GOxzA5UNfrpS3y4IgiAIgiAIfTDoeYirq6vJzc11fHYfEtFXuR17KhU7y5cvZ/ny5Z47Ht4HNpvrNpsVjuyHMeMDtl+IDtatW+eSZifSUgDZ8albYdgi2hWiEdGtEI0EottBD4hzcnJcglyz2RxQuZ2srCz/UqlcMAUMBteg2GCECZP9N1qIOtydnrNDDCd+61YYtoh2hWhEdCtEI4HodtCHTOTm5vLCCy8AsGHDBvLz8wMqD5gx4+H+NXoQDPrv+0uld1gQBEEQBEHwi0HvIc7Pz6esrIyCggIAysrKqKmpoaCggOrqaq/lA+aWFXDFQn2YxITJEgwLgiAIgiAIfhOUtGulpaWUl5dTXl6O2WzGYrFQXV3tszwQfC7POGY8zL1myAfDw315ymg+/2i2faAM53OH6D7/aLZ9MJDzj87zj1a7Bws5/8DPP+oW5pCLLOcfrUSz7QNlOJ87RPf5R7Ptg4Gcf3Sef7TaPVjI+Q+DgLg/9OeLCUWdUAk2Us9luP/B9kWk6ra/dUJxjEjV+nAjUq9DpPrcSNX6cCNSr0Ok6jZUdUJ1/hIQh7HOUBK5OOfBJ1J12986oThGpGp9uBGp1yFSfW6kan24EanXIVJ1G6o6oTp/TSn7ihaRxfTp08nJyfHYXltbS1ZWVkBtRWqdSLWrP3XCbVd1dTU7d+4MqK1g4Eu3EH3f6WDWiVS7+lNnsI8R6dodLtchnHUi1a7e6ohuQ1cnUu0KVZ1Q6TZiA2JBEARBEARBCAXDYsiEIAiCIAiCIPhCAmJBEARBEARhWCMBsSAIgiAIgjCskYBYEARBEARBGNZIQCwIgiAIgiAMayQgFgRBEARBEIY1EhALgiAIgiAIwxoJiAVBEARBEIRhTUy4DfCFrD4TXXXCbVekr5oE0fedDmadSLWrP3Vkpbq+icbrEM46kWpXb3VEt6GrE6l2hapOyHSrIpRFixYFtL0/bYW7TqTa1Z864barP20Fg97siLbvdDDrRKpd/akz2MeIdO0Ol+sQzjqRaldvdUS3oasTqXaFqk6odDsshkwsX748Iuv05xj9IVLPJVTnH61Eqm77WycUx4hUrQ83IvU6RKrPjVStDzci9TpEqm5DVSdkug047A4RkX5XGi6G+vnbbDb9ZdVfVqvV8ao/3ahu/eLtqvFMs0e9SPleoqEnMBwM9XN3162zdutP+datUpHz3YjP9c5QPn+Hbn343IbTTVHrcyPFvnAx1M+/vz63t+8lYscQ+2I43+EqpVi2bBk2m617Q8921/08PygvhW7VXNuxt93zxrUd57aVWyXnbe7t9GJ3b+x8fx8b133ItKR5PPbdZ7l5xVVces00v+tHAsNVu0opvrzsy33qVt/m/sZTu95k42irN715HMRTu+66dWmr37r9QHQbpSibk8911kQ/fK4/utXfDrLP7cXu3oh2nzusdTsAn9u73lyP4dK2Hz7XtR3vPndwYoX++dwhExArm0IphaZpaAYtxFb1D7vNtu7f9s/6C9fPNkVzfQuzJ8/jxMEzpKQnhdt8v1BKYbPaul8Kq9WGzWbD1qVvs9rLbM77OW23KlqbWvln2RaXNl97+h0sMyeQmpkcxrMLDF/atVltoKFrV4t87brr0qtelULZ9GvVVHeOSydfHnW6Vd2atLrp8/+3d+bhbVVn/v/eKy/yLtvZHGezFGcjIUS2SYAQoEhsbdwpseKmTEtLsFVmoZ2ZThy3ZQJdCHbLTEvbKXagM/OjJWPLMAOd0oIUQiCstkzAIYsd3Thkwwm25X3X+f0h32vtlmzZ1rXfz/PosXTPPfeec/XV6/ee+573jAyLmnV4a9vl1dPZhzdMH7gZ9Vml29F/thzkYXPdNQv/NtdlmyxtrsPFzrro092uutpaF9s7Wqenow9HauRtc/36CqPfO8dxkt2NdALZXIenjkd9BTnaXE8/wJ9tdfvsUmeyNjdiHeKLFy8iPz8fu3btCupOb3hoGP29g27bOJ4bdTJcnA2X9xzPgXPZbzJOSahOQih3PABw/J0mHP7v95x3Uxyw+e6NUG9Y4teoSf+0JSPnyyAyjIyMSGVuL4f7Mb0NqUuZw2Xb8AhGXATKHKH1M5Tr3d7SgT+99kccPHgQFy9enJLzhEqougWAns4+t89j+gQw6mw45Tn2HpyLtnluwk7JRJyEUBDv1hkDOA7YfM9GqDcsDWjURobd/5mP+NPnsIvuHN43UoG0O+Lw3OZddyoQdZucnoiDBw/KWruD/UMYGhiWPnvZV19218PmTsYpCdVJCJXjbzficNX7Ljb3WmStXxrUzZCnnXWtMzIyOiDg8F3XTaMudtzNzgbQbqi/0WCZLTaXOZi3zZVsqKhjd/2K7zGVNjdMvoKnzb1e9BUCDDr5u1kS6/jXt8cxXXwNx7DDh5314TcMj51rKghFtxybql/PJMnPz8fLL78c9P5DA0NeDvFk8OeUAHB3dB2TM0BDA0Po6exHb1cfejv7nO87+0Y/O993dfSgt6N/0v3hFRx4BS+9FC7vxTIF775NoVB41Rury4EfLZeOxXscL8p1m2ddX+3gwfOc2/be7n784acvuz1u4XgOf/dv90l3faHqZaqYSDu62nvC2gZXZ2PMkANgY3fhE3USRBwjDvR197vptadzTLM9XX3oae9FR2v3pPvDe+qF58FH8e6fg9G2m0Y5KKJGte2hT+e+Y9r2Oh7v0pYo12O6a7u3qx/P7/9jQN0C8tVuf++Am0M8WfzaXIZJOwkijDEM9g952VpP7Xbb+9DfPUmb66oTl/d8lLed9addhV99etd136YY1bCnXR49ZpTCy87yHtqdrTZXHEkMF/5uBMF5+AqTtLnDQyPo6+p316uHdrvsPehu751kh+DhCwT4Xy36CeK+Ubzfur605u03uNpUX3V9aNvl1dvZN67NDaSXiB0hnmkko+syUNTV3gP71S6o5icFfAwxMjyC3q5+56tTFOyYgHs7+9Ez6gB7/kPheQ7xyXGjLyXSM1OhWpCE03XNXue5bef1WJQ1368jyY86owoFL4tHmoDLSJH0x3k9bv/ajTh08F3noy6ewz0PbJPNo7vphjmYexwWgtMuYwwDvYNjeu3qd9OuqNnern70dfd7BJsByvgYSbtJqnjEJSp9OsS37szDohXz/TqSrhqWnt7IAFftcuCQkBxPug2Bydjc4cFhd726abcPPaO2uLezDyPD7qP/imgFEpKUknYzVszH0OAwTn0geJ3ntsLNWLRiXlA3XbK2uUlkc4OFMea8aXMxiN1nbOg8fQbJq1cicaXvvPSAM+yov3vAqVVRo360O+A54McBcYlKJCQ5fYWU0d9IY3uz13mcNneBX0eS590HCOSCNNiDUZs7Sd2SQxwkro8hwAHrNq9E6sJkt9HcntG//T0D7pU5IC4hVjK4yemJWJQ1D/HJcUhIjkO8izFWxsV4GdKu9h40Wpvd73o4DivWLwkqPsiXwZPeS6caGwEX33CedUY/ezoo4iP8sTqcx7HHa8P4/zg2330t1l6vRntLB1IXppBhDgFP7a7KyUJKeqI0GtbbOWaIPUMFomOjED9qcOOT45A6P1l676rduEQloqIVbnW72nsgfPSpl26z1i8NOq7N08mU3rvo1rkf3DXoo47b8QA3vXMeG720G8TvwBek24njqdu116uhWpDsNpIrvh/sH3Kry/GcpM2EpDikL0rB0uxF7tod1W+MMtrru+xq78HpWsHb5l6TGSab66EzfzZ3HN2O1SGbGymcevq/YD4OMI4H/vwZNiw9itTN13s9hejt7EdfV7/X047YuJgxnSbFYV5m6qgNdtphUbtxCbHgFe7Oa1d7D5o+9PYVQra5Pu2dtMfofvCvW6nOOL7C6EZPOc6UzZ09DnHPBSiunIQjaSVYfGgrmozHJeEKDj3/3tgGBpx47wyilVFITI6XhJqWoRoT7KiAE5KViEtUegl3PMQRBp7nkL5IhTu+sRWvPfe2dNdz1/1bsWj5POfOEzR4ciM5PZGMcggMD42g4Wgj3nqxbmwjAxrrziI+RYmklATEJ8dh/pJUxCctlvQaL+lXiZjY6JDOKWqW4zikLUrxqduFy9L9Gjxg9mmXdBs6zScueNnck+8LiI2LQYLK6SgkqRKwcNk8F82OaTcuITakEVopvpkbtbkZKtx5/1a8+v/I5pJ2g6f1+Gm8dtzFe+R4NFwAFJetSFAljDq5SmSsmO9hb8e06zmwMB6SzeV5v75CIJtLuh1jdjjEJ55F1JFiRDMHGHgMXP8rDGnun9QhHQ4Hmj+5iIajjTh34pLPfbYX34Yl2YtCOq5oeJ0CHjPAHM+7bfMkV78eq7Qr6G6dGBf71U40HG3CyffO+I2rv+v+m0PWrniTxvEceE8d874ftZFuiWAZGhxGU30zGt5qRMunrT73+WLRLaHbXJebNFGn7rbXt83N0a1H9ibSLhEYxhhazrWi4WgjTtfa4DXcCeCv9POR+cU7Qzqu6+R/nuf86tgTsrkTR/4OcfcF4EgxOCamAHIgtvZhDGfoJjRS3NPZh0/eacLxd5rQ3d6LhcvSsfUrWrz9v/VejyFS5iW51XW9UxMdBk/ndzJ3Y3S3TvjDMeLA2eMX8PHRRpw/dRnK+Bis3bIS6g1L8OJTrwXU7rg3adzk0mqRbolAtLd0oOFoI06+L2CgfxDL1yzG7V/bMhYuMYovmzuRm7RQIO0S/hgaGMJpazMajjbi6vk2JKXEIm/wGD5QXOsMlxiFYyNIWb3Sra7nDVmwN2nBQrqdGPJ3iDuaAOYe98ixEfBdNowE6RAzxnCh8TM0HG2E8PF58Aoeq3KzcO3WVViwLB2AM67n9YPvO3Md8xzu+PpNWLAkLeCdGkFMNd32Xhx/pwmfvNOEno4+LFoxD/q/vhHZm5YjKsb58/7Cri1uaXjuFB+hheEmjSAmwsiIA8LH59Hw1mlcaGqBMjEW62/Kxvqbst2c3tf/+33p0e+d37gJC5amh+UmjSAmSutlOxqONuLUBwIGB4awYl0mbrpegTXP/wO4xGSoNi3Ca5fmg3EKcGwEd14Xhfkb14XtJo2YOiLWIQ46t2BKNsDxbk4x4xRwJPmf2SnS3zuAk+8LOH60Ee1XOpG6KAVbv5KDtddrEBsf47bv+htXYfVyJTpP25C6bhWS12RPuG9E+JB7LteJwBwM5xsvo+GtRgjHLyAqSoHVeVnYsHUV5i9J89o/p/M9rDvxA7RHpyN1qBXJneVA1DVT0jYieOaidrvae3D87SZ88u4Z9Hb2YbF6Ae68fys0G5d5xU5uuGk11qyIQ8epM2RzI4i5qNuR4RHYPvoUHx9txKUzVxCXpMS121Zj/cYFWPC77yP69RcwdMdX0f/dJ7E6MQVZ5z9Ft01A6lrSbaQQjG5nRx7iE8+CHTGCYyNgnAIDeU8FjCFuOfc5Go42otHaDIeDQbNxKTZsXY3MlQt8jpZxPId48x/A//jbgMMB8DywrxK4d/dEu0eEGbnmxASCz0Pc1zOAk++dQcPbTei42oX0DBU2bF2F1XlZiI2L8a4wPAzl2y8j+pH74ZYjjVcArzYDi5aE1E5iapCrdoPNQ8wcDOdOXkLD241oPn4RUbFRWDN6AzdvcarPOoooHnGv/gHcj41kcyMUueo2lDzEna3dzhu4986gr6sfmSsXYsPWVdBsXIqYj96C8nEjuL4e9P/Tv2H4dgMAZ0Yp8ekcEXnM/jzE63ZjeNEXMHTlFBxJGp+xw2K8z/Gjjbhyvg1JqQnIu3MDrrlhJeKT43wfd3AAUWc+QuwHr4H/3RNj2x0O4DEjcOOd5FQQUwpjDJ81f46Gtxqd6XQAZF+3DPr7bkSGer73DdzgABTWw4g+8hKi3v4TuI4274M6RoDzZ0i7xJTS29WPE++dwfG3m9DZ2o15mam4def1WJ2bhRil/+wlUdEKKLuugvuRcezJH9lcYppwOBw4d+ISGt5qRPPJi4iJjcbazWqsv2kV0jNUwOAAYiseQUzVUxjetA39368EW7gEHMchLjEWiqjQskQQkcPscIgBIGEJRhYu8NrcetmO42834uQHAgb7h7BibSa2G2/D8nWLvWN5ejqhOP4+FB+/43ydtIIb7AdilN7nI6eCmEIGB4ZwuvYsGo424vOL7UhOT8SWL16HtZs1iE/y0GN/L6LeNyPqyEuIevcv4Ho6wZavAmcwApu2An+/3elQiPAKYKn7JA+CCAeMMVwWrqLh6Gk0HfsUHIBs7Qrcef9WLFoxb9x49ejYKCgxBDz+915zQ8jmElNJb2cfPnn3DI6/04Suth4sWJqG23dtwSrtCkSPpp/khU+g/PFu8J82ov9vHsfQzr8DeOdCLHGJ3nmBCXkxaxzixs/Oo0GwYdXipVCnLYbto/NoONqIi2danPE+W1dj/U3ZbjMvuc8/g6LhHckB5m3HwTkccKjmgV23FfjOT4GcbYBqHnCPhpwKIux0tnbjwpkWaSWuzy+1o+GtRpyqO4vhgWGsWJ+JG/M3Yfmaxe6TiHo6EfXOXxD15kuIet8Mrr8XI5r1GPzqw4i+2wB+1Yax9D/7Kp2ja44Rp273VZBTQUyK05fO4eMzNmgWLkb2gqUY6BvEqdqzOH60Ea2X7UiZn4Qbv7QJa7doEJcQG9QxY+NiEPPRW8C+3UDrZ079Mo9QH7K5xCTpbOvGJeEqVPOTkKiKx8UzLWg42gjbR+fB8xxW5azAhq2rsFDMOQ0ADgeia36L2Mp/gSNTjd6KI3Cs3ADAucxxfKKSJnnOAmaFQ/yr/6mG/cVW8IzDGZwBF8MDgwyLVy7AXd90TthQKHhwF84g6t1RB7jhXfAXnUtzOjLVGLn2Rgx9xYjhjTcieuVaxMZ7GHFyKogwc+yNk3jl2TedKxVxQEp6Ijo+70Z8chyuu2UN1t+YjaQ0l9WFOloR9fYriD7yEhR1r4MbGsTImhwM3r8XQ9vywa1Y5Ryl8Hzyce9u56Pm82ecDgXplpgErvb2FE4jelks+M8cGB4egXr9Etx8bw6WrsoIyUFQYhDRP/9noOq3QO4twIFDQO1hsrlEWDn2xkn86dkj0pSK+OQ49Hb2IXVBMrb+lRZrrldD6fG/n7t6Ccr9RkTVHcag4W8xUPwYEOt8ShcVrYAyIZYy9cwSZO8Qn750DvYXWsGLywmCAxt0YFtRDnJiBqD4+E9Q/M+oA9x+FYzn4dBswPCWOzBy7Y0Y2XAD2LwM6XjK+Bjp8Ygb5FQQYaSztXvMGQYABnR83o1bCzfjmhtWQjH66I1rbUHU0T8i6shLUHz4JuBwYGTDFgwYf4zhW/LBFi4FACiiFIhLDGCYFy0hzRKT5vSlc5IzDAA8OAx/OoDsbVnYps9Boio+pONxHIe440eh+HEx0P458IPfADu/7ZxEt1RNNpcIG52t3W7OMOAMk7jrWzcje9Nyn7Yz6o3/gfJnD4PFKtH75MsYyfuCVBYdEwVlkE8/CHkge4f45KfNkjMswoHDkkd2I6H9OFhMLEbW5mLoS990OsDXXA8kpvg81rizQ8mpIMJEW0uH1xr2AJC2MBlRn19E1JGXEfXmS1A0vAvwPEY2bcPAd5/E8NbtYOkL3epExURBGR9DoxTElHPy02bJGRbhwAHZUaE7w31diK/cB/6FSuD624BnDwNLstx3IptLhInT58+5OcMivcoBb9vZ0wnlL/8Z0X/5A4Zu+TL6v/cUkJIuFccoo31n9iFkjc8I8ObmZuzcuROlpaVobm5Gbm4usrOz8dFHH01bw8TcggcPHgy438IRXlqlToRjI+jfegt6fmNB9yuX0PerVzFYtA8jm/U+nWGO4xCfpKRUKTLk4MGDyM/Pj7icmOPpdkA1DAaPSUPMgfTybyDRsBaxFY8ACcnoL/l3dP+vgL5//SOGvvyglzMcExuNOHpkJ0vkqN21y1bAwbl7FQ7OgezFoTmtUdbDSPjmZvB/fh545LfAAYu3M0xEJHLULQC0JnX71G5rknvaS8XH7yDhWzcg6shL6CutQP+Pfu/mDCvjY8gZliHB6NanQ2wwGFBYWIjU1FTk5OTAZDLh1VdfxYMPPjhljfUkMzMTL7/88riJtuMvXsE9F/4Ajo0AcDrD91x4Ht1rtsKxYQsQE/iRBs/ziE9SUqoUmbJr1y68/PLLyMwMfZnuqSBY3bZ2nsIXz3vq9g9AogN9j/wO3S+dRV9ZDYbv+bqbMXYlNi7GawEZQj7IUburFy/H6ls+A4dR3WIEK2+6jOwFS4M7SU8n4n7+MOL+YTu4ZdnAiw1jIRKELJCjbgFgfaYaL285BgfnHIhwcA78cctHWLNwmXOH4SHEHHgMcQ/fBTYvAz3/8S6G775vbHIygLhEpe+QSiLiCUa3PodE29vbsWPHDnR0dKCyshJZWc4790hcw2PBtddiQdu7UHedQHvMfKQOXkX8UCfOrf3tuHUVUTziEmh2KDH9rL5wHult70DjotvkITsu/tNvMHzzznHrU/J3YkbovoCdQz9BZ04y2vvnI1V5FUmsCz29X/eZ/90VxQcWKH/2d+C67MAjTwOGYjdngyCmkiXK+fjX6+KwfvAH6Oyfj2TlVdy07j5kxswD92kj4n7yIPimjzH4wA8x+LV/BKLG7CvHc4hLoBzDsx2f/1G1Wi0KCwtht9uhUqnwzDPPwG63Iy3Ne1nYmSZjTTbe/tpPsfn5HyJ5yI5h8Di641HkrAy8dDPNDiVmkvR5yQAHJA/ZkTxkd27kgLT0JARa+4uSvxMzSkcTwBxIjrUjOdbu3MYAvsuGEX8OcXcHYn/zfcT86b+ALTrgsWeAxcunrckEAQDovoCbP/4VEOtA6qh2bzv5Www0zUdsZRnYgiXo/fdDcKzNcavG8zziknxk7yFmHT4d4urqarzwwgtQq9XYtGkT9u7dCwAwmUzT2rhguam0FOe/+GVcPvYx0teuG9cZjo6N8kqtQhDTyeV5m7BwG8C/CedEDw4Y2cbhUupGeC8v44SSvxMzzWW2BAsYB4VLLOYw43HZkelTt4r3XoPyZ38PrrfTmbpyx4M0KkzMDKM3c+gG0AEgBuBqHVCeexSDX96Ngb95HIhLcKtCT5HnFn6fue7YsQMA0NnZiSeeeAKdnZ1ITk6etoaFyqLV2VAtHX/UITYuJuCyoQQxHTR1JuMnsUX45X3PIKqTYTiZw3euPIj87hTfjgUZZiICaOpMxk+EB/FL9bOI4hwYZjy+I+xGfp6HbrvsUP6mFNGvPAfHFj24Hz0DZCybqWYTBJCSDZzkgCNMyjbBooH+x57G8G1/7bU7Ze+Ze4wbhFhUVISqqirpr5xRJsQimuIuiQhAsygJv//8Vlg6NkCtbIHQshAtQ/Pw8PwEr30pvIeIFLx02++tW8W7rzpjhft64PiXSvAFNCpMRADdAI7APfXaMIeRa27z2jUmNpomLM9Bgn72Ot0T6oJNpRIMzrhLJTnDsxC5pgDKTIvHUw9sRsvwPBztXIeWoXkoK9yIxao4t/2iY6MQl6gkZ3gWIkftBtRtVzuUjxsRX7IDDs16sBc+Bm8oImd4liFH3QIAPm1yXwocAMcY+Is2t22UvWd2EoxuI9ZDFFOpTBaaHTq72bVrF3bt2oX8/PyZbgqA0HR7/y0a6DZk4PiZq1gxP8HLGabwntmNXLUr6vbUuTYsUSmxWBUHxTt/dsYKD/Rh4PtPI2ZnETiKdZ+VyFW3WJbtTO/nGMv/zngFHJljc47oKfLsJRjdjmuxIjHVWrBQjmEi0slMi8eN2fO8nGFlQiw5w0TEkjnYhpu7PkFmmwDlT4sQv9cAR/ZG9P+hDjFfLSZnmIg8Fi3B21/9CYZH3Z5h8DjylX1gCzKlxbnIGZ7bjPvtFxYWuv2VC4oohXMFL5qERMiMuEQloqLpJo6IUF58FnisGDEOB6IBIDYOfaUV4PK/gbhE5Uy3jiB8crGtF/ecWo5F1/wC6oEWCLEL0XJ2Hj7o6MfKpamUvYcI7BB3dnZix44daG5ullUMI80OJeQIhfcQEc9nF4DHiqXHzhwANjQA/kYdYskZJiIY22ddcDDgUkw6LsWMrv7JGD7rGcIqcoYJBAiZeOihh7B//350dHRAp9Phgw8+CHqUuKSkBDk5OdDr9bDb7V7lHMdBo9FAo9GgpKRkwo33RUxstHNkmJxhQkZQeA8hCz5tcovBBADO4UDs1U9nqEEEERyaRUnwfGCs4DloMiI3nSwxvfh1iOvq6rB//34cOHAARqMRTzzxBNrb28c9oMVigSAIsFqtMBqN2L9/v1u5IAgoKCiAzWaDzWZDWVnZ5HsxCs0OJeSIIkqB+CQlrYRERD7ixCRXeAWwdOXMtIcggkTMkKIY9YoVPIdffut6ZKbFz3DLiEjBb8hEVlYWnnnmGTz99NOwWCw4dOhQUAesr6+XRpILCgp8OsR2ux0GgwFpaWkoKyuDSqUKusGXL1/G5cuX3balpqZixYoVGBgYQH19g1cdrVYLADh9+jR6enrcylasWIG0tDRcvXoV58+fdytLSkpCdnY2RkZG8NFHH3kdd8OGDYiOjobNZkNHR4dbWWZmJhYuXIj29nacPXvWrSwuLg5r164FAHz44YdeExfXrl2LuLg4nDt3Dq2trW5lCxcuRGZmJrq6utDU1ORWFh0djQ0bNgAAGhoaMDQ05FaenZ2NpKQkXLx4ES0tLW5l6enpWL58Ofr6+nDy5Em3Mo7jsGnTJgDAyZMn0dfX51aelZWF1NRUtLS0eKU0SUlJgUajwdDQEBoavL+bjRs3QqFQoKmpCV1dXW5lS5cuxfz589HW1obm5mYAQEZGBjIyMryOIwfG0+6JEye86pB2nchdu7NKt1//AVKf/SmyohzoB48TX/8+cOmK8zUK6daJ3HULyNfm+rK325al4viT+Th1/nMMt1/AgqQO1NfXS+WkWydzVrfMD3a7nf3sZz9jH374IWOMsb1790rvA1FcXMzMZrP0Wa1Wu5WbzWZWVlbG2tvbWVlZGSsoKPB5HK1Wy7Zv3y69nn/+ecYYY/v27WNwptaWXvfddx9jjLGmpiavMtcubtmyxavsueeeY4wx9utf/9qr7I477mCMMdbR0eHzuFeuXGGMMbZ9+3avsieffJIxxlh1dbVX2aZNm6Q2xcTEeJUfP36cMcbY7t27vcr27t3LGGPs8OHDXmWZmZnScTMzM73KDx8+LH2XnmW7d+9mjDF2/Phxr7KYmBjpuJs2bfIqr66uZowx9uSTT3qVbd++nTHG2JUrV3xew46ODsYYY3fccYdX2a9//WvGGGPPPfectG3fvn2MMcaef/55N31otVqfOppu/OmWMdLuXNauqFvG5Kddn7q99yuMfXCYNb3zJul2lNmoW1ftzgrdkr0l3QbQLceY77xqx44dw+OPPy7F4jLGwHHcuKvVlZeXQ61Wo6CgAACQk5MDq9Xqd//U1FSfoRj5+fk+cwv6G2XLyspCf38/jbLN0bs+f3qZbgK1g7Q7d7UbaLQi0rVLup27ugXka3NJt6TbkHXrz1POzc1lhw4dYna73e01HmazWRr1NZlMbM+ePW7lZWVlrKKigjHGmNVqZTqdzudxxLsFggiGSNFLpLSDkA+RoplIaQchDyJFL5HSDkIeBNJLwBjiL3zhC/6K/aLT6WAymaDX6wEAJpMJgiBAr9fDZrOhuLgYBoMBFRUVUjlBEARBEARBzBReDvHPf/5z6X1eXh50Oh3S09Olbd/73vfGPajo7IqoVCrYbDbpvdlsnnCDCYIgCIIgCCKceDnEWVlZbn8JgiAIgiAIYjbj5RDv2LEDANDR0QGTyYQHH3wQHR0dOHDgAIqLi6e9gQRBEARBEAQxlfhdCWDnzp3SKnMpKSlgjMFgMExXu3Dx4kXk5+fj4MGD03ZOQn4cPHgQ+fn5XjNWZwrSLREspF1CjpBuCTkSjG79pl3Lzc1FXV3duNumikhJ6ULIg0jRS6S0g5APkaKZSGkHIQ8iRS+R0g5CHgTSi98RYrVajdLSUrz++us4duwY9u7dC7VaPWWNJAiCIAiCmA3k5OTMdBNmnFCuQU1NDSorK6ds/2Dwm3aturoaBw4ckDJG5OXl4YknngjryQmCIAiCIKaDi229sH3WBc2iJGSmxc90cyKDzy4AnzYBy7KBRUtmrBniYm5TtX8w+HWIOzs7YTab3db5bm5uxooVK8LeCIIgCIIgiKniv47Y8PDv3oeDATwHPPXAZtx/i2bCx9Pr9Whra0NaWhoqKiqgVqulbbm5uQH3ixhefBZ4rBhwOACeB/ZVAvfuntQhg7kGBoMBJpMJarUaNTU1qK2thV6vhyAISEtLg9lsRltbGwRBwIEDB6DVamEwGKRyk8mEuro6CIIQ1mQPfh1ig8GAPXv24PbbbwfgHJ42Go149dVXw3ZygiAIgiCIydA7MIzGy51+y6909EvOMAA4GPDw795HhioOC1KUPuusykhGfKxvF8lisUCv12PPnj2oqalBRUUF0tPTodVqUVZWhsrKStTV1fncr6ysbNL9DZq+XuDsKd9lrS3Ao8UAczg/OxxO53j+YiB9of9jZq0B4nyPrpeXlwd1DQoLC2GxWFBcXIyqqiqUlpZCEATpOBaLBTabDfX19di/fz/0ej3UajVMJhPKy8tRXV2NtLS0iV4Vv/h1iFtbWyVnGHAOT4c7XoMgCIIgCGIyNF7uxM3/8peQ6jgYsOPJN/yWv/Wju3DdCt9Ol06nQ1paGsrLy1FVVQWdTgez2Sw5uzqdDhUVFT73m1bOngIKQ4hldjiAv7kn8D5VVmCd1mdRsNegoKAARqMRxcXFEAQBWq3WzSEWwyHUajXsdjvMZjOMRiMAYM+ePQCcg7Thxq9DrFar8dBDD0mp1qqrq6FSqcLeAIIgCIIgiImyKiMZb/3oLr/lVzr6YfjXN6QRYsAZNmH6x1sDjhD7w2KxoKSkBKWlpSgtLUVtbe2k9psystY4HVhftLYAf/ulsRFiwBk28ev/G3+EOAR8XQO1Wg1BEGCxWHzeJLiujiziOiIspgQON36zTFRXV0Or1cJkMsFkMiE3NxfV1dVT0ghfUG5BIhgoJyYhV0i7hByJRN1+1XAvTr77Kq5bkebzdcfGxXjqgc1Q8BwAQMFzeOqBzbhj42K/dfyFSwDOkdDS0lIUFBRAEATY7Xbo9XpUVVUBcDqB/vabVuLinaO5vl433w08WgnwCue+vMIZQ3zz3f7rrNP6DZcAENI10Ol0KCkpQWFh4bjdyMvLk45bXl4+oWiFSeUhPnbsGB588EFpGFuj0eCZZ57Bxo0bQ27IRKDcgkQoRIpeIqUdhHyIFM1ESjsIeRApegmlHRfbeiG0dEG9cHJZJgRBgNFohEqlglqtRmVlJc6ePQuDweA2oaykpMTnfhH1tP2zC8D5M8DSlWHJMuE5qc7fNairq4PBYEB7ezsAZwiEOPFOEATs2bMHdrsdBoMBZrPZa1KdxWJBW1tbyJPqAunFr0Ocl5eHyspKbNq0CQBQX18Po9E4bUP+kfJjI+RBpOglUtpByIdI0UyktIOQB5Gil0hpByEPJrQwB2NMcoYBQKvVwo/vTBAEQRAEEdFc6L+Kw23HcKH/6qSOU15eLoUETGS/YOvPRWZyQRO/QTI6nQ533nkn9Ho9AGcciEajwYsvvggAuPfee6enhQRBEARBEJPg2Qt/RvGJX8IBB3jwqFz3HexecvdMN4uIIPw6xBqNRprpxxiTZgLabDZwHDc9rSMIgiAIgghA70g/TvWc91veMtCO4hO/gAPOp9wOOFB84pdYHJuOhbGpPuusSViKeIXvDBQAUFFRgZKSEgCQFo/wXIDC337B1ler1VLsrE6ng91uR0VFBYxGI+rq6gBAWuDCH5cvX8bly5fdtqWmpiIrKwv9/f04ceKEVx2xjadPn0ZPT4+0PSMjAxkZGX7PJS6yYbFYcOjQISmmWuxPfX29z0U3fC3m4StmuKqqCna7XYrhFifaWa1+MmmESMARYqPRCKvVitbWVuzcuRPl5eW0Uh1BEARBEBHDqZ7zyHnvb0Oq44AD93z4Q7/l1i2/gTY522+53W6H1WpFfX09ioqKUFZW5nOxDs/9ROct2PquC1LU19dL+XfFukajEWaz2W87Kyoq8Nhjj7ltu++++/D73/8eFy5c8BmiIIbHfvOb38R7770nbd+3bx8effRRv+cCnNklrFarzwU58vLyvBbdyMvL81rMo7Ky0s0RLioqQmFhoZSTuKSkBGazGVarFUaj0W/6tlDx6xDv3LkTlZWV2L9/PwCguLgYBoNh2ibViSmAdu3ahV27dk3LOQn5cfDgQRw8eDCiUgCRbolgIO0SciQSdfvDb/4jfvrV7bjrLt+5iFsG2vGlDx+RRogBgAeP/9v0o4AjxIEQ12gQF5XwtwiH536h1K+trUVpaSkA52IVZrMZZrNZytAAQBop9ofRaER+fr7bttRUZ5+XLFkScHT1P//zP71GiMdD7Le/6+Fr0Q3PxTysVqvUP3FwtrCwUArh1Wg00Gg00vtg0tkFo1u/DrE4qU4Mj9DpdNi7d++4Jw0XmZmZNHOUGBfxn7fnD36mIN0SwULaJeRIROr2xfF1W7nuuzCe+CVG4IACPCrWfQd3z78+bO2Y7CIc49UXnT6VSoWysrKgR0QDhTkolUopPMIXq1evDq7xLoihtv7642vRjekgGN36zTKRm5uLhx56CIIg4PXXX8e3v/1tt/gOgiAIgiAIObB7yd1o3vYcDuf+DM3bnpv0hDqTyQTAmZJWrVb7XYDCc79Q6oshBsDYQhd5eXlSXYvFIo2kRhrBLkriazGPnJwcqY81NTUBnfZw4neE+Omnn8YLL7wAxhhee+016PV67NixY1oaRRAEQRAEEU6WKOdjiXL+pI+jUqmg1Wql+FvReRMneqnValRXV2Pfvn0+9wu2vrjYh9lshlarhUqlkkInPOtGGkaj0as/N9xwg9d+e/bsgV6vR05ODnJzc5GbmyuF6IohEuKEvKnG78IcMw0l2yZCIVL0EintIORDpGgmUtpByINI0UuktGMqEJ1ArVYLi8XiFm9LTIxAevG/WDdBEARBEMRsofsC0NEEpGQDiZNfpjgUxKWJQ1lqWK1Wo6ioCIAzhngqRoM7W7vR1tKBtIUpSE5PnPTxxJRo4gTCgoICyYm32+1ITU2FVquVQigqKiqQm5srbRePsXPnTil13XRBDjFBEARBELObE88CR4oB5gA4HrilEli3e9pOL2ZXCAWVSjWlIRHH3jiJV559E4wxcByHe3Zvw3W3rp3UMQ0GgzTpz2634/bbb0dlZaV0I6DVaqXMFjU1NVJ6X9ftgDMTRklJScAcy+GGHGKCIAiCIOTLUC9gP+W/vLcFeKMYgMP5mTmcznHCYiB+oe86qjVAdLzfQ/paOEIcARYEASUlJSgsLJQWqnjkkUdw5coVFBcXh7SwxmQYGhjC55fsPst6OnrxyrNHIAbNMsbwyrNvIlEVj4QU//2et1iF6Nhon2UWiwVqtVrKgCE69P7if3U6Hdra2nyW5ebmBpVOLZxErENMOTGJYIjEnJikWyIYSLuEHIlE3X73W3fhFze+FVpF5gD+dI//coMVmO87u0FlZaXbghnV1dVIS0vzua+4UIW4oEaoC2tMhs8v2fG7R14Ien/GGKp+/ueA+zzw4x3IyPI9MbG+vl6aCCeiVqv9OvzidfR1HEEQwppdYlJ5iGcayolJBENE5sQk3RJBQNol5Egk6vYX//Hf448Q/+lLkEaIAWfYxD3/F3iE2A9msxlGoxGAM0sCMOboeuKZLzjUhTUmw7zFKjzwY9/ZwXo6elH95J/hmlaB4zjs/Ke7xh0h9kdra6vk4IrhEuJ7m80GwOnsihkyxNF1z+2CIEgLkoSLYHQbsQ4xQRAEQRDEuETH+x3Nlbi1EjhiBNgIwCmAWyqA5RPPRew6Iuz5aN/1s+dCFKEurDEZomOj/Y7mAsA9u2/BK797E8zBwPEc7nlgG1Zet3zC59NoNKitrUVBQQFUKpUUEyyuKgfAK1YYcF4vXzHExcXFUKlUE25PqJBDTBAEQRDE7GbdbmDZnUDHGSBl5aSyTOTl5aGqqgparRbl5eUAnKEB4iiouMCEv7omkwk6nQ4WiwUVFRUzlkv4ulvXQr1hKdpbOpAahiwTxcXF0Gg0KCwslMIdxJH0UMnNzUVbW5v8HeKSkhJYLBZpONyzQ+OVEwRBEARBhJXEJWFJt7Znzx4YDAbk5OS4+TEVFRXQ6/XQ6/V+42YjbWGN5PTEsKRbExHDSdra2pCWlgaj0TghH0+tVsNisYSUpm6yhN0htlgsEARBCiLfv3+/WyLp8coJgiAIgiAiGV+ObKDJca5p16Y7v+50Ii5D7YrYd9cwCld8bZ+Ja8SH+4D19fUoLCwE4LwIno8OxisnCIIgCIIgiOkk7CPENpvNLVWGZ7D5eOUiYgogEUoFRLgiplARiaQUQKRbIhCkXUKOkG4JORKKbsPuEGs0Gjcn1zN2ZLxyEUoBRATC0+hFUgog0i0RCNIuIUdIt4QcCUW3YQ+Z0Gq1qKqqAuDMy+eZWmS8coIgCIIgCIKYTsI+QqzT6WAymaTVSkwmEwRBgF6vh81m81lOEARBEARBEDNF2EeIAefsQLPZDLPZDJVK5Zafz1d5KLjGgsxFqP/y7b+c2z5Z5nLfAXn3X85tDwfUf3n2X67tDhfU/9D7PyUO8VRCXzL1X67Iue2TZS73HZB3/+Xc9nBA/Zdn/+Xa7nBB/Z8DDvFEmMiFmY460yXYSO3LXP/Bjkek6naidabjHJGq9blGpH4PkWpzI1Xrc41I/R4iVbfTVWe6+k8O8QzWmU0iJ+McfiJVtxOtMx3niFStzzUi9XuIVJsbqVqfa0Tq9xCpup2uOtPVf44xxqblTCFyzTXXQKPReG2/ePEiMjMzQzpWpNaJ1HZNpM5Mt8tms+GTTz4J6VhTgT/dAvK7puGsE6ntmkidcJ8j0rU7V76HmawTqe0KVId0O311IrVd01VnunQbsQ4xQRAEQRAEQUwHcyJkgiAIgiAIgiD8QQ4xQRAEQRAEMachh5ggCIIgCIKY08jKIS4pKUFOTg70ej3sdvtMN2dKqampgcVikT776vtsvR5GoxE5OTnQaDSor68HIO/+y6Wd4YB0S7qVK6Rd0q4cId2GT7eycYgtFgsEQYDVaoXRaMT+/ftnuklThtFoRFFRkfTF+er7bL0eNTU1AACr1QqTyYSioiJZ918u7QwHpFvSrVwh7ZJ25QjpNry6lY1DXF9fj8LCQgBAQUGB2x3RbKOsrAzFxcXSZ199n63XQ61Wo6SkRHoPyLv/cmlnOCDdkm7lCmmXtCtHSLfh1a1sHGKbzQaVSiV9nk3D/p6oVCqkp6dLn331fbZeD61WC7VaDUEQcPvtt6OsrEzW/ZdLO8MB6ZZ0K1dIu6RdOUK6Da9uo6auueFFo9G4dcS1g7MdX32fzdejvLwcZrMZJpMJarUa9fX1su2/XNo5FZBuSbdyhbRL2pUjpNvJ6VY2I8RarRZVVVUAnLEjOp1uhls0ffjq+2y9HjU1NaitrYXZbJYeg8i5/3Jp51Qg5+8tVEi3sws5f3ehQtqdPcj5ewuVqdCtbEaIdTodTCYT9Ho9AMBkMs1wi6YPX31XqVSz8nqYzWZYLBZpKU61Wi3dAcqx/6RbeX5voUK6nV2Qdkm7coR0Oznd0tLNBEEQBEEQxJxGNiETBEEQBEEQBDEVkENMEARBEARBzGnIISYIgiAIgiDmNOQQEwRBEARBEHMacogJgiAIgiCIOQ05xARBEARBEMSchhziCVJeXj7pNcHtdjvq6+uD2rempgaVlZUhl4WbQOcKpT/EzEHa9Ya0G/mQbr0h3UY+pFtvIla3jJgQZWVlzGw2T+oYNpuNFRcXh6lFM89s689shbTrzWzrz2yEdOvNbOvPbIR0602k9mfOLcxRU1MDs9mMtrY2CIKAAwcOQBAEtLW1obi4GIIgoKSkBIWFhaiqqoLdbocgCDAajdLyf1arFeXl5aitrYUgCACAAwcOQKvVwmg0oq6uDoBzRZT6+nrU1tbCYrHg0KFDbutoGwwGWCwWmEwm2O12t/0MBgPa2tqQlpaGiooKCIIAQRCQlpbm1X7xva8yrVYLg8EAQRCg0+lgt9tRUVHhdV0qKyths9mkO1nPumlpaTCZTKirq/N7rv3790v9yc3NRVFREQRBQG5urs9zEqFB2iXtyhHSLelWjpBu555u52TIhPhFiF+MP+x2O8xmMwoKCmA2m2G1WpGbmysJwW63w2q14sCBAygqKkJNTQ0ASNuMRqN0PqvV6iZwACgrK8POnTultbXF/erq6qDX62G1WmE0GlFRUQG73e63/YHKysvLoVarYbVakZ6eLv0offW1vr7erT+VlZVIS0uD1WpFSUkJioqKAp7LtT+VlZVSH1QqlVs9YuKQdn33lbQb2ZBuffeVdBvZkG5993W26nZOOsQFBQUAnGtfB7r44trXGo0GBoNBei/WEbdptVoIggCz2Yy6ujoYDAbs379fuvsTRTwe4n46nQ46nQ7l5eU+f4SB2u9ZVltbi8LCQrey8for9sdqtUp91Ol0XjE/gdqh0+lQVlaG8vJylJaWev3AiYlB2g3cX9JuZEK6Ddxf0m1kQroN3N/Zpts56RCnp6f7LZvM3YlKpUJZWRlMJhNMJhPa29vHPZ+vdlksFhQVFUGtVqO0tNTvfoGO4Ytw33kFOpdWq4XZbAYA5OTk+L3bJEKDtBseSLvTC+k2PJBupxfSbXiQi27npEPsC5vNBgAhzQY1mUwAgPr6eqjVauTl5UnbLBaLdMcUiLa2Nq9tZrMZpaWlKCgogCAIkxJnXl6e1Kfx+iaKUuxPTk6O1J+amhpotdpxzyf2p6SkBIIgYM+ePSgoKIjMGaWzBNIuaVeOkG5Jt3KEdDt7dRs1Y2eOIAoKClBRUQG9Xg+9Xg+1Wj1uHZVKBa1Wi5ycHABOwavVapjNZrdtgb7ctLQ01NfXe4nPaDRKgflqtRrV1dW44YYbJtS3PXv2QK/Xw2w2Q6vVBnwcoVKppLa7BsqLj0cqKiqC7k9hYSFKSkpQVlYm3Q0T4Ye0O9Yn0q58IN2O9Yl0Kx9It2N9mo26nXNZJuYaoii1Wi0sFgvMZrNPwYkB9ePFDhHEdEHaJeQI6ZaQI6RbGiGe9ajVahQVFQFwxgWJjzUIItIh7RJyhHRLyBHSLY0QEwRBEARBEHMcmlRHEARBEARBzGnIISYIgiAIgiDmNOQQEwRBEARBEHOa/w+CyAlEY+TrBAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 720x444.984 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(4,4, figsize=(TWO_COL_WIDTH_INCH, TWO_COL_GOLDEN_RATIO_HEIGHT_INCH), sharex='all', sharey='all')\n",
    "\n",
    "# plot learning curves (with errorband) for each combination of learning_rate_multiplier and n_epochs\n",
    "# n_epochs in the rows, learning_rate_multiplier in the columns\n",
    "\n",
    "num_epochs = [1, 2, 4, 8]\n",
    "learning_rate_multipliers = [0.02, 0.05, 0.1, 0.2]\n",
    "base_models = ['ada', 'babbage', 'curie', 'davinci']\n",
    "for i, n_epochs in enumerate(num_epochs):\n",
    "    for j, learning_rate_multiplier in enumerate(learning_rate_multipliers):\n",
    "        for model in base_models:\n",
    "            try:\n",
    "                ax[i,j].plot(\n",
    "                    grouped.loc[model, :, n_epochs, learning_rate_multiplier].index,\n",
    "                    grouped.loc[model, :, n_epochs, learning_rate_multiplier][('f1_macro', 'mean')],\n",
    "                    label=model,\n",
    "                    marker='o'\n",
    "                )\n",
    "\n",
    "                # try to plot errorband\n",
    "                try: \n",
    "                    std = grouped.loc[model, :, n_epochs, learning_rate_multiplier][('f1_macro', 'std')]\n",
    "                    ax[i,j].fill_between(\n",
    "                        grouped.loc[model, :, n_epochs, learning_rate_multiplier].index,\n",
    "                        grouped.loc[model, :, n_epochs, learning_rate_multiplier][('f1_macro', 'mean')] - std,\n",
    "                        grouped.loc[model, :, n_epochs, learning_rate_multiplier][('f1_macro', 'mean')] + std,\n",
    "                        alpha=0.2,\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            \n",
    "        ax[i,j].hlines(0.5, 0, 200, label=\"random\", linestyle='--', color='k')\n",
    "        # plot GPR baseline \n",
    "        ax[i,j].plot(gpr_baseline.index, gpr_baseline[('f1_macro', 'mean')], label=\"GPR\", marker='o')\n",
    "        ax[i,j].fill_between(\n",
    "            gpr_baseline.index,\n",
    "            gpr_baseline[('f1_macro', 'mean')] - gpr_baseline[('f1_macro', 'std')],\n",
    "            gpr_baseline[('f1_macro', 'mean')] + gpr_baseline[('f1_macro', 'std')],\n",
    "            alpha=.1\n",
    "        )\n",
    "\n",
    "# label the top row with teh lr_multipliers\n",
    "for j, learning_rate_multiplier in enumerate(learning_rate_multipliers):\n",
    "    ax[0,j].set_title(fr\"$\\eta$ multiplier={learning_rate_multiplier}\")\n",
    "    ax[-1, j].set_xlabel(\"number training points\")\n",
    "\n",
    "# label the first column with the n_epochs\n",
    "for j, n_epochs in enumerate(num_epochs):\n",
    "    ax[j,0].set_ylabel(f\"epochs={n_epochs}\")\n",
    "\n",
    "ax[-1,-1].legend(ncols=2, labelspacing=0, columnspacing=.5, loc='lower right')\n",
    "\n",
    "fig.suptitle(\"F$_1$ macro scores (100 test points, GPT-3 fine tuned on SMILES)\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gptchem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f3b9074e5baa1438c27e2ea813f7f53b7516c83bd70840b6d64eae6820ee5df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
