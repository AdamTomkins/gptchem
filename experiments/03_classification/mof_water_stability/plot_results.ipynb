{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotx\n",
    "import pandas as pd\n",
    "from fastcore.xtras import load_pickle\n",
    "from scipy.stats import sem\n",
    "\n",
    "from gptchem.evaluator import find_learning_curve_intersection, fit_learning_curve, lc\n",
    "from gptchem.settings import ONE_COL_WIDTH_INCH, TWO_COL_GOLDEN_RATIO_HEIGHT_INCH, ONE_COL_GOLDEN_RATIO_HEIGHT_INCH\n",
    "\n",
    "from gptchem.plotsettings import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_out = glob(\"out/**/*.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_out = [load_pickle(p) for p in all_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'train_size': 100,\n",
       "  'predictions': (#69) [1,1,1,1,1,0,1,1,1,1...],\n",
       "  'xgboost': {'accuracy': 0.7681159420289855,\n",
       "   'acc_macro': 0.7681159420289855,\n",
       "   'racc': 0.6286494433942449,\n",
       "   'kappa': 0.37556561085972845,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.6877828054298643,\n",
       "   'f1_micro': 0.7681159420289855,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#69) [1,1,0,1,1,1,1,1,0,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "          0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "          1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "          1, 1, 0]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'tabpfn': {'accuracy': 0.855072463768116,\n",
       "   'acc_macro': 0.855072463768116,\n",
       "   'racc': 0.6727578239865575,\n",
       "   'kappa': 0.5571245186136072,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.775974025974026,\n",
       "   'f1_micro': 0.855072463768116,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#69) [1,1,0,1,1,1,1,1,0,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "          0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "          1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'base_model': 'ada',\n",
       "  'batch_size': None,\n",
       "  'n_epochs': 8,\n",
       "  'learning_rate_multiplier': 0.02,\n",
       "  'run_name': None,\n",
       "  'wandb_sync': False,\n",
       "  'outdir': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_042354',\n",
       "  'train_filename': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_042354/train.jsonl',\n",
       "  'valid_filename': 'None',\n",
       "  'model_name': 'ada:ft-lsmoepfl-2023-02-06-03-26-38',\n",
       "  'ft_id': 'ft-u8IGFzGo7JzluMriRVTGZAf8',\n",
       "  'date': '20230206_042757',\n",
       "  'train_file_id': 'file-GGit6FZJ2hJY7G4sJ0v9vVuG',\n",
       "  'valid_file_id': None,\n",
       "  'accuracy': 0.7391304347826086,\n",
       "  'acc_macro': 0.7391304347826086,\n",
       "  'racc': 0.6874606175173282,\n",
       "  'kappa': 0.1653225806451613,\n",
       "  'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "  'f1_macro': 0.573489010989011,\n",
       "  'f1_micro': 0.7391304347826086,\n",
       "  'frac_valid': 1.0,\n",
       "  'all_y_true': (#69) [1,1,0,1,1,1,1,1,0,1...],\n",
       "  'all_y_pred': (#69) [1,1,1,1,1,0,1,1,1,1...],\n",
       "  'valid_indices': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68],\n",
       "  'might_have_rounded_floats': False},\n",
       " {'train_size': 20,\n",
       "  'predictions': (#149) [1,1,1,1,1,1,1,1,1,1...],\n",
       "  'xgboost': {'accuracy': 0.7583892617449665,\n",
       "   'acc_macro': 0.7583892617449665,\n",
       "   'racc': 0.7583892617449665,\n",
       "   'kappa': 0.0,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.4312977099236641,\n",
       "   'f1_micro': 0.7583892617449665,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#149) [1,1,0,1,1,1,1,1,1,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118,\n",
       "    119,\n",
       "    120,\n",
       "    121,\n",
       "    122,\n",
       "    123,\n",
       "    124,\n",
       "    125,\n",
       "    126,\n",
       "    127,\n",
       "    128,\n",
       "    129,\n",
       "    130,\n",
       "    131,\n",
       "    132,\n",
       "    133,\n",
       "    134,\n",
       "    135,\n",
       "    136,\n",
       "    137,\n",
       "    138,\n",
       "    139,\n",
       "    140,\n",
       "    141,\n",
       "    142,\n",
       "    143,\n",
       "    144,\n",
       "    145,\n",
       "    146,\n",
       "    147,\n",
       "    148],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'tabpfn': {'accuracy': 0.7583892617449665,\n",
       "   'acc_macro': 0.7583892617449665,\n",
       "   'racc': 0.7583892617449665,\n",
       "   'kappa': 0.0,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.4312977099236641,\n",
       "   'f1_micro': 0.7583892617449665,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#149) [1,1,0,1,1,1,1,1,1,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118,\n",
       "    119,\n",
       "    120,\n",
       "    121,\n",
       "    122,\n",
       "    123,\n",
       "    124,\n",
       "    125,\n",
       "    126,\n",
       "    127,\n",
       "    128,\n",
       "    129,\n",
       "    130,\n",
       "    131,\n",
       "    132,\n",
       "    133,\n",
       "    134,\n",
       "    135,\n",
       "    136,\n",
       "    137,\n",
       "    138,\n",
       "    139,\n",
       "    140,\n",
       "    141,\n",
       "    142,\n",
       "    143,\n",
       "    144,\n",
       "    145,\n",
       "    146,\n",
       "    147,\n",
       "    148],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'base_model': 'ada',\n",
       "  'batch_size': None,\n",
       "  'n_epochs': 8,\n",
       "  'learning_rate_multiplier': 0.02,\n",
       "  'run_name': None,\n",
       "  'wandb_sync': False,\n",
       "  'outdir': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_055917',\n",
       "  'train_filename': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_055917/train.jsonl',\n",
       "  'valid_filename': 'None',\n",
       "  'model_name': 'ada:ft-lsmoepfl-2023-02-06-05-08-24',\n",
       "  'ft_id': 'ft-HSB6296aMzQQgvXn2nhAYfOD',\n",
       "  'date': '20230206_060921',\n",
       "  'train_file_id': 'file-Sle9BqkYddr7YktHprClDMDE',\n",
       "  'valid_file_id': None,\n",
       "  'accuracy': 0.7114093959731543,\n",
       "  'acc_macro': 0.7114093959731543,\n",
       "  'racc': 0.7133012026485294,\n",
       "  'kappa': -0.006598586017282173,\n",
       "  'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "  'f1_macro': 0.47487910826981394,\n",
       "  'f1_micro': 0.7114093959731543,\n",
       "  'frac_valid': 1.0,\n",
       "  'all_y_true': (#149) [1,1,0,1,1,1,1,1,1,1...],\n",
       "  'all_y_pred': (#149) [1,1,1,1,1,1,1,1,1,1...],\n",
       "  'valid_indices': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102,\n",
       "   103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118,\n",
       "   119,\n",
       "   120,\n",
       "   121,\n",
       "   122,\n",
       "   123,\n",
       "   124,\n",
       "   125,\n",
       "   126,\n",
       "   127,\n",
       "   128,\n",
       "   129,\n",
       "   130,\n",
       "   131,\n",
       "   132,\n",
       "   133,\n",
       "   134,\n",
       "   135,\n",
       "   136,\n",
       "   137,\n",
       "   138,\n",
       "   139,\n",
       "   140,\n",
       "   141,\n",
       "   142,\n",
       "   143,\n",
       "   144,\n",
       "   145,\n",
       "   146,\n",
       "   147,\n",
       "   148],\n",
       "  'might_have_rounded_floats': False},\n",
       " {'train_size': 50,\n",
       "  'predictions': (#119) [1,1,1,1,1,1,1,0,1,0...],\n",
       "  'xgboost': {'accuracy': 0.7983193277310925,\n",
       "   'acc_macro': 0.7983193277310925,\n",
       "   'racc': 0.6399971753407245,\n",
       "   'kappa': 0.439780306002354,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.7197802197802198,\n",
       "   'f1_micro': 0.7983193277310925,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#119) [1,1,1,1,0,1,1,1,1,0...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "          1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "          1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "          1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "          0, 1, 1, 1, 0, 1, 0, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'tabpfn': {'accuracy': 0.7563025210084033,\n",
       "   'acc_macro': 0.7563025210084033,\n",
       "   'racc': 0.7563025210084033,\n",
       "   'kappa': 0.0,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.430622009569378,\n",
       "   'f1_micro': 0.7563025210084033,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#119) [1,1,1,1,0,1,1,1,1,0...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'base_model': 'ada',\n",
       "  'batch_size': None,\n",
       "  'n_epochs': 8,\n",
       "  'learning_rate_multiplier': 0.02,\n",
       "  'run_name': None,\n",
       "  'wandb_sync': False,\n",
       "  'outdir': '/Users/kevinmaikjablonka/git/kjappelbaum/gptchem/experiments/03_classification/mof_water_stability/out/20230131_150831',\n",
       "  'train_filename': '/Users/kevinmaikjablonka/git/kjappelbaum/gptchem/experiments/03_classification/mof_water_stability/out/20230131_150831/train.jsonl',\n",
       "  'valid_filename': 'None',\n",
       "  'model_name': 'ada:ft-lsmoepfl-2023-01-31-15-11-48',\n",
       "  'ft_id': 'ft-MTSJIHsq6HKtm00M87sxOdhn',\n",
       "  'date': '20230131_161210',\n",
       "  'train_file_id': 'file-ieoELakPOfCI4L2Yb8Mr8S5A',\n",
       "  'valid_file_id': None,\n",
       "  'accuracy': 0.7310924369747899,\n",
       "  'acc_macro': 0.7310924369747899,\n",
       "  'racc': 0.6744580185015182,\n",
       "  'kappa': 0.1739696312364425,\n",
       "  'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "  'f1_macro': 0.5824561403508772,\n",
       "  'f1_micro': 0.7310924369747899,\n",
       "  'frac_valid': 1.0,\n",
       "  'all_y_true': (#119) [1,1,1,1,0,1,1,1,1,0...],\n",
       "  'all_y_pred': (#119) [1,1,1,1,1,1,1,0,1,0...],\n",
       "  'valid_indices': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102,\n",
       "   103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118],\n",
       "  'might_have_rounded_floats': False},\n",
       " {'train_size': 20,\n",
       "  'predictions': (#149) [0,1,1,1,0,0,1,1,1,1...],\n",
       "  'xgboost': {'accuracy': 0.7583892617449665,\n",
       "   'acc_macro': 0.7583892617449665,\n",
       "   'racc': 0.7583892617449665,\n",
       "   'kappa': 0.0,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.4312977099236641,\n",
       "   'f1_micro': 0.7583892617449665,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#149) [1,1,1,1,1,1,1,1,1,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118,\n",
       "    119,\n",
       "    120,\n",
       "    121,\n",
       "    122,\n",
       "    123,\n",
       "    124,\n",
       "    125,\n",
       "    126,\n",
       "    127,\n",
       "    128,\n",
       "    129,\n",
       "    130,\n",
       "    131,\n",
       "    132,\n",
       "    133,\n",
       "    134,\n",
       "    135,\n",
       "    136,\n",
       "    137,\n",
       "    138,\n",
       "    139,\n",
       "    140,\n",
       "    141,\n",
       "    142,\n",
       "    143,\n",
       "    144,\n",
       "    145,\n",
       "    146,\n",
       "    147,\n",
       "    148],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'tabpfn': {'accuracy': 0.738255033557047,\n",
       "   'acc_macro': 0.738255033557047,\n",
       "   'racc': 0.7133012026485294,\n",
       "   'kappa': 0.08703849175176757,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.5237275633144824,\n",
       "   'f1_micro': 0.738255033557047,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#149) [1,1,1,1,1,1,1,1,1,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "          0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118,\n",
       "    119,\n",
       "    120,\n",
       "    121,\n",
       "    122,\n",
       "    123,\n",
       "    124,\n",
       "    125,\n",
       "    126,\n",
       "    127,\n",
       "    128,\n",
       "    129,\n",
       "    130,\n",
       "    131,\n",
       "    132,\n",
       "    133,\n",
       "    134,\n",
       "    135,\n",
       "    136,\n",
       "    137,\n",
       "    138,\n",
       "    139,\n",
       "    140,\n",
       "    141,\n",
       "    142,\n",
       "    143,\n",
       "    144,\n",
       "    145,\n",
       "    146,\n",
       "    147,\n",
       "    148],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'base_model': 'ada',\n",
       "  'batch_size': None,\n",
       "  'n_epochs': 8,\n",
       "  'learning_rate_multiplier': 0.02,\n",
       "  'run_name': None,\n",
       "  'wandb_sync': False,\n",
       "  'outdir': '/Users/kevinmaikjablonka/git/kjappelbaum/gptchem/experiments/03_classification/mof_water_stability/out/20230201_003837',\n",
       "  'train_filename': '/Users/kevinmaikjablonka/git/kjappelbaum/gptchem/experiments/03_classification/mof_water_stability/out/20230201_003837/train.jsonl',\n",
       "  'valid_filename': 'None',\n",
       "  'model_name': 'ada:ft-lsmoepfl-2023-02-01-03-11-34',\n",
       "  'ft_id': 'ft-C1uaRxnahU9tBRADoWv7Eg9y',\n",
       "  'date': '20230201_041153',\n",
       "  'train_file_id': 'file-HgUGHNbYSahTsm2vakF4vEkD',\n",
       "  'valid_file_id': None,\n",
       "  'accuracy': 0.6040268456375839,\n",
       "  'acc_macro': 0.6040268456375839,\n",
       "  'racc': 0.6300617089320301,\n",
       "  'kappa': -0.0703762328016558,\n",
       "  'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "  'f1_macro': 0.464779299847793,\n",
       "  'f1_micro': 0.6040268456375839,\n",
       "  'frac_valid': 1.0,\n",
       "  'all_y_true': (#149) [1,1,1,1,1,1,1,1,1,1...],\n",
       "  'all_y_pred': (#149) [0,1,1,1,0,0,1,1,1,1...],\n",
       "  'valid_indices': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102,\n",
       "   103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118,\n",
       "   119,\n",
       "   120,\n",
       "   121,\n",
       "   122,\n",
       "   123,\n",
       "   124,\n",
       "   125,\n",
       "   126,\n",
       "   127,\n",
       "   128,\n",
       "   129,\n",
       "   130,\n",
       "   131,\n",
       "   132,\n",
       "   133,\n",
       "   134,\n",
       "   135,\n",
       "   136,\n",
       "   137,\n",
       "   138,\n",
       "   139,\n",
       "   140,\n",
       "   141,\n",
       "   142,\n",
       "   143,\n",
       "   144,\n",
       "   145,\n",
       "   146,\n",
       "   147,\n",
       "   148],\n",
       "  'might_have_rounded_floats': False},\n",
       " {'train_size': 150,\n",
       "  'predictions': (#19) [1,1,1,1,1,1,1,1,1,1...],\n",
       "  'xgboost': {'accuracy': 0.7368421052631579,\n",
       "   'acc_macro': 0.7368421052631579,\n",
       "   'racc': 0.5872576177285318,\n",
       "   'kappa': 0.3624161073825503,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.6801346801346801,\n",
       "   'f1_micro': 0.7368421052631579,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#19) [1,1,1,1,1,0,1,1,1,0...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'tabpfn': {'accuracy': 0.7894736842105263,\n",
       "   'acc_macro': 0.7894736842105263,\n",
       "   'racc': 0.6121883656509696,\n",
       "   'kappa': 0.45714285714285713,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.7285714285714285,\n",
       "   'f1_micro': 0.7894736842105263,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#19) [1,1,1,1,1,0,1,1,1,0...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'base_model': 'ada',\n",
       "  'batch_size': None,\n",
       "  'n_epochs': 8,\n",
       "  'learning_rate_multiplier': 0.02,\n",
       "  'run_name': None,\n",
       "  'wandb_sync': False,\n",
       "  'outdir': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230207_015455',\n",
       "  'train_filename': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230207_015455/train.jsonl',\n",
       "  'valid_filename': 'None',\n",
       "  'model_name': 'ada:ft-lsmoepfl-2023-02-07-03-59-51',\n",
       "  'ft_id': 'ft-RberHM1GAWpS56IoG0WEIENG',\n",
       "  'date': '20230207_050149',\n",
       "  'train_file_id': 'file-4FWli0MOKZvDMuyNKlXbsQ2I',\n",
       "  'valid_file_id': None,\n",
       "  'accuracy': 0.8947368421052632,\n",
       "  'acc_macro': 0.8947368421052632,\n",
       "  'racc': 0.6620498614958449,\n",
       "  'kappa': 0.6885245901639344,\n",
       "  'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "  'f1_macro': 0.8416666666666667,\n",
       "  'f1_micro': 0.8947368421052632,\n",
       "  'frac_valid': 1.0,\n",
       "  'all_y_true': (#19) [1,1,1,1,1,0,1,1,1,0...],\n",
       "  'all_y_pred': (#19) [1,1,1,1,1,1,1,1,1,1...],\n",
       "  'valid_indices': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18],\n",
       "  'might_have_rounded_floats': False},\n",
       " {'train_size': 50,\n",
       "  'predictions': (#119) [1,1,1,1,1,1,1,1,1,1...],\n",
       "  'xgboost': {'accuracy': 0.7226890756302521,\n",
       "   'acc_macro': 0.7226890756302521,\n",
       "   'racc': 0.6443047807358238,\n",
       "   'kappa': 0.2203692674210839,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.6098360655737705,\n",
       "   'f1_micro': 0.7226890756302521,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#119) [0,1,1,1,0,1,1,1,1,1...],\n",
       "   'all_y_pred': array([0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "          0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "          0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "          1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "          1, 0, 1, 1, 1, 1, 0, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'tabpfn': {'accuracy': 0.7647058823529411,\n",
       "   'acc_macro': 0.7647058823529411,\n",
       "   'racc': 0.7519949156133041,\n",
       "   'kappa': 0.05125284738040992,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.46602564102564104,\n",
       "   'f1_micro': 0.7647058823529411,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#119) [0,1,1,1,0,1,1,1,1,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'base_model': 'ada',\n",
       "  'batch_size': None,\n",
       "  'n_epochs': 8,\n",
       "  'learning_rate_multiplier': 0.02,\n",
       "  'run_name': None,\n",
       "  'wandb_sync': False,\n",
       "  'outdir': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_033505',\n",
       "  'train_filename': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_033505/train.jsonl',\n",
       "  'valid_filename': 'None',\n",
       "  'model_name': 'ada:ft-lsmoepfl-2023-02-06-02-42-46',\n",
       "  'ft_id': 'ft-9VDl0HIP5SkSXcKj0CKuKuog',\n",
       "  'date': '20230206_034309',\n",
       "  'train_file_id': 'file-JxSihMfDXZoIpcfybG8p4uXQ',\n",
       "  'valid_file_id': None,\n",
       "  'accuracy': 0.7647058823529411,\n",
       "  'acc_macro': 0.7647058823529411,\n",
       "  'racc': 0.7347644940329073,\n",
       "  'kappa': 0.11288604898828504,\n",
       "  'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "  'f1_macro': 0.5196078431372549,\n",
       "  'f1_micro': 0.7647058823529411,\n",
       "  'frac_valid': 1.0,\n",
       "  'all_y_true': (#119) [0,1,1,1,0,1,1,1,1,1...],\n",
       "  'all_y_pred': (#119) [1,1,1,1,1,1,1,1,1,1...],\n",
       "  'valid_indices': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102,\n",
       "   103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118],\n",
       "  'might_have_rounded_floats': False},\n",
       " {'train_size': 50,\n",
       "  'predictions': (#119) [1,1,1,1,1,1,1,1,1,0...],\n",
       "  'xgboost': {'accuracy': 0.7058823529411765,\n",
       "   'acc_macro': 0.7058823529411765,\n",
       "   'racc': 0.6615352023162206,\n",
       "   'kappa': 0.13102441059878991,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.5632798573975044,\n",
       "   'f1_micro': 0.7058823529411765,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#119) [0,1,1,0,1,1,1,1,1,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "          1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "          1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "          1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "          1, 1, 1, 1, 1, 1, 1, 0, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'tabpfn': {'accuracy': 0.7983193277310925,\n",
       "   'acc_macro': 0.7983193277310925,\n",
       "   'racc': 0.708918861662312,\n",
       "   'kappa': 0.30713245997088806,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.6393939393939394,\n",
       "   'f1_micro': 0.7983193277310925,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#119) [0,1,1,0,1,1,1,1,1,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "          1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "          1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 0, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'base_model': 'ada',\n",
       "  'batch_size': None,\n",
       "  'n_epochs': 8,\n",
       "  'learning_rate_multiplier': 0.02,\n",
       "  'run_name': None,\n",
       "  'wandb_sync': False,\n",
       "  'outdir': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_010109',\n",
       "  'train_filename': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_010109/train.jsonl',\n",
       "  'valid_filename': 'None',\n",
       "  'model_name': 'ada:ft-lsmoepfl-2023-02-06-00-04-56',\n",
       "  'ft_id': 'ft-OCIHxMi8KMKwAnKEvQilZHSg',\n",
       "  'date': '20230206_010512',\n",
       "  'train_file_id': 'file-0h1WFZ01XR9Vxl8ZU54DgusN',\n",
       "  'valid_file_id': None,\n",
       "  'accuracy': 0.6722689075630253,\n",
       "  'acc_macro': 0.6722689075630253,\n",
       "  'racc': 0.6959960454770143,\n",
       "  'kappa': -0.07804878048780466,\n",
       "  'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "  'f1_macro': 0.44651162790697674,\n",
       "  'f1_micro': 0.6722689075630253,\n",
       "  'frac_valid': 1.0,\n",
       "  'all_y_true': (#119) [0,1,1,0,1,1,1,1,1,1...],\n",
       "  'all_y_pred': (#119) [1,1,1,1,1,1,1,1,1,0...],\n",
       "  'valid_indices': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102,\n",
       "   103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118],\n",
       "  'might_have_rounded_floats': False},\n",
       " {'train_size': 50,\n",
       "  'predictions': (#119) [1,1,1,1,1,1,1,1,1,1...],\n",
       "  'xgboost': {'accuracy': 0.7563025210084033,\n",
       "   'acc_macro': 0.7563025210084033,\n",
       "   'racc': 0.7218416778476096,\n",
       "   'kappa': 0.12388931200812406,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.5359688046255211,\n",
       "   'f1_micro': 0.7563025210084033,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#119) [1,1,0,1,1,1,1,1,0,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 0, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'tabpfn': {'accuracy': 0.773109243697479,\n",
       "   'acc_macro': 0.773109243697479,\n",
       "   'racc': 0.7304568886378081,\n",
       "   'kappa': 0.15823945506942622,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.5477832512315272,\n",
       "   'f1_micro': 0.773109243697479,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#119) [1,1,0,1,1,1,1,1,0,1...],\n",
       "   'all_y_pred': array([1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'base_model': 'ada',\n",
       "  'batch_size': None,\n",
       "  'n_epochs': 8,\n",
       "  'learning_rate_multiplier': 0.02,\n",
       "  'run_name': None,\n",
       "  'wandb_sync': False,\n",
       "  'outdir': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_062723',\n",
       "  'train_filename': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_062723/train.jsonl',\n",
       "  'valid_filename': 'None',\n",
       "  'model_name': 'ada:ft-lsmoepfl-2023-02-06-05-35-53',\n",
       "  'ft_id': 'ft-fd6F6senPHwATyXWTnw8HyJl',\n",
       "  'date': '20230206_063727',\n",
       "  'train_file_id': 'file-MidFWrodCQedB3gwmDcv5OCe',\n",
       "  'valid_file_id': None,\n",
       "  'accuracy': 0.7647058823529411,\n",
       "  'acc_macro': 0.7647058823529411,\n",
       "  'racc': 0.7433797048231057,\n",
       "  'kappa': 0.0831040176114474,\n",
       "  'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "  'f1_macro': 0.4945388349514563,\n",
       "  'f1_micro': 0.7647058823529411,\n",
       "  'frac_valid': 1.0,\n",
       "  'all_y_true': (#119) [1,1,0,1,1,1,1,1,0,1...],\n",
       "  'all_y_pred': (#119) [1,1,1,1,1,1,1,1,1,1...],\n",
       "  'valid_indices': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102,\n",
       "   103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118],\n",
       "  'might_have_rounded_floats': False},\n",
       " {'train_size': 150,\n",
       "  'predictions': (#19) [1,1,0,1,1,1,1,0,1,1...],\n",
       "  'xgboost': {'accuracy': 0.7368421052631579,\n",
       "   'acc_macro': 0.7368421052631579,\n",
       "   'racc': 0.6869806094182825,\n",
       "   'kappa': 0.15929203539822998,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.5622119815668203,\n",
       "   'f1_micro': 0.7368421052631579,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#19) [1,0,0,1,1,1,1,0,1,1...],\n",
       "   'all_y_pred': array([1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'tabpfn': {'accuracy': 0.7894736842105263,\n",
       "   'acc_macro': 0.7894736842105263,\n",
       "   'racc': 0.6620498614958449,\n",
       "   'kappa': 0.3770491803278689,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.6833333333333333,\n",
       "   'f1_micro': 0.7894736842105263,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#19) [1,0,0,1,1,1,1,0,1,1...],\n",
       "   'all_y_pred': array([1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'base_model': 'ada',\n",
       "  'batch_size': None,\n",
       "  'n_epochs': 8,\n",
       "  'learning_rate_multiplier': 0.02,\n",
       "  'run_name': None,\n",
       "  'wandb_sync': False,\n",
       "  'outdir': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_020334',\n",
       "  'train_filename': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_020334/train.jsonl',\n",
       "  'valid_filename': 'None',\n",
       "  'model_name': 'ada:ft-lsmoepfl-2023-02-06-01-11-44',\n",
       "  'ft_id': 'ft-aPfqIGzHrYKT6DskV6UWW2HT',\n",
       "  'date': '20230206_021339',\n",
       "  'train_file_id': 'file-gTgS6vzakeYFQzbHdj86B9Xq',\n",
       "  'valid_file_id': None,\n",
       "  'accuracy': 0.8947368421052632,\n",
       "  'acc_macro': 0.8947368421052632,\n",
       "  'racc': 0.6121883656509696,\n",
       "  'kappa': 0.7285714285714285,\n",
       "  'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "  'f1_macro': 0.8642857142857143,\n",
       "  'f1_micro': 0.8947368421052632,\n",
       "  'frac_valid': 1.0,\n",
       "  'all_y_true': (#19) [1,0,0,1,1,1,1,0,1,1...],\n",
       "  'all_y_pred': (#19) [1,1,0,1,1,1,1,0,1,1...],\n",
       "  'valid_indices': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18],\n",
       "  'might_have_rounded_floats': False},\n",
       " {'train_size': 10,\n",
       "  'predictions': (#159) [1,1,1,1,1,1,1,1,1,1...],\n",
       "  'xgboost': {'accuracy': 0.7547169811320755,\n",
       "   'acc_macro': 0.7547169811320755,\n",
       "   'racc': 0.7547169811320755,\n",
       "   'kappa': 0.0,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.43010752688172044,\n",
       "   'f1_micro': 0.7547169811320755,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#159) [1,1,1,1,0,1,0,1,1,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118,\n",
       "    119,\n",
       "    120,\n",
       "    121,\n",
       "    122,\n",
       "    123,\n",
       "    124,\n",
       "    125,\n",
       "    126,\n",
       "    127,\n",
       "    128,\n",
       "    129,\n",
       "    130,\n",
       "    131,\n",
       "    132,\n",
       "    133,\n",
       "    134,\n",
       "    135,\n",
       "    136,\n",
       "    137,\n",
       "    138,\n",
       "    139,\n",
       "    140,\n",
       "    141,\n",
       "    142,\n",
       "    143,\n",
       "    144,\n",
       "    145,\n",
       "    146,\n",
       "    147,\n",
       "    148,\n",
       "    149,\n",
       "    150,\n",
       "    151,\n",
       "    152,\n",
       "    153,\n",
       "    154,\n",
       "    155,\n",
       "    156,\n",
       "    157,\n",
       "    158],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'tabpfn': {'accuracy': 0.7672955974842768,\n",
       "   'acc_macro': 0.7672955974842768,\n",
       "   'racc': 0.7419010323958705,\n",
       "   'kappa': 0.09839080459770119,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.5024947145877379,\n",
       "   'f1_micro': 0.7672955974842768,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#159) [1,1,1,1,0,1,0,1,1,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118,\n",
       "    119,\n",
       "    120,\n",
       "    121,\n",
       "    122,\n",
       "    123,\n",
       "    124,\n",
       "    125,\n",
       "    126,\n",
       "    127,\n",
       "    128,\n",
       "    129,\n",
       "    130,\n",
       "    131,\n",
       "    132,\n",
       "    133,\n",
       "    134,\n",
       "    135,\n",
       "    136,\n",
       "    137,\n",
       "    138,\n",
       "    139,\n",
       "    140,\n",
       "    141,\n",
       "    142,\n",
       "    143,\n",
       "    144,\n",
       "    145,\n",
       "    146,\n",
       "    147,\n",
       "    148,\n",
       "    149,\n",
       "    150,\n",
       "    151,\n",
       "    152,\n",
       "    153,\n",
       "    154,\n",
       "    155,\n",
       "    156,\n",
       "    157,\n",
       "    158],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'base_model': 'ada',\n",
       "  'batch_size': None,\n",
       "  'n_epochs': 8,\n",
       "  'learning_rate_multiplier': 0.02,\n",
       "  'run_name': None,\n",
       "  'wandb_sync': False,\n",
       "  'outdir': '/Users/kevinmaikjablonka/git/kjappelbaum/gptchem/experiments/03_classification/mof_water_stability/out/20230201_093054',\n",
       "  'train_filename': '/Users/kevinmaikjablonka/git/kjappelbaum/gptchem/experiments/03_classification/mof_water_stability/out/20230201_093054/train.jsonl',\n",
       "  'valid_filename': 'None',\n",
       "  'model_name': 'ada:ft-lsmoepfl-2023-02-01-12-53-23',\n",
       "  'ft_id': 'ft-Mz05I8tCKTnckdHJuUVVquO3',\n",
       "  'date': '20230201_135431',\n",
       "  'train_file_id': 'file-uVL5nPUysTHBUqO0ThDddN9u',\n",
       "  'valid_file_id': None,\n",
       "  'accuracy': 0.7547169811320755,\n",
       "  'acc_macro': 0.7547169811320755,\n",
       "  'racc': 0.7547169811320755,\n",
       "  'kappa': 0.0,\n",
       "  'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "  'f1_macro': 0.43010752688172044,\n",
       "  'f1_micro': 0.7547169811320755,\n",
       "  'frac_valid': 1.0,\n",
       "  'all_y_true': (#159) [1,1,1,1,0,1,0,1,1,1...],\n",
       "  'all_y_pred': (#159) [1,1,1,1,1,1,1,1,1,1...],\n",
       "  'valid_indices': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102,\n",
       "   103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118,\n",
       "   119,\n",
       "   120,\n",
       "   121,\n",
       "   122,\n",
       "   123,\n",
       "   124,\n",
       "   125,\n",
       "   126,\n",
       "   127,\n",
       "   128,\n",
       "   129,\n",
       "   130,\n",
       "   131,\n",
       "   132,\n",
       "   133,\n",
       "   134,\n",
       "   135,\n",
       "   136,\n",
       "   137,\n",
       "   138,\n",
       "   139,\n",
       "   140,\n",
       "   141,\n",
       "   142,\n",
       "   143,\n",
       "   144,\n",
       "   145,\n",
       "   146,\n",
       "   147,\n",
       "   148,\n",
       "   149,\n",
       "   150,\n",
       "   151,\n",
       "   152,\n",
       "   153,\n",
       "   154,\n",
       "   155,\n",
       "   156,\n",
       "   157,\n",
       "   158],\n",
       "  'might_have_rounded_floats': False},\n",
       " {'train_size': 150,\n",
       "  'predictions': (#19) [1,1,0,1,1,1,1,0,0,1...],\n",
       "  'xgboost': {'accuracy': 0.7368421052631579,\n",
       "   'acc_macro': 0.7368421052631579,\n",
       "   'racc': 0.5872576177285318,\n",
       "   'kappa': 0.3624161073825503,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.6801346801346801,\n",
       "   'f1_micro': 0.7368421052631579,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#19) [1,1,1,1,0,1,1,1,0,1...],\n",
       "   'all_y_pred': array([0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'tabpfn': {'accuracy': 0.7368421052631579,\n",
       "   'acc_macro': 0.7368421052631579,\n",
       "   'racc': 0.6869806094182825,\n",
       "   'kappa': 0.15929203539822998,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.5622119815668203,\n",
       "   'f1_micro': 0.7368421052631579,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#19) [1,1,1,1,0,1,1,1,0,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'base_model': 'ada',\n",
       "  'batch_size': None,\n",
       "  'n_epochs': 8,\n",
       "  'learning_rate_multiplier': 0.02,\n",
       "  'run_name': None,\n",
       "  'wandb_sync': False,\n",
       "  'outdir': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_074358',\n",
       "  'train_filename': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_074358/train.jsonl',\n",
       "  'valid_filename': 'None',\n",
       "  'model_name': 'ada:ft-lsmoepfl-2023-02-06-07-03-31',\n",
       "  'ft_id': 'ft-EeuqfWm5jSMVkg2vJaKLdeAN',\n",
       "  'date': '20230206_080405',\n",
       "  'train_file_id': 'file-KYZ9OlzfC5p83beOOAvXieNP',\n",
       "  'valid_file_id': None,\n",
       "  'accuracy': 0.6842105263157895,\n",
       "  'acc_macro': 0.6842105263157895,\n",
       "  'racc': 0.6620498614958449,\n",
       "  'kappa': 0.06557377049180331,\n",
       "  'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "  'f1_macro': 0.525,\n",
       "  'f1_micro': 0.6842105263157895,\n",
       "  'frac_valid': 1.0,\n",
       "  'all_y_true': (#19) [1,1,1,1,0,1,1,1,0,1...],\n",
       "  'all_y_pred': (#19) [1,1,0,1,1,1,1,0,0,1...],\n",
       "  'valid_indices': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18],\n",
       "  'might_have_rounded_floats': False},\n",
       " {'train_size': 20,\n",
       "  'predictions': (#149) [1,1,1,1,1,1,1,1,1,1...],\n",
       "  'xgboost': {'accuracy': 0.6845637583892618,\n",
       "   'acc_macro': 0.6845637583892618,\n",
       "   'racc': 0.6647448313139048,\n",
       "   'kappa': 0.05911594787048223,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.526984126984127,\n",
       "   'f1_micro': 0.6845637583892618,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#149) [0,1,0,1,1,1,1,1,1,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "          1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "          1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "          1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118,\n",
       "    119,\n",
       "    120,\n",
       "    121,\n",
       "    122,\n",
       "    123,\n",
       "    124,\n",
       "    125,\n",
       "    126,\n",
       "    127,\n",
       "    128,\n",
       "    129,\n",
       "    130,\n",
       "    131,\n",
       "    132,\n",
       "    133,\n",
       "    134,\n",
       "    135,\n",
       "    136,\n",
       "    137,\n",
       "    138,\n",
       "    139,\n",
       "    140,\n",
       "    141,\n",
       "    142,\n",
       "    143,\n",
       "    144,\n",
       "    145,\n",
       "    146,\n",
       "    147,\n",
       "    148],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'tabpfn': {'accuracy': 0.7651006711409396,\n",
       "   'acc_macro': 0.7651006711409396,\n",
       "   'racc': 0.7341110760776541,\n",
       "   'kappa': 0.11655090631882105,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.5243958048335613,\n",
       "   'f1_micro': 0.7651006711409396,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#149) [0,1,0,1,1,1,1,1,1,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118,\n",
       "    119,\n",
       "    120,\n",
       "    121,\n",
       "    122,\n",
       "    123,\n",
       "    124,\n",
       "    125,\n",
       "    126,\n",
       "    127,\n",
       "    128,\n",
       "    129,\n",
       "    130,\n",
       "    131,\n",
       "    132,\n",
       "    133,\n",
       "    134,\n",
       "    135,\n",
       "    136,\n",
       "    137,\n",
       "    138,\n",
       "    139,\n",
       "    140,\n",
       "    141,\n",
       "    142,\n",
       "    143,\n",
       "    144,\n",
       "    145,\n",
       "    146,\n",
       "    147,\n",
       "    148],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'base_model': 'ada',\n",
       "  'batch_size': None,\n",
       "  'n_epochs': 8,\n",
       "  'learning_rate_multiplier': 0.02,\n",
       "  'run_name': None,\n",
       "  'wandb_sync': False,\n",
       "  'outdir': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_093100',\n",
       "  'train_filename': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_093100/train.jsonl',\n",
       "  'valid_filename': 'None',\n",
       "  'model_name': 'ada:ft-lsmoepfl-2023-02-06-10-52-39',\n",
       "  'ft_id': 'ft-05kWypRz5xStuP3vJhmjgqnO',\n",
       "  'date': '20230206_115341',\n",
       "  'train_file_id': 'file-owL6M66HTBRaNgEr9Gox4ftg',\n",
       "  'valid_file_id': None,\n",
       "  'accuracy': 0.7583892617449665,\n",
       "  'acc_macro': 0.7583892617449665,\n",
       "  'racc': 0.7583892617449665,\n",
       "  'kappa': 0.0,\n",
       "  'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "  'f1_macro': 0.4312977099236641,\n",
       "  'f1_micro': 0.7583892617449665,\n",
       "  'frac_valid': 1.0,\n",
       "  'all_y_true': (#149) [0,1,0,1,1,1,1,1,1,1...],\n",
       "  'all_y_pred': (#149) [1,1,1,1,1,1,1,1,1,1...],\n",
       "  'valid_indices': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102,\n",
       "   103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118,\n",
       "   119,\n",
       "   120,\n",
       "   121,\n",
       "   122,\n",
       "   123,\n",
       "   124,\n",
       "   125,\n",
       "   126,\n",
       "   127,\n",
       "   128,\n",
       "   129,\n",
       "   130,\n",
       "   131,\n",
       "   132,\n",
       "   133,\n",
       "   134,\n",
       "   135,\n",
       "   136,\n",
       "   137,\n",
       "   138,\n",
       "   139,\n",
       "   140,\n",
       "   141,\n",
       "   142,\n",
       "   143,\n",
       "   144,\n",
       "   145,\n",
       "   146,\n",
       "   147,\n",
       "   148],\n",
       "  'might_have_rounded_floats': False},\n",
       " {'train_size': 10,\n",
       "  'predictions': (#159) [1,1,1,1,1,1,1,1,1,1...],\n",
       "  'xgboost': {'accuracy': 0.7547169811320755,\n",
       "   'acc_macro': 0.7547169811320755,\n",
       "   'racc': 0.7547169811320755,\n",
       "   'kappa': 0.0,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.43010752688172044,\n",
       "   'f1_micro': 0.7547169811320755,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#159) [1,1,0,1,1,1,1,1,1,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118,\n",
       "    119,\n",
       "    120,\n",
       "    121,\n",
       "    122,\n",
       "    123,\n",
       "    124,\n",
       "    125,\n",
       "    126,\n",
       "    127,\n",
       "    128,\n",
       "    129,\n",
       "    130,\n",
       "    131,\n",
       "    132,\n",
       "    133,\n",
       "    134,\n",
       "    135,\n",
       "    136,\n",
       "    137,\n",
       "    138,\n",
       "    139,\n",
       "    140,\n",
       "    141,\n",
       "    142,\n",
       "    143,\n",
       "    144,\n",
       "    145,\n",
       "    146,\n",
       "    147,\n",
       "    148,\n",
       "    149,\n",
       "    150,\n",
       "    151,\n",
       "    152,\n",
       "    153,\n",
       "    154,\n",
       "    155,\n",
       "    156,\n",
       "    157,\n",
       "    158],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'tabpfn': {'accuracy': 0.7547169811320755,\n",
       "   'acc_macro': 0.7547169811320755,\n",
       "   'racc': 0.7547169811320755,\n",
       "   'kappa': 0.0,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.43010752688172044,\n",
       "   'f1_micro': 0.7547169811320755,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#159) [1,1,0,1,1,1,1,1,1,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118,\n",
       "    119,\n",
       "    120,\n",
       "    121,\n",
       "    122,\n",
       "    123,\n",
       "    124,\n",
       "    125,\n",
       "    126,\n",
       "    127,\n",
       "    128,\n",
       "    129,\n",
       "    130,\n",
       "    131,\n",
       "    132,\n",
       "    133,\n",
       "    134,\n",
       "    135,\n",
       "    136,\n",
       "    137,\n",
       "    138,\n",
       "    139,\n",
       "    140,\n",
       "    141,\n",
       "    142,\n",
       "    143,\n",
       "    144,\n",
       "    145,\n",
       "    146,\n",
       "    147,\n",
       "    148,\n",
       "    149,\n",
       "    150,\n",
       "    151,\n",
       "    152,\n",
       "    153,\n",
       "    154,\n",
       "    155,\n",
       "    156,\n",
       "    157,\n",
       "    158],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'base_model': 'ada',\n",
       "  'batch_size': None,\n",
       "  'n_epochs': 8,\n",
       "  'learning_rate_multiplier': 0.02,\n",
       "  'run_name': None,\n",
       "  'wandb_sync': False,\n",
       "  'outdir': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_022914',\n",
       "  'train_filename': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_022914/train.jsonl',\n",
       "  'valid_filename': 'None',\n",
       "  'model_name': 'ada:ft-lsmoepfl-2023-02-06-01-44-35',\n",
       "  'ft_id': 'ft-PXgEhwelUAyzETFXo9e6n4gy',\n",
       "  'date': '20230206_024520',\n",
       "  'train_file_id': 'file-7V019B5lysvjIqVmgOoZ56OZ',\n",
       "  'valid_file_id': None,\n",
       "  'accuracy': 0.7547169811320755,\n",
       "  'acc_macro': 0.7547169811320755,\n",
       "  'racc': 0.7547169811320755,\n",
       "  'kappa': 0.0,\n",
       "  'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "  'f1_macro': 0.43010752688172044,\n",
       "  'f1_micro': 0.7547169811320755,\n",
       "  'frac_valid': 1.0,\n",
       "  'all_y_true': (#159) [1,1,0,1,1,1,1,1,1,1...],\n",
       "  'all_y_pred': (#159) [1,1,1,1,1,1,1,1,1,1...],\n",
       "  'valid_indices': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102,\n",
       "   103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118,\n",
       "   119,\n",
       "   120,\n",
       "   121,\n",
       "   122,\n",
       "   123,\n",
       "   124,\n",
       "   125,\n",
       "   126,\n",
       "   127,\n",
       "   128,\n",
       "   129,\n",
       "   130,\n",
       "   131,\n",
       "   132,\n",
       "   133,\n",
       "   134,\n",
       "   135,\n",
       "   136,\n",
       "   137,\n",
       "   138,\n",
       "   139,\n",
       "   140,\n",
       "   141,\n",
       "   142,\n",
       "   143,\n",
       "   144,\n",
       "   145,\n",
       "   146,\n",
       "   147,\n",
       "   148,\n",
       "   149,\n",
       "   150,\n",
       "   151,\n",
       "   152,\n",
       "   153,\n",
       "   154,\n",
       "   155,\n",
       "   156,\n",
       "   157,\n",
       "   158],\n",
       "  'might_have_rounded_floats': False},\n",
       " {'train_size': 10,\n",
       "  'predictions': (#159) [1,1,1,1,1,1,1,1,1,1...],\n",
       "  'xgboost': {'accuracy': 0.7547169811320755,\n",
       "   'acc_macro': 0.7547169811320755,\n",
       "   'racc': 0.7547169811320755,\n",
       "   'kappa': 0.0,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.43010752688172044,\n",
       "   'f1_micro': 0.7547169811320755,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#159) [1,1,1,1,0,1,1,1,1,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118,\n",
       "    119,\n",
       "    120,\n",
       "    121,\n",
       "    122,\n",
       "    123,\n",
       "    124,\n",
       "    125,\n",
       "    126,\n",
       "    127,\n",
       "    128,\n",
       "    129,\n",
       "    130,\n",
       "    131,\n",
       "    132,\n",
       "    133,\n",
       "    134,\n",
       "    135,\n",
       "    136,\n",
       "    137,\n",
       "    138,\n",
       "    139,\n",
       "    140,\n",
       "    141,\n",
       "    142,\n",
       "    143,\n",
       "    144,\n",
       "    145,\n",
       "    146,\n",
       "    147,\n",
       "    148,\n",
       "    149,\n",
       "    150,\n",
       "    151,\n",
       "    152,\n",
       "    153,\n",
       "    154,\n",
       "    155,\n",
       "    156,\n",
       "    157,\n",
       "    158],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'tabpfn': {'accuracy': 0.7672955974842768,\n",
       "   'acc_macro': 0.7672955974842768,\n",
       "   'racc': 0.7483090067639729,\n",
       "   'kappa': 0.07543611504007566,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.48199348419476973,\n",
       "   'f1_micro': 0.7672955974842768,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#159) [1,1,1,1,0,1,1,1,1,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118,\n",
       "    119,\n",
       "    120,\n",
       "    121,\n",
       "    122,\n",
       "    123,\n",
       "    124,\n",
       "    125,\n",
       "    126,\n",
       "    127,\n",
       "    128,\n",
       "    129,\n",
       "    130,\n",
       "    131,\n",
       "    132,\n",
       "    133,\n",
       "    134,\n",
       "    135,\n",
       "    136,\n",
       "    137,\n",
       "    138,\n",
       "    139,\n",
       "    140,\n",
       "    141,\n",
       "    142,\n",
       "    143,\n",
       "    144,\n",
       "    145,\n",
       "    146,\n",
       "    147,\n",
       "    148,\n",
       "    149,\n",
       "    150,\n",
       "    151,\n",
       "    152,\n",
       "    153,\n",
       "    154,\n",
       "    155,\n",
       "    156,\n",
       "    157,\n",
       "    158],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'base_model': 'ada',\n",
       "  'batch_size': None,\n",
       "  'n_epochs': 8,\n",
       "  'learning_rate_multiplier': 0.02,\n",
       "  'run_name': None,\n",
       "  'wandb_sync': False,\n",
       "  'outdir': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_000822',\n",
       "  'train_filename': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_000822/train.jsonl',\n",
       "  'valid_filename': 'None',\n",
       "  'model_name': 'ada:ft-lsmoepfl-2023-02-05-23-13-09',\n",
       "  'ft_id': 'ft-dvX6txqePd6SZCJgjMiLYEwl',\n",
       "  'date': '20230206_001425',\n",
       "  'train_file_id': 'file-wme4Y8Dg3B3YYzwqzrmckl7Z',\n",
       "  'valid_file_id': None,\n",
       "  'accuracy': 0.7547169811320755,\n",
       "  'acc_macro': 0.7547169811320755,\n",
       "  'racc': 0.7547169811320755,\n",
       "  'kappa': 0.0,\n",
       "  'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "  'f1_macro': 0.43010752688172044,\n",
       "  'f1_micro': 0.7547169811320755,\n",
       "  'frac_valid': 1.0,\n",
       "  'all_y_true': (#159) [1,1,1,1,0,1,1,1,1,1...],\n",
       "  'all_y_pred': (#159) [1,1,1,1,1,1,1,1,1,1...],\n",
       "  'valid_indices': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102,\n",
       "   103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118,\n",
       "   119,\n",
       "   120,\n",
       "   121,\n",
       "   122,\n",
       "   123,\n",
       "   124,\n",
       "   125,\n",
       "   126,\n",
       "   127,\n",
       "   128,\n",
       "   129,\n",
       "   130,\n",
       "   131,\n",
       "   132,\n",
       "   133,\n",
       "   134,\n",
       "   135,\n",
       "   136,\n",
       "   137,\n",
       "   138,\n",
       "   139,\n",
       "   140,\n",
       "   141,\n",
       "   142,\n",
       "   143,\n",
       "   144,\n",
       "   145,\n",
       "   146,\n",
       "   147,\n",
       "   148,\n",
       "   149,\n",
       "   150,\n",
       "   151,\n",
       "   152,\n",
       "   153,\n",
       "   154,\n",
       "   155,\n",
       "   156,\n",
       "   157,\n",
       "   158],\n",
       "  'might_have_rounded_floats': False},\n",
       " {'train_size': 20,\n",
       "  'predictions': (#149) [1,1,1,0,1,1,1,1,1,1...],\n",
       "  'xgboost': {'accuracy': 0.7449664429530202,\n",
       "   'acc_macro': 0.7449664429530202,\n",
       "   'racc': 0.6682131435520923,\n",
       "   'kappa': 0.2313331523214771,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.613039912520503,\n",
       "   'f1_micro': 0.7449664429530202,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#149) [0,1,1,1,1,1,1,0,0,1...],\n",
       "   'all_y_pred': array([0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "          1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118,\n",
       "    119,\n",
       "    120,\n",
       "    121,\n",
       "    122,\n",
       "    123,\n",
       "    124,\n",
       "    125,\n",
       "    126,\n",
       "    127,\n",
       "    128,\n",
       "    129,\n",
       "    130,\n",
       "    131,\n",
       "    132,\n",
       "    133,\n",
       "    134,\n",
       "    135,\n",
       "    136,\n",
       "    137,\n",
       "    138,\n",
       "    139,\n",
       "    140,\n",
       "    141,\n",
       "    142,\n",
       "    143,\n",
       "    144,\n",
       "    145,\n",
       "    146,\n",
       "    147,\n",
       "    148],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'tabpfn': {'accuracy': 0.7785234899328859,\n",
       "   'acc_macro': 0.7785234899328859,\n",
       "   'racc': 0.6716814557902797,\n",
       "   'kappa': 0.3254218685690767,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.6598879435567545,\n",
       "   'f1_micro': 0.7785234899328859,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#149) [0,1,1,1,1,1,1,0,0,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "          0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "          1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "          1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118,\n",
       "    119,\n",
       "    120,\n",
       "    121,\n",
       "    122,\n",
       "    123,\n",
       "    124,\n",
       "    125,\n",
       "    126,\n",
       "    127,\n",
       "    128,\n",
       "    129,\n",
       "    130,\n",
       "    131,\n",
       "    132,\n",
       "    133,\n",
       "    134,\n",
       "    135,\n",
       "    136,\n",
       "    137,\n",
       "    138,\n",
       "    139,\n",
       "    140,\n",
       "    141,\n",
       "    142,\n",
       "    143,\n",
       "    144,\n",
       "    145,\n",
       "    146,\n",
       "    147,\n",
       "    148],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'base_model': 'ada',\n",
       "  'batch_size': None,\n",
       "  'n_epochs': 8,\n",
       "  'learning_rate_multiplier': 0.02,\n",
       "  'run_name': None,\n",
       "  'wandb_sync': False,\n",
       "  'outdir': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_001922',\n",
       "  'train_filename': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_001922/train.jsonl',\n",
       "  'valid_filename': 'None',\n",
       "  'model_name': 'ada:ft-lsmoepfl-2023-02-05-23-29-14',\n",
       "  'ft_id': 'ft-veWoQcknQ7jjyPcK6aeoALMD',\n",
       "  'date': '20230206_002927',\n",
       "  'train_file_id': 'file-ETETLe12hZOeNDejke7e7LaO',\n",
       "  'valid_file_id': None,\n",
       "  'accuracy': 0.7449664429530202,\n",
       "  'acc_macro': 0.7449664429530202,\n",
       "  'racc': 0.7306427638394667,\n",
       "  'kappa': 0.05317725752508374,\n",
       "  'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "  'f1_macro': 0.493378668575519,\n",
       "  'f1_micro': 0.7449664429530202,\n",
       "  'frac_valid': 1.0,\n",
       "  'all_y_true': (#149) [0,1,1,1,1,1,1,0,0,1...],\n",
       "  'all_y_pred': (#149) [1,1,1,0,1,1,1,1,1,1...],\n",
       "  'valid_indices': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102,\n",
       "   103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118,\n",
       "   119,\n",
       "   120,\n",
       "   121,\n",
       "   122,\n",
       "   123,\n",
       "   124,\n",
       "   125,\n",
       "   126,\n",
       "   127,\n",
       "   128,\n",
       "   129,\n",
       "   130,\n",
       "   131,\n",
       "   132,\n",
       "   133,\n",
       "   134,\n",
       "   135,\n",
       "   136,\n",
       "   137,\n",
       "   138,\n",
       "   139,\n",
       "   140,\n",
       "   141,\n",
       "   142,\n",
       "   143,\n",
       "   144,\n",
       "   145,\n",
       "   146,\n",
       "   147,\n",
       "   148],\n",
       "  'might_have_rounded_floats': False},\n",
       " {'train_size': 10,\n",
       "  'predictions': (#159) [1,1,0,1,1,1,1,1,1,1...],\n",
       "  'xgboost': {'accuracy': 0.7547169811320755,\n",
       "   'acc_macro': 0.7547169811320755,\n",
       "   'racc': 0.7547169811320755,\n",
       "   'kappa': 0.0,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.43010752688172044,\n",
       "   'f1_micro': 0.7547169811320755,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#159) [1,1,1,1,1,1,0,1,1,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118,\n",
       "    119,\n",
       "    120,\n",
       "    121,\n",
       "    122,\n",
       "    123,\n",
       "    124,\n",
       "    125,\n",
       "    126,\n",
       "    127,\n",
       "    128,\n",
       "    129,\n",
       "    130,\n",
       "    131,\n",
       "    132,\n",
       "    133,\n",
       "    134,\n",
       "    135,\n",
       "    136,\n",
       "    137,\n",
       "    138,\n",
       "    139,\n",
       "    140,\n",
       "    141,\n",
       "    142,\n",
       "    143,\n",
       "    144,\n",
       "    145,\n",
       "    146,\n",
       "    147,\n",
       "    148,\n",
       "    149,\n",
       "    150,\n",
       "    151,\n",
       "    152,\n",
       "    153,\n",
       "    154,\n",
       "    155,\n",
       "    156,\n",
       "    157,\n",
       "    158],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'tabpfn': {'accuracy': 0.7735849056603774,\n",
       "   'acc_macro': 0.7735849056603774,\n",
       "   'racc': 0.7451050195799217,\n",
       "   'kappa': 0.11173184357541911,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.5062111801242236,\n",
       "   'f1_micro': 0.7735849056603774,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#159) [1,1,1,1,1,1,0,1,1,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118,\n",
       "    119,\n",
       "    120,\n",
       "    121,\n",
       "    122,\n",
       "    123,\n",
       "    124,\n",
       "    125,\n",
       "    126,\n",
       "    127,\n",
       "    128,\n",
       "    129,\n",
       "    130,\n",
       "    131,\n",
       "    132,\n",
       "    133,\n",
       "    134,\n",
       "    135,\n",
       "    136,\n",
       "    137,\n",
       "    138,\n",
       "    139,\n",
       "    140,\n",
       "    141,\n",
       "    142,\n",
       "    143,\n",
       "    144,\n",
       "    145,\n",
       "    146,\n",
       "    147,\n",
       "    148,\n",
       "    149,\n",
       "    150,\n",
       "    151,\n",
       "    152,\n",
       "    153,\n",
       "    154,\n",
       "    155,\n",
       "    156,\n",
       "    157,\n",
       "    158],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'base_model': 'ada',\n",
       "  'batch_size': None,\n",
       "  'n_epochs': 8,\n",
       "  'learning_rate_multiplier': 0.02,\n",
       "  'run_name': None,\n",
       "  'wandb_sync': False,\n",
       "  'outdir': '/Users/kevinmaikjablonka/git/kjappelbaum/gptchem/experiments/03_classification/mof_water_stability/out/20230131_222923',\n",
       "  'train_filename': '/Users/kevinmaikjablonka/git/kjappelbaum/gptchem/experiments/03_classification/mof_water_stability/out/20230131_222923/train.jsonl',\n",
       "  'valid_filename': 'None',\n",
       "  'model_name': 'ada:ft-lsmoepfl-2023-01-31-23-36-07',\n",
       "  'ft_id': 'ft-mXMkYScpirIOAIvZxKHBsvlU',\n",
       "  'date': '20230201_003609',\n",
       "  'train_file_id': 'file-MQkmjZoXsPcCqMox73Pfs057',\n",
       "  'valid_file_id': None,\n",
       "  'accuracy': 0.5849056603773585,\n",
       "  'acc_macro': 0.5849056603773585,\n",
       "  'racc': 0.6489854040583837,\n",
       "  'kappa': -0.18255578093306263,\n",
       "  'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "  'f1_macro': 0.40752032520325204,\n",
       "  'f1_micro': 0.5849056603773585,\n",
       "  'frac_valid': 1.0,\n",
       "  'all_y_true': (#159) [1,1,1,1,1,1,0,1,1,1...],\n",
       "  'all_y_pred': (#159) [1,1,0,1,1,1,1,1,1,1...],\n",
       "  'valid_indices': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102,\n",
       "   103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118,\n",
       "   119,\n",
       "   120,\n",
       "   121,\n",
       "   122,\n",
       "   123,\n",
       "   124,\n",
       "   125,\n",
       "   126,\n",
       "   127,\n",
       "   128,\n",
       "   129,\n",
       "   130,\n",
       "   131,\n",
       "   132,\n",
       "   133,\n",
       "   134,\n",
       "   135,\n",
       "   136,\n",
       "   137,\n",
       "   138,\n",
       "   139,\n",
       "   140,\n",
       "   141,\n",
       "   142,\n",
       "   143,\n",
       "   144,\n",
       "   145,\n",
       "   146,\n",
       "   147,\n",
       "   148,\n",
       "   149,\n",
       "   150,\n",
       "   151,\n",
       "   152,\n",
       "   153,\n",
       "   154,\n",
       "   155,\n",
       "   156,\n",
       "   157,\n",
       "   158],\n",
       "  'might_have_rounded_floats': False},\n",
       " {'train_size': 50,\n",
       "  'predictions': (#119) [1,1,1,1,1,1,1,1,1,0...],\n",
       "  'xgboost': {'accuracy': 0.6722689075630253,\n",
       "   'acc_macro': 0.6722689075630253,\n",
       "   'racc': 0.6356895699456253,\n",
       "   'kappa': 0.10040705563093637,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.550159930212271,\n",
       "   'f1_micro': 0.6722689075630253,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#119) [0,1,0,1,1,0,1,1,1,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "          1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "          1, 0, 1, 0, 1, 1, 0, 1, 0]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'tabpfn': {'accuracy': 0.7647058823529411,\n",
       "   'acc_macro': 0.7647058823529411,\n",
       "   'racc': 0.6313819645505261,\n",
       "   'kappa': 0.36168582375478914,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.6808429118773947,\n",
       "   'f1_micro': 0.7647058823529411,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#119) [0,1,0,1,1,0,1,1,1,1...],\n",
       "   'all_y_pred': array([1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "          1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "          1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "          1, 0, 1, 0, 1, 1, 0, 1, 0]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'base_model': 'ada',\n",
       "  'batch_size': None,\n",
       "  'n_epochs': 8,\n",
       "  'learning_rate_multiplier': 0.02,\n",
       "  'run_name': None,\n",
       "  'wandb_sync': False,\n",
       "  'outdir': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_121054',\n",
       "  'train_filename': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_121054/train.jsonl',\n",
       "  'valid_filename': 'None',\n",
       "  'model_name': 'ada:ft-lsmoepfl-2023-02-06-14-56-47',\n",
       "  'ft_id': 'ft-SjcYv7KOKhUTvNm9dtJZStek',\n",
       "  'date': '20230206_155755',\n",
       "  'train_file_id': 'file-F4YK756ojq0kDS0SAPXNzmSe',\n",
       "  'valid_file_id': None,\n",
       "  'accuracy': 0.7394957983193278,\n",
       "  'acc_macro': 0.7394957983193278,\n",
       "  'racc': 0.7304568886378081,\n",
       "  'kappa': 0.03353418915378567,\n",
       "  'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "  'f1_macro': 0.4807881773399015,\n",
       "  'f1_micro': 0.7394957983193278,\n",
       "  'frac_valid': 1.0,\n",
       "  'all_y_true': (#119) [0,1,0,1,1,0,1,1,1,1...],\n",
       "  'all_y_pred': (#119) [1,1,1,1,1,1,1,1,1,0...],\n",
       "  'valid_indices': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102,\n",
       "   103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118],\n",
       "  'might_have_rounded_floats': False},\n",
       " {'train_size': 150,\n",
       "  'predictions': (#19) [1,1,0,1,1,1,1,1,1,1...],\n",
       "  'xgboost': {'accuracy': 0.7894736842105263,\n",
       "   'acc_macro': 0.7894736842105263,\n",
       "   'racc': 0.6620498614958449,\n",
       "   'kappa': 0.3770491803278689,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.6833333333333333,\n",
       "   'f1_micro': 0.7894736842105263,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#19) [0,1,1,1,1,1,1,0,1,0...],\n",
       "   'all_y_pred': array([1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'tabpfn': {'accuracy': 0.7894736842105263,\n",
       "   'acc_macro': 0.7894736842105263,\n",
       "   'racc': 0.7119113573407202,\n",
       "   'kappa': 0.26923076923076933,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.6041666666666666,\n",
       "   'f1_micro': 0.7894736842105263,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#19) [0,1,1,1,1,1,1,0,1,0...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'base_model': 'ada',\n",
       "  'batch_size': None,\n",
       "  'n_epochs': 8,\n",
       "  'learning_rate_multiplier': 0.02,\n",
       "  'run_name': None,\n",
       "  'wandb_sync': False,\n",
       "  'outdir': '/Users/kevinmaikjablonka/git/kjappelbaum/gptchem/experiments/03_classification/mof_water_stability/out/20230131_194732',\n",
       "  'train_filename': '/Users/kevinmaikjablonka/git/kjappelbaum/gptchem/experiments/03_classification/mof_water_stability/out/20230131_194732/train.jsonl',\n",
       "  'valid_filename': 'None',\n",
       "  'model_name': 'ada:ft-lsmoepfl-2023-01-31-21-24-50',\n",
       "  'ft_id': 'ft-irpP4zzvMnPvw9UN3GTzxKFt',\n",
       "  'date': '20230131_222502',\n",
       "  'train_file_id': 'file-qVGXDyxgspJGCXnXbHF16HZT',\n",
       "  'valid_file_id': None,\n",
       "  'accuracy': 0.7894736842105263,\n",
       "  'acc_macro': 0.7894736842105263,\n",
       "  'racc': 0.6620498614958449,\n",
       "  'kappa': 0.3770491803278689,\n",
       "  'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "  'f1_macro': 0.6833333333333333,\n",
       "  'f1_micro': 0.7894736842105263,\n",
       "  'frac_valid': 1.0,\n",
       "  'all_y_true': (#19) [0,1,1,1,1,1,1,0,1,0...],\n",
       "  'all_y_pred': (#19) [1,1,0,1,1,1,1,1,1,1...],\n",
       "  'valid_indices': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18],\n",
       "  'might_have_rounded_floats': False},\n",
       " {'train_size': 100,\n",
       "  'predictions': (#69) [1,1,1,1,1,1,0,1,1,1...],\n",
       "  'xgboost': {'accuracy': 0.782608695652174,\n",
       "   'acc_macro': 0.782608695652174,\n",
       "   'racc': 0.6065952530980886,\n",
       "   'kappa': 0.4474105712760279,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.723039871554723,\n",
       "   'f1_micro': 0.782608695652174,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#69) [0,1,1,1,1,1,0,1,1,1...],\n",
       "   'all_y_pred': array([1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "          1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "          1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'tabpfn': {'accuracy': 0.855072463768116,\n",
       "   'acc_macro': 0.855072463768116,\n",
       "   'racc': 0.6580550304557866,\n",
       "   'kappa': 0.5761670761670762,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.787037037037037,\n",
       "   'f1_micro': 0.855072463768116,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#69) [0,1,1,1,1,1,0,1,1,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "          1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "          1, 0, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'base_model': 'ada',\n",
       "  'batch_size': None,\n",
       "  'n_epochs': 8,\n",
       "  'learning_rate_multiplier': 0.02,\n",
       "  'run_name': None,\n",
       "  'wandb_sync': False,\n",
       "  'outdir': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_160748',\n",
       "  'train_filename': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_160748/train.jsonl',\n",
       "  'valid_filename': 'None',\n",
       "  'model_name': 'ada:ft-lsmoepfl-2023-02-07-00-42-56',\n",
       "  'ft_id': 'ft-Ff7ObTh2P3ai9gBPk13h688J',\n",
       "  'date': '20230207_014423',\n",
       "  'train_file_id': 'file-VUqTzy8n0nGcxDUYYXNz6iRC',\n",
       "  'valid_file_id': None,\n",
       "  'accuracy': 0.8115942028985508,\n",
       "  'acc_macro': 0.8115942028985508,\n",
       "  'racc': 0.6948120142827137,\n",
       "  'kappa': 0.3826565726083967,\n",
       "  'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "  'f1_macro': 0.6824778761061947,\n",
       "  'f1_micro': 0.8115942028985508,\n",
       "  'frac_valid': 1.0,\n",
       "  'all_y_true': (#69) [0,1,1,1,1,1,0,1,1,1...],\n",
       "  'all_y_pred': (#69) [1,1,1,1,1,1,0,1,1,1...],\n",
       "  'valid_indices': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68],\n",
       "  'might_have_rounded_floats': False},\n",
       " {'train_size': 20,\n",
       "  'predictions': (#149) [1,1,1,1,1,1,1,1,1,1...],\n",
       "  'xgboost': {'accuracy': 0.7583892617449665,\n",
       "   'acc_macro': 0.7583892617449665,\n",
       "   'racc': 0.7583892617449665,\n",
       "   'kappa': 0.0,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.4312977099236641,\n",
       "   'f1_micro': 0.7583892617449665,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#149) [0,1,1,0,0,1,1,1,1,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118,\n",
       "    119,\n",
       "    120,\n",
       "    121,\n",
       "    122,\n",
       "    123,\n",
       "    124,\n",
       "    125,\n",
       "    126,\n",
       "    127,\n",
       "    128,\n",
       "    129,\n",
       "    130,\n",
       "    131,\n",
       "    132,\n",
       "    133,\n",
       "    134,\n",
       "    135,\n",
       "    136,\n",
       "    137,\n",
       "    138,\n",
       "    139,\n",
       "    140,\n",
       "    141,\n",
       "    142,\n",
       "    143,\n",
       "    144,\n",
       "    145,\n",
       "    146,\n",
       "    147,\n",
       "    148],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'tabpfn': {'accuracy': 0.7919463087248322,\n",
       "   'acc_macro': 0.7919463087248322,\n",
       "   'racc': 0.7410477005540291,\n",
       "   'kappa': 0.19655592276917702,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.5616399354655025,\n",
       "   'f1_micro': 0.7919463087248322,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#149) [0,1,1,0,0,1,1,1,1,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "          1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118,\n",
       "    119,\n",
       "    120,\n",
       "    121,\n",
       "    122,\n",
       "    123,\n",
       "    124,\n",
       "    125,\n",
       "    126,\n",
       "    127,\n",
       "    128,\n",
       "    129,\n",
       "    130,\n",
       "    131,\n",
       "    132,\n",
       "    133,\n",
       "    134,\n",
       "    135,\n",
       "    136,\n",
       "    137,\n",
       "    138,\n",
       "    139,\n",
       "    140,\n",
       "    141,\n",
       "    142,\n",
       "    143,\n",
       "    144,\n",
       "    145,\n",
       "    146,\n",
       "    147,\n",
       "    148],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'base_model': 'ada',\n",
       "  'batch_size': None,\n",
       "  'n_epochs': 8,\n",
       "  'learning_rate_multiplier': 0.02,\n",
       "  'run_name': None,\n",
       "  'wandb_sync': False,\n",
       "  'outdir': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_025858',\n",
       "  'train_filename': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_025858/train.jsonl',\n",
       "  'valid_filename': 'None',\n",
       "  'model_name': 'ada:ft-lsmoepfl-2023-02-06-02-07-57',\n",
       "  'ft_id': 'ft-tXsBnfMp5XQpD4yyVKWyTgm8',\n",
       "  'date': '20230206_030903',\n",
       "  'train_file_id': 'file-QkRH68yFmWLeJWbEdxLGBUKk',\n",
       "  'valid_file_id': None,\n",
       "  'accuracy': 0.738255033557047,\n",
       "  'acc_macro': 0.738255033557047,\n",
       "  'racc': 0.7271744516012791,\n",
       "  'kappa': 0.040614165428430375,\n",
       "  'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "  'f1_macro': 0.4895915678524374,\n",
       "  'f1_micro': 0.738255033557047,\n",
       "  'frac_valid': 1.0,\n",
       "  'all_y_true': (#149) [0,1,1,0,0,1,1,1,1,1...],\n",
       "  'all_y_pred': (#149) [1,1,1,1,1,1,1,1,1,1...],\n",
       "  'valid_indices': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102,\n",
       "   103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118,\n",
       "   119,\n",
       "   120,\n",
       "   121,\n",
       "   122,\n",
       "   123,\n",
       "   124,\n",
       "   125,\n",
       "   126,\n",
       "   127,\n",
       "   128,\n",
       "   129,\n",
       "   130,\n",
       "   131,\n",
       "   132,\n",
       "   133,\n",
       "   134,\n",
       "   135,\n",
       "   136,\n",
       "   137,\n",
       "   138,\n",
       "   139,\n",
       "   140,\n",
       "   141,\n",
       "   142,\n",
       "   143,\n",
       "   144,\n",
       "   145,\n",
       "   146,\n",
       "   147,\n",
       "   148],\n",
       "  'might_have_rounded_floats': False},\n",
       " {'train_size': 100,\n",
       "  'predictions': (#69) [1,1,1,1,1,1,1,1,1,1...],\n",
       "  'xgboost': {'accuracy': 0.7536231884057971,\n",
       "   'acc_macro': 0.7536231884057971,\n",
       "   'racc': 0.7242176013442554,\n",
       "   'kappa': 0.10662604722010674,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.5225885225885225,\n",
       "   'f1_micro': 0.7536231884057971,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#69) [1,0,0,1,1,1,0,0,1,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'tabpfn': {'accuracy': 0.782608695652174,\n",
       "   'acc_macro': 0.782608695652174,\n",
       "   'racc': 0.7242176013442554,\n",
       "   'kappa': 0.2117288651942119,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.5787545787545787,\n",
       "   'f1_micro': 0.782608695652174,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#69) [1,0,0,1,1,1,0,0,1,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'base_model': 'ada',\n",
       "  'batch_size': None,\n",
       "  'n_epochs': 8,\n",
       "  'learning_rate_multiplier': 0.02,\n",
       "  'run_name': None,\n",
       "  'wandb_sync': False,\n",
       "  'outdir': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_070400',\n",
       "  'train_filename': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_070400/train.jsonl',\n",
       "  'valid_filename': 'None',\n",
       "  'model_name': 'ada:ft-lsmoepfl-2023-02-06-06-08-39',\n",
       "  'ft_id': 'ft-j35Xj1UQxitRcqQjkzfryaca',\n",
       "  'date': '20230206_071003',\n",
       "  'train_file_id': 'file-FdGqkjvBtMEQh6U5wVVPmwuo',\n",
       "  'valid_file_id': None,\n",
       "  'accuracy': 0.782608695652174,\n",
       "  'acc_macro': 0.782608695652174,\n",
       "  'racc': 0.7389203948750263,\n",
       "  'kappa': 0.1673370876910701,\n",
       "  'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "  'f1_macro': 0.5422379478107032,\n",
       "  'f1_micro': 0.782608695652174,\n",
       "  'frac_valid': 1.0,\n",
       "  'all_y_true': (#69) [1,0,0,1,1,1,0,0,1,1...],\n",
       "  'all_y_pred': (#69) [1,1,1,1,1,1,1,1,1,1...],\n",
       "  'valid_indices': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68],\n",
       "  'might_have_rounded_floats': False},\n",
       " {'train_size': 50,\n",
       "  'predictions': (#119) [1,1,1,1,1,1,0,1,1,0...],\n",
       "  'xgboost': {'accuracy': 0.8067226890756303,\n",
       "   'acc_macro': 0.8067226890756303,\n",
       "   'racc': 0.6787656238966174,\n",
       "   'kappa': 0.3983293031435482,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.6951097248524005,\n",
       "   'f1_micro': 0.8067226890756303,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#119) [1,1,1,1,1,1,1,1,1,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "          1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "          1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'tabpfn': {'accuracy': 0.7983193277310925,\n",
       "   'acc_macro': 0.7983193277310925,\n",
       "   'racc': 0.6572275969211214,\n",
       "   'kappa': 0.41161928306551304,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.7047146401985112,\n",
       "   'f1_micro': 0.7983193277310925,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#119) [1,1,1,1,1,1,1,1,1,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "          1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "          1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'base_model': 'ada',\n",
       "  'batch_size': None,\n",
       "  'n_epochs': 8,\n",
       "  'learning_rate_multiplier': 0.02,\n",
       "  'run_name': None,\n",
       "  'wandb_sync': False,\n",
       "  'outdir': '/Users/kevinmaikjablonka/git/kjappelbaum/gptchem/experiments/03_classification/mof_water_stability/out/20230201_041624',\n",
       "  'train_filename': '/Users/kevinmaikjablonka/git/kjappelbaum/gptchem/experiments/03_classification/mof_water_stability/out/20230201_041624/train.jsonl',\n",
       "  'valid_filename': 'None',\n",
       "  'model_name': 'ada:ft-lsmoepfl-2023-02-01-04-58-51',\n",
       "  'ft_id': 'ft-vnJEtCNPlOKN6RRVtMiMQiog',\n",
       "  'date': '20230201_055906',\n",
       "  'train_file_id': 'file-qoS6Bt697muJeGFGjo2wChEy',\n",
       "  'valid_file_id': None,\n",
       "  'accuracy': 0.7563025210084033,\n",
       "  'acc_macro': 0.7563025210084033,\n",
       "  'racc': 0.6787656238966174,\n",
       "  'kappa': 0.2413717300505606,\n",
       "  'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "  'f1_macro': 0.6155731313356355,\n",
       "  'f1_micro': 0.7563025210084033,\n",
       "  'frac_valid': 1.0,\n",
       "  'all_y_true': (#119) [1,1,1,1,1,1,1,1,1,1...],\n",
       "  'all_y_pred': (#119) [1,1,1,1,1,1,0,1,1,0...],\n",
       "  'valid_indices': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102,\n",
       "   103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118],\n",
       "  'might_have_rounded_floats': False},\n",
       " {'train_size': 10,\n",
       "  'predictions': (#159) [1,1,1,1,1,1,1,1,1,1...],\n",
       "  'xgboost': {'accuracy': 0.7547169811320755,\n",
       "   'acc_macro': 0.7547169811320755,\n",
       "   'racc': 0.7547169811320755,\n",
       "   'kappa': 0.0,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.43010752688172044,\n",
       "   'f1_micro': 0.7547169811320755,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#159) [0,1,0,1,1,1,1,1,1,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118,\n",
       "    119,\n",
       "    120,\n",
       "    121,\n",
       "    122,\n",
       "    123,\n",
       "    124,\n",
       "    125,\n",
       "    126,\n",
       "    127,\n",
       "    128,\n",
       "    129,\n",
       "    130,\n",
       "    131,\n",
       "    132,\n",
       "    133,\n",
       "    134,\n",
       "    135,\n",
       "    136,\n",
       "    137,\n",
       "    138,\n",
       "    139,\n",
       "    140,\n",
       "    141,\n",
       "    142,\n",
       "    143,\n",
       "    144,\n",
       "    145,\n",
       "    146,\n",
       "    147,\n",
       "    148,\n",
       "    149,\n",
       "    150,\n",
       "    151,\n",
       "    152,\n",
       "    153,\n",
       "    154,\n",
       "    155,\n",
       "    156,\n",
       "    157,\n",
       "    158],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'tabpfn': {'accuracy': 0.7421383647798742,\n",
       "   'acc_macro': 0.7421383647798742,\n",
       "   'racc': 0.7483090067639729,\n",
       "   'kappa': -0.02451673738802471,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.4259927797833935,\n",
       "   'f1_micro': 0.7421383647798742,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#159) [0,1,0,1,1,1,1,1,1,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118,\n",
       "    119,\n",
       "    120,\n",
       "    121,\n",
       "    122,\n",
       "    123,\n",
       "    124,\n",
       "    125,\n",
       "    126,\n",
       "    127,\n",
       "    128,\n",
       "    129,\n",
       "    130,\n",
       "    131,\n",
       "    132,\n",
       "    133,\n",
       "    134,\n",
       "    135,\n",
       "    136,\n",
       "    137,\n",
       "    138,\n",
       "    139,\n",
       "    140,\n",
       "    141,\n",
       "    142,\n",
       "    143,\n",
       "    144,\n",
       "    145,\n",
       "    146,\n",
       "    147,\n",
       "    148,\n",
       "    149,\n",
       "    150,\n",
       "    151,\n",
       "    152,\n",
       "    153,\n",
       "    154,\n",
       "    155,\n",
       "    156,\n",
       "    157,\n",
       "    158],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'base_model': 'ada',\n",
       "  'batch_size': None,\n",
       "  'n_epochs': 8,\n",
       "  'learning_rate_multiplier': 0.02,\n",
       "  'run_name': None,\n",
       "  'wandb_sync': False,\n",
       "  'outdir': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_081705',\n",
       "  'train_filename': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_081705/train.jsonl',\n",
       "  'valid_filename': 'None',\n",
       "  'model_name': 'ada:ft-lsmoepfl-2023-02-06-08-16-22',\n",
       "  'ft_id': 'ft-xWGtlBLzyuorX3KEawx2rgSg',\n",
       "  'date': '20230206_091723',\n",
       "  'train_file_id': 'file-P32co0Pi3NCLVdaaAYGpuqE6',\n",
       "  'valid_file_id': None,\n",
       "  'accuracy': 0.7358490566037735,\n",
       "  'acc_macro': 0.7358490566037735,\n",
       "  'racc': 0.7451050195799217,\n",
       "  'kappa': -0.03631284916201146,\n",
       "  'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "  'f1_macro': 0.42391304347826086,\n",
       "  'f1_micro': 0.7358490566037735,\n",
       "  'frac_valid': 1.0,\n",
       "  'all_y_true': (#159) [0,1,0,1,1,1,1,1,1,1...],\n",
       "  'all_y_pred': (#159) [1,1,1,1,1,1,1,1,1,1...],\n",
       "  'valid_indices': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102,\n",
       "   103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118,\n",
       "   119,\n",
       "   120,\n",
       "   121,\n",
       "   122,\n",
       "   123,\n",
       "   124,\n",
       "   125,\n",
       "   126,\n",
       "   127,\n",
       "   128,\n",
       "   129,\n",
       "   130,\n",
       "   131,\n",
       "   132,\n",
       "   133,\n",
       "   134,\n",
       "   135,\n",
       "   136,\n",
       "   137,\n",
       "   138,\n",
       "   139,\n",
       "   140,\n",
       "   141,\n",
       "   142,\n",
       "   143,\n",
       "   144,\n",
       "   145,\n",
       "   146,\n",
       "   147,\n",
       "   148,\n",
       "   149,\n",
       "   150,\n",
       "   151,\n",
       "   152,\n",
       "   153,\n",
       "   154,\n",
       "   155,\n",
       "   156,\n",
       "   157,\n",
       "   158],\n",
       "  'might_have_rounded_floats': False},\n",
       " {'train_size': 100,\n",
       "  'predictions': (#69) [0,1,1,0,1,0,1,1,1,1...],\n",
       "  'xgboost': {'accuracy': 0.855072463768116,\n",
       "   'acc_macro': 0.855072463768116,\n",
       "   'racc': 0.6139466498634741,\n",
       "   'kappa': 0.6245919477693145,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.8120915032679739,\n",
       "   'f1_micro': 0.855072463768116,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#69) [1,1,1,1,1,0,1,1,1,1...],\n",
       "   'all_y_pred': array([0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "          0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "          1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "          1, 0, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'tabpfn': {'accuracy': 0.8260869565217391,\n",
       "   'acc_macro': 0.8260869565217391,\n",
       "   'racc': 0.6727578239865575,\n",
       "   'kappa': 0.46854942233632857,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.7311688311688311,\n",
       "   'f1_micro': 0.8260869565217391,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#69) [1,1,1,1,1,0,1,1,1,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "          0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "          1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 0, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'base_model': 'ada',\n",
       "  'batch_size': None,\n",
       "  'n_epochs': 8,\n",
       "  'learning_rate_multiplier': 0.02,\n",
       "  'run_name': None,\n",
       "  'wandb_sync': False,\n",
       "  'outdir': '/Users/kevinmaikjablonka/git/kjappelbaum/gptchem/experiments/03_classification/mof_water_stability/out/20230131_163638',\n",
       "  'train_filename': '/Users/kevinmaikjablonka/git/kjappelbaum/gptchem/experiments/03_classification/mof_water_stability/out/20230131_163638/train.jsonl',\n",
       "  'valid_filename': 'None',\n",
       "  'model_name': 'ada:ft-lsmoepfl-2023-01-31-18-39-59',\n",
       "  'ft_id': 'ft-n1m57ccqoZVxb0ri4bAln4zK',\n",
       "  'date': '20230131_194128',\n",
       "  'train_file_id': 'file-rh7esiZEVMBnVVNBi9kDQoj0',\n",
       "  'valid_file_id': None,\n",
       "  'accuracy': 0.782608695652174,\n",
       "  'acc_macro': 0.782608695652174,\n",
       "  'racc': 0.6360008401596303,\n",
       "  'kappa': 0.40276976341604165,\n",
       "  'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "  'f1_macro': 0.7012987012987013,\n",
       "  'f1_micro': 0.782608695652174,\n",
       "  'frac_valid': 1.0,\n",
       "  'all_y_true': (#69) [1,1,1,1,1,0,1,1,1,1...],\n",
       "  'all_y_pred': (#69) [0,1,1,0,1,0,1,1,1,1...],\n",
       "  'valid_indices': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68],\n",
       "  'might_have_rounded_floats': False},\n",
       " {'train_size': 100,\n",
       "  'predictions': (#69) [1,1,1,1,1,1,1,1,1,1...],\n",
       "  'xgboost': {'accuracy': 0.7101449275362319,\n",
       "   'acc_macro': 0.7101449275362319,\n",
       "   'racc': 0.6433522369250158,\n",
       "   'kappa': 0.18727915194346303,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.5931603773584906,\n",
       "   'f1_micro': 0.7101449275362319,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#69) [1,1,0,0,1,1,1,1,0,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "          1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "          1, 1, 0]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'tabpfn': {'accuracy': 0.8115942028985508,\n",
       "   'acc_macro': 0.8115942028985508,\n",
       "   'racc': 0.6948120142827137,\n",
       "   'kappa': 0.3826565726083967,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.6824778761061947,\n",
       "   'f1_micro': 0.8115942028985508,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#69) [1,1,0,0,1,1,1,1,0,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "          1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "          1, 1, 0]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'base_model': 'ada',\n",
       "  'batch_size': None,\n",
       "  'n_epochs': 8,\n",
       "  'learning_rate_multiplier': 0.02,\n",
       "  'run_name': None,\n",
       "  'wandb_sync': False,\n",
       "  'outdir': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_011620',\n",
       "  'train_filename': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_011620/train.jsonl',\n",
       "  'valid_filename': 'None',\n",
       "  'model_name': 'ada:ft-lsmoepfl-2023-02-06-00-20-55',\n",
       "  'ft_id': 'ft-5Sd6ego8RBNj8sn7vmuhb5jX',\n",
       "  'date': '20230206_012223',\n",
       "  'train_file_id': 'file-GE3DOTlepfXHBVofUtIjmHBL',\n",
       "  'valid_file_id': None,\n",
       "  'accuracy': 0.782608695652174,\n",
       "  'acc_macro': 0.782608695652174,\n",
       "  'racc': 0.6801092207519428,\n",
       "  'kappa': 0.3204202232435984,\n",
       "  'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "  'f1_macro': 0.6546546546546547,\n",
       "  'f1_micro': 0.782608695652174,\n",
       "  'frac_valid': 1.0,\n",
       "  'all_y_true': (#69) [1,1,0,0,1,1,1,1,0,1...],\n",
       "  'all_y_pred': (#69) [1,1,1,1,1,1,1,1,1,1...],\n",
       "  'valid_indices': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68],\n",
       "  'might_have_rounded_floats': False},\n",
       " {'train_size': 10,\n",
       "  'predictions': (#159) [1,1,1,1,1,1,1,1,1,1...],\n",
       "  'xgboost': {'accuracy': 0.7547169811320755,\n",
       "   'acc_macro': 0.7547169811320755,\n",
       "   'racc': 0.7547169811320755,\n",
       "   'kappa': 0.0,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.43010752688172044,\n",
       "   'f1_micro': 0.7547169811320755,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#159) [1,1,1,1,0,1,0,1,1,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118,\n",
       "    119,\n",
       "    120,\n",
       "    121,\n",
       "    122,\n",
       "    123,\n",
       "    124,\n",
       "    125,\n",
       "    126,\n",
       "    127,\n",
       "    128,\n",
       "    129,\n",
       "    130,\n",
       "    131,\n",
       "    132,\n",
       "    133,\n",
       "    134,\n",
       "    135,\n",
       "    136,\n",
       "    137,\n",
       "    138,\n",
       "    139,\n",
       "    140,\n",
       "    141,\n",
       "    142,\n",
       "    143,\n",
       "    144,\n",
       "    145,\n",
       "    146,\n",
       "    147,\n",
       "    148,\n",
       "    149,\n",
       "    150,\n",
       "    151,\n",
       "    152,\n",
       "    153,\n",
       "    154,\n",
       "    155,\n",
       "    156,\n",
       "    157,\n",
       "    158],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'tabpfn': {'accuracy': 0.7672955974842768,\n",
       "   'acc_macro': 0.7672955974842768,\n",
       "   'racc': 0.7419010323958705,\n",
       "   'kappa': 0.09839080459770119,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.5024947145877379,\n",
       "   'f1_micro': 0.7672955974842768,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#159) [1,1,1,1,0,1,0,1,1,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118,\n",
       "    119,\n",
       "    120,\n",
       "    121,\n",
       "    122,\n",
       "    123,\n",
       "    124,\n",
       "    125,\n",
       "    126,\n",
       "    127,\n",
       "    128,\n",
       "    129,\n",
       "    130,\n",
       "    131,\n",
       "    132,\n",
       "    133,\n",
       "    134,\n",
       "    135,\n",
       "    136,\n",
       "    137,\n",
       "    138,\n",
       "    139,\n",
       "    140,\n",
       "    141,\n",
       "    142,\n",
       "    143,\n",
       "    144,\n",
       "    145,\n",
       "    146,\n",
       "    147,\n",
       "    148,\n",
       "    149,\n",
       "    150,\n",
       "    151,\n",
       "    152,\n",
       "    153,\n",
       "    154,\n",
       "    155,\n",
       "    156,\n",
       "    157,\n",
       "    158],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'base_model': 'ada',\n",
       "  'batch_size': None,\n",
       "  'n_epochs': 8,\n",
       "  'learning_rate_multiplier': 0.02,\n",
       "  'run_name': None,\n",
       "  'wandb_sync': False,\n",
       "  'outdir': '/Users/kevinmaikjablonka/git/kjappelbaum/gptchem/experiments/03_classification/mof_water_stability/out/20230131_111441',\n",
       "  'train_filename': '/Users/kevinmaikjablonka/git/kjappelbaum/gptchem/experiments/03_classification/mof_water_stability/out/20230131_111441/train.jsonl',\n",
       "  'valid_filename': 'None',\n",
       "  'model_name': 'ada:ft-lsmoepfl-2023-01-31-10-52-40',\n",
       "  'ft_id': 'ft-GsnbqoPrnkdyjKx8ejMWaSFh',\n",
       "  'date': '20230131_115252',\n",
       "  'train_file_id': 'file-kaZYOo5rChf4xoM3vc2qp6yS',\n",
       "  'valid_file_id': None,\n",
       "  'accuracy': 0.7547169811320755,\n",
       "  'acc_macro': 0.7547169811320755,\n",
       "  'racc': 0.7547169811320755,\n",
       "  'kappa': 0.0,\n",
       "  'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "  'f1_macro': 0.43010752688172044,\n",
       "  'f1_micro': 0.7547169811320755,\n",
       "  'frac_valid': 1.0,\n",
       "  'all_y_true': (#159) [1,1,1,1,0,1,0,1,1,1...],\n",
       "  'all_y_pred': (#159) [1,1,1,1,1,1,1,1,1,1...],\n",
       "  'valid_indices': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102,\n",
       "   103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118,\n",
       "   119,\n",
       "   120,\n",
       "   121,\n",
       "   122,\n",
       "   123,\n",
       "   124,\n",
       "   125,\n",
       "   126,\n",
       "   127,\n",
       "   128,\n",
       "   129,\n",
       "   130,\n",
       "   131,\n",
       "   132,\n",
       "   133,\n",
       "   134,\n",
       "   135,\n",
       "   136,\n",
       "   137,\n",
       "   138,\n",
       "   139,\n",
       "   140,\n",
       "   141,\n",
       "   142,\n",
       "   143,\n",
       "   144,\n",
       "   145,\n",
       "   146,\n",
       "   147,\n",
       "   148,\n",
       "   149,\n",
       "   150,\n",
       "   151,\n",
       "   152,\n",
       "   153,\n",
       "   154,\n",
       "   155,\n",
       "   156,\n",
       "   157,\n",
       "   158],\n",
       "  'might_have_rounded_floats': False},\n",
       " {'train_size': 10,\n",
       "  'predictions': (#159) [1,1,1,1,1,1,1,1,1,1...],\n",
       "  'xgboost': {'accuracy': 0.7547169811320755,\n",
       "   'acc_macro': 0.7547169811320755,\n",
       "   'racc': 0.7547169811320755,\n",
       "   'kappa': 0.0,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.43010752688172044,\n",
       "   'f1_micro': 0.7547169811320755,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#159) [1,1,0,0,1,1,0,1,1,0...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118,\n",
       "    119,\n",
       "    120,\n",
       "    121,\n",
       "    122,\n",
       "    123,\n",
       "    124,\n",
       "    125,\n",
       "    126,\n",
       "    127,\n",
       "    128,\n",
       "    129,\n",
       "    130,\n",
       "    131,\n",
       "    132,\n",
       "    133,\n",
       "    134,\n",
       "    135,\n",
       "    136,\n",
       "    137,\n",
       "    138,\n",
       "    139,\n",
       "    140,\n",
       "    141,\n",
       "    142,\n",
       "    143,\n",
       "    144,\n",
       "    145,\n",
       "    146,\n",
       "    147,\n",
       "    148,\n",
       "    149,\n",
       "    150,\n",
       "    151,\n",
       "    152,\n",
       "    153,\n",
       "    154,\n",
       "    155,\n",
       "    156,\n",
       "    157,\n",
       "    158],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'tabpfn': {'accuracy': 0.7547169811320755,\n",
       "   'acc_macro': 0.7547169811320755,\n",
       "   'racc': 0.7547169811320755,\n",
       "   'kappa': 0.0,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.43010752688172044,\n",
       "   'f1_micro': 0.7547169811320755,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#159) [1,1,0,0,1,1,0,1,1,0...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118,\n",
       "    119,\n",
       "    120,\n",
       "    121,\n",
       "    122,\n",
       "    123,\n",
       "    124,\n",
       "    125,\n",
       "    126,\n",
       "    127,\n",
       "    128,\n",
       "    129,\n",
       "    130,\n",
       "    131,\n",
       "    132,\n",
       "    133,\n",
       "    134,\n",
       "    135,\n",
       "    136,\n",
       "    137,\n",
       "    138,\n",
       "    139,\n",
       "    140,\n",
       "    141,\n",
       "    142,\n",
       "    143,\n",
       "    144,\n",
       "    145,\n",
       "    146,\n",
       "    147,\n",
       "    148,\n",
       "    149,\n",
       "    150,\n",
       "    151,\n",
       "    152,\n",
       "    153,\n",
       "    154,\n",
       "    155,\n",
       "    156,\n",
       "    157,\n",
       "    158],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'base_model': 'ada',\n",
       "  'batch_size': None,\n",
       "  'n_epochs': 8,\n",
       "  'learning_rate_multiplier': 0.02,\n",
       "  'run_name': None,\n",
       "  'wandb_sync': False,\n",
       "  'outdir': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_053456',\n",
       "  'train_filename': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_053456/train.jsonl',\n",
       "  'valid_filename': 'None',\n",
       "  'model_name': 'ada:ft-lsmoepfl-2023-02-06-04-47-02',\n",
       "  'ft_id': 'ft-aJoHg5hlbRmwMbCGzbr8PBxc',\n",
       "  'date': '20230206_054901',\n",
       "  'train_file_id': 'file-1i0xijplnU0ZTDp6kKxm9yeO',\n",
       "  'valid_file_id': None,\n",
       "  'accuracy': 0.7547169811320755,\n",
       "  'acc_macro': 0.7547169811320755,\n",
       "  'racc': 0.7547169811320755,\n",
       "  'kappa': 0.0,\n",
       "  'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "  'f1_macro': 0.43010752688172044,\n",
       "  'f1_micro': 0.7547169811320755,\n",
       "  'frac_valid': 1.0,\n",
       "  'all_y_true': (#159) [1,1,0,0,1,1,0,1,1,0...],\n",
       "  'all_y_pred': (#159) [1,1,1,1,1,1,1,1,1,1...],\n",
       "  'valid_indices': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102,\n",
       "   103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118,\n",
       "   119,\n",
       "   120,\n",
       "   121,\n",
       "   122,\n",
       "   123,\n",
       "   124,\n",
       "   125,\n",
       "   126,\n",
       "   127,\n",
       "   128,\n",
       "   129,\n",
       "   130,\n",
       "   131,\n",
       "   132,\n",
       "   133,\n",
       "   134,\n",
       "   135,\n",
       "   136,\n",
       "   137,\n",
       "   138,\n",
       "   139,\n",
       "   140,\n",
       "   141,\n",
       "   142,\n",
       "   143,\n",
       "   144,\n",
       "   145,\n",
       "   146,\n",
       "   147,\n",
       "   148,\n",
       "   149,\n",
       "   150,\n",
       "   151,\n",
       "   152,\n",
       "   153,\n",
       "   154,\n",
       "   155,\n",
       "   156,\n",
       "   157,\n",
       "   158],\n",
       "  'might_have_rounded_floats': False},\n",
       " {'train_size': 150,\n",
       "  'predictions': (#19) [0,1,1,1,0,1,1,1,1,1...],\n",
       "  'xgboost': {'accuracy': 0.9473684210526315,\n",
       "   'acc_macro': 0.9473684210526315,\n",
       "   'racc': 0.6371191135734072,\n",
       "   'kappa': 0.8549618320610686,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.9272030651340997,\n",
       "   'f1_micro': 0.9473684210526315,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#19) [0,1,0,1,0,1,1,1,1,1...],\n",
       "   'all_y_pred': array([0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'tabpfn': {'accuracy': 0.8947368421052632,\n",
       "   'acc_macro': 0.8947368421052632,\n",
       "   'racc': 0.6620498614958449,\n",
       "   'kappa': 0.6885245901639344,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.8416666666666667,\n",
       "   'f1_micro': 0.8947368421052632,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#19) [0,1,0,1,0,1,1,1,1,1...],\n",
       "   'all_y_pred': array([0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'base_model': 'ada',\n",
       "  'batch_size': None,\n",
       "  'n_epochs': 8,\n",
       "  'learning_rate_multiplier': 0.02,\n",
       "  'run_name': None,\n",
       "  'wandb_sync': False,\n",
       "  'outdir': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_051217',\n",
       "  'train_filename': '/home/kevin/Documents/gptchem/experiments/03_classification/mof_water_stability/out/20230206_051217/train.jsonl',\n",
       "  'valid_filename': 'None',\n",
       "  'model_name': 'ada:ft-lsmoepfl-2023-02-06-04-22-13',\n",
       "  'ft_id': 'ft-S9N1795lFU0f0J73fEVAC7xy',\n",
       "  'date': '20230206_052222',\n",
       "  'train_file_id': 'file-qkShWzFncOfzXmdT6UZTM2GC',\n",
       "  'valid_file_id': None,\n",
       "  'accuracy': 0.8421052631578947,\n",
       "  'acc_macro': 0.8421052631578947,\n",
       "  'racc': 0.6869806094182825,\n",
       "  'kappa': 0.49557522123893794,\n",
       "  'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "  'f1_macro': 0.7373271889400921,\n",
       "  'f1_micro': 0.8421052631578947,\n",
       "  'frac_valid': 1.0,\n",
       "  'all_y_true': (#19) [0,1,0,1,0,1,1,1,1,1...],\n",
       "  'all_y_pred': (#19) [0,1,1,1,0,1,1,1,1,1...],\n",
       "  'valid_indices': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18],\n",
       "  'might_have_rounded_floats': False},\n",
       " {'train_size': 20,\n",
       "  'predictions': (#149) [0,1,1,1,1,1,1,1,1,1...],\n",
       "  'xgboost': {'accuracy': 0.7583892617449665,\n",
       "   'acc_macro': 0.7583892617449665,\n",
       "   'racc': 0.7583892617449665,\n",
       "   'kappa': 0.0,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.4312977099236641,\n",
       "   'f1_micro': 0.7583892617449665,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#149) [1,1,1,1,1,1,1,1,1,1...],\n",
       "   'all_y_pred': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118,\n",
       "    119,\n",
       "    120,\n",
       "    121,\n",
       "    122,\n",
       "    123,\n",
       "    124,\n",
       "    125,\n",
       "    126,\n",
       "    127,\n",
       "    128,\n",
       "    129,\n",
       "    130,\n",
       "    131,\n",
       "    132,\n",
       "    133,\n",
       "    134,\n",
       "    135,\n",
       "    136,\n",
       "    137,\n",
       "    138,\n",
       "    139,\n",
       "    140,\n",
       "    141,\n",
       "    142,\n",
       "    143,\n",
       "    144,\n",
       "    145,\n",
       "    146,\n",
       "    147,\n",
       "    148],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'tabpfn': {'accuracy': 0.7248322147651006,\n",
       "   'acc_macro': 0.7248322147651006,\n",
       "   'racc': 0.6647448313139048,\n",
       "   'kappa': 0.1792288055891439,\n",
       "   'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "   'f1_macro': 0.5873691320499831,\n",
       "   'f1_micro': 0.7248322147651006,\n",
       "   'frac_valid': 1.0,\n",
       "   'all_y_true': (#149) [1,1,1,1,1,1,1,1,1,1...],\n",
       "   'all_y_pred': array([0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "          1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "          0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "          1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "          1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1]),\n",
       "   'valid_indices': [0,\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    8,\n",
       "    9,\n",
       "    10,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    15,\n",
       "    16,\n",
       "    17,\n",
       "    18,\n",
       "    19,\n",
       "    20,\n",
       "    21,\n",
       "    22,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    31,\n",
       "    32,\n",
       "    33,\n",
       "    34,\n",
       "    35,\n",
       "    36,\n",
       "    37,\n",
       "    38,\n",
       "    39,\n",
       "    40,\n",
       "    41,\n",
       "    42,\n",
       "    43,\n",
       "    44,\n",
       "    45,\n",
       "    46,\n",
       "    47,\n",
       "    48,\n",
       "    49,\n",
       "    50,\n",
       "    51,\n",
       "    52,\n",
       "    53,\n",
       "    54,\n",
       "    55,\n",
       "    56,\n",
       "    57,\n",
       "    58,\n",
       "    59,\n",
       "    60,\n",
       "    61,\n",
       "    62,\n",
       "    63,\n",
       "    64,\n",
       "    65,\n",
       "    66,\n",
       "    67,\n",
       "    68,\n",
       "    69,\n",
       "    70,\n",
       "    71,\n",
       "    72,\n",
       "    73,\n",
       "    74,\n",
       "    75,\n",
       "    76,\n",
       "    77,\n",
       "    78,\n",
       "    79,\n",
       "    80,\n",
       "    81,\n",
       "    82,\n",
       "    83,\n",
       "    84,\n",
       "    85,\n",
       "    86,\n",
       "    87,\n",
       "    88,\n",
       "    89,\n",
       "    90,\n",
       "    91,\n",
       "    92,\n",
       "    93,\n",
       "    94,\n",
       "    95,\n",
       "    96,\n",
       "    97,\n",
       "    98,\n",
       "    99,\n",
       "    100,\n",
       "    101,\n",
       "    102,\n",
       "    103,\n",
       "    104,\n",
       "    105,\n",
       "    106,\n",
       "    107,\n",
       "    108,\n",
       "    109,\n",
       "    110,\n",
       "    111,\n",
       "    112,\n",
       "    113,\n",
       "    114,\n",
       "    115,\n",
       "    116,\n",
       "    117,\n",
       "    118,\n",
       "    119,\n",
       "    120,\n",
       "    121,\n",
       "    122,\n",
       "    123,\n",
       "    124,\n",
       "    125,\n",
       "    126,\n",
       "    127,\n",
       "    128,\n",
       "    129,\n",
       "    130,\n",
       "    131,\n",
       "    132,\n",
       "    133,\n",
       "    134,\n",
       "    135,\n",
       "    136,\n",
       "    137,\n",
       "    138,\n",
       "    139,\n",
       "    140,\n",
       "    141,\n",
       "    142,\n",
       "    143,\n",
       "    144,\n",
       "    145,\n",
       "    146,\n",
       "    147,\n",
       "    148],\n",
       "   'might_have_rounded_floats': False},\n",
       "  'base_model': 'ada',\n",
       "  'batch_size': None,\n",
       "  'n_epochs': 8,\n",
       "  'learning_rate_multiplier': 0.02,\n",
       "  'run_name': None,\n",
       "  'wandb_sync': False,\n",
       "  'outdir': '/Users/kevinmaikjablonka/git/kjappelbaum/gptchem/experiments/03_classification/mof_water_stability/out/20230131_115701',\n",
       "  'train_filename': '/Users/kevinmaikjablonka/git/kjappelbaum/gptchem/experiments/03_classification/mof_water_stability/out/20230131_115701/train.jsonl',\n",
       "  'valid_filename': 'None',\n",
       "  'model_name': 'ada:ft-lsmoepfl-2023-01-31-13-50-10',\n",
       "  'ft_id': 'ft-qcyBD7Ce0T0bEyIPTRJk5pEy',\n",
       "  'date': '20230131_150323',\n",
       "  'train_file_id': 'file-VcyhDkl1Ou59ESo3nWhXmELq',\n",
       "  'valid_file_id': None,\n",
       "  'accuracy': 0.7651006711409396,\n",
       "  'acc_macro': 0.7651006711409396,\n",
       "  'racc': 0.747984325030404,\n",
       "  'kappa': 0.0679177837354782,\n",
       "  'confusion_matrix': pycm.ConfusionMatrix(classes: [0, 1]),\n",
       "  'f1_macro': 0.4837144837144837,\n",
       "  'f1_micro': 0.7651006711409396,\n",
       "  'frac_valid': 1.0,\n",
       "  'all_y_true': (#149) [1,1,1,1,1,1,1,1,1,1...],\n",
       "  'all_y_pred': (#149) [0,1,1,1,1,1,1,1,1,1...],\n",
       "  'valid_indices': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102,\n",
       "   103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118,\n",
       "   119,\n",
       "   120,\n",
       "   121,\n",
       "   122,\n",
       "   123,\n",
       "   124,\n",
       "   125,\n",
       "   126,\n",
       "   127,\n",
       "   128,\n",
       "   129,\n",
       "   130,\n",
       "   131,\n",
       "   132,\n",
       "   133,\n",
       "   134,\n",
       "   135,\n",
       "   136,\n",
       "   137,\n",
       "   138,\n",
       "   139,\n",
       "   140,\n",
       "   141,\n",
       "   142,\n",
       "   143,\n",
       "   144,\n",
       "   145,\n",
       "   146,\n",
       "   147,\n",
       "   148],\n",
       "  'might_have_rounded_floats': False}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_res = []\n",
    "xgboost_results = []\n",
    "tabpfn_results = []\n",
    "dummy_results = []\n",
    "\n",
    "for out in all_out:\n",
    "    res = {\n",
    "        \"train_size\": out[\"train_size\"],\n",
    "        \"frac_valid\": out[\"frac_valid\"],\n",
    "        \"accuracy\": out[\"accuracy\"],\n",
    "        \"f1_macro\": out[\"f1_macro\"],\n",
    "        \"f1_micro\": out[\"f1_micro\"],\n",
    "        \"kappa\": out[\"kappa\"],\n",
    "    }\n",
    "\n",
    "    xgb_res = {\n",
    "        \"train_size\": out[\"train_size\"],\n",
    "        \"accuracy\": out[\"xgboost\"][\"accuracy\"],\n",
    "        \"f1_macro\": out[\"xgboost\"][\"f1_macro\"],\n",
    "        \"f1_micro\": out[\"xgboost\"][\"f1_micro\"],\n",
    "        \"kappa\": out[\"xgboost\"][\"kappa\"],\n",
    "    }\n",
    "\n",
    "    tabpfn_res = {\n",
    "        \"train_size\": out[\"train_size\"],\n",
    "        \"accuracy\": out[\"tabpfn\"][\"accuracy\"],\n",
    "        \"f1_macro\": out[\"tabpfn\"][\"f1_macro\"],\n",
    "        \"f1_micro\": out[\"tabpfn\"][\"f1_micro\"],\n",
    "        \"kappa\": out[\"tabpfn\"][\"kappa\"],\n",
    "    }\n",
    "\n",
    "\n",
    "    extracted_res.append(res)\n",
    "    xgboost_results.append(xgb_res)\n",
    "    tabpfn_results.append(tabpfn_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(extracted_res)\n",
    "xgboost_res = pd.DataFrame(xgboost_results)\n",
    "tabpfn_res = pd.DataFrame(tabpfn_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_res = res.groupby([\"train_size\"]).agg([\"mean\", \"std\", \"count\", sem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_xgboost_res = xgboost_res.groupby([\"train_size\"]).agg([\"mean\", \"std\", \"count\", sem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_tabpfn_res = tabpfn_res.groupby([\"train_size\"]).agg([\"mean\", \"std\", \"count\", sem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">frac_valid</th>\n",
       "      <th colspan=\"4\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1_macro</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1_micro</th>\n",
       "      <th colspan=\"4\" halign=\"left\">kappa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>sem</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.727763</td>\n",
       "      <td>0.063385</td>\n",
       "      <td>7</td>\n",
       "      <td>0.023957</td>\n",
       "      <td>0.425996</td>\n",
       "      <td>0.008468</td>\n",
       "      <td>7</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.727763</td>\n",
       "      <td>0.063385</td>\n",
       "      <td>7</td>\n",
       "      <td>0.023957</td>\n",
       "      <td>-0.031267</td>\n",
       "      <td>0.068071</td>\n",
       "      <td>7</td>\n",
       "      <td>0.025728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.720358</td>\n",
       "      <td>0.059979</td>\n",
       "      <td>6</td>\n",
       "      <td>0.024486</td>\n",
       "      <td>0.472940</td>\n",
       "      <td>0.022872</td>\n",
       "      <td>6</td>\n",
       "      <td>0.009337</td>\n",
       "      <td>0.720358</td>\n",
       "      <td>0.059979</td>\n",
       "      <td>6</td>\n",
       "      <td>0.024486</td>\n",
       "      <td>0.014122</td>\n",
       "      <td>0.050774</td>\n",
       "      <td>6</td>\n",
       "      <td>0.020728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.035020</td>\n",
       "      <td>6</td>\n",
       "      <td>0.014297</td>\n",
       "      <td>0.523246</td>\n",
       "      <td>0.064122</td>\n",
       "      <td>6</td>\n",
       "      <td>0.026178</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.035020</td>\n",
       "      <td>6</td>\n",
       "      <td>0.014297</td>\n",
       "      <td>0.094469</td>\n",
       "      <td>0.111216</td>\n",
       "      <td>6</td>\n",
       "      <td>0.045404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.779710</td>\n",
       "      <td>0.025925</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011594</td>\n",
       "      <td>0.630832</td>\n",
       "      <td>0.069530</td>\n",
       "      <td>5</td>\n",
       "      <td>0.031095</td>\n",
       "      <td>0.779710</td>\n",
       "      <td>0.025925</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011594</td>\n",
       "      <td>0.287701</td>\n",
       "      <td>0.114882</td>\n",
       "      <td>5</td>\n",
       "      <td>0.051377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.821053</td>\n",
       "      <td>0.088069</td>\n",
       "      <td>5</td>\n",
       "      <td>0.039386</td>\n",
       "      <td>0.730323</td>\n",
       "      <td>0.136710</td>\n",
       "      <td>5</td>\n",
       "      <td>0.061138</td>\n",
       "      <td>0.821053</td>\n",
       "      <td>0.088069</td>\n",
       "      <td>5</td>\n",
       "      <td>0.039386</td>\n",
       "      <td>0.471059</td>\n",
       "      <td>0.268077</td>\n",
       "      <td>5</td>\n",
       "      <td>0.119888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           frac_valid                  accuracy                            \\\n",
       "                 mean  std count  sem      mean       std count       sem   \n",
       "train_size                                                                  \n",
       "10                1.0  0.0     7  0.0  0.727763  0.063385     7  0.023957   \n",
       "20                1.0  0.0     6  0.0  0.720358  0.059979     6  0.024486   \n",
       "50                1.0  0.0     6  0.0  0.738095  0.035020     6  0.014297   \n",
       "100               1.0  0.0     5  0.0  0.779710  0.025925     5  0.011594   \n",
       "150               1.0  0.0     5  0.0  0.821053  0.088069     5  0.039386   \n",
       "\n",
       "            f1_macro                            f1_micro                  \\\n",
       "                mean       std count       sem      mean       std count   \n",
       "train_size                                                                 \n",
       "10          0.425996  0.008468     7  0.003200  0.727763  0.063385     7   \n",
       "20          0.472940  0.022872     6  0.009337  0.720358  0.059979     6   \n",
       "50          0.523246  0.064122     6  0.026178  0.738095  0.035020     6   \n",
       "100         0.630832  0.069530     5  0.031095  0.779710  0.025925     5   \n",
       "150         0.730323  0.136710     5  0.061138  0.821053  0.088069     5   \n",
       "\n",
       "                         kappa                            \n",
       "                 sem      mean       std count       sem  \n",
       "train_size                                                \n",
       "10          0.023957 -0.031267  0.068071     7  0.025728  \n",
       "20          0.024486  0.014122  0.050774     6  0.020728  \n",
       "50          0.014297  0.094469  0.111216     6  0.045404  \n",
       "100         0.011594  0.287701  0.114882     5  0.051377  \n",
       "150         0.039386  0.471059  0.268077     5  0.119888  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_res.loc[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1_macro</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1_micro</th>\n",
       "      <th colspan=\"4\" halign=\"left\">kappa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>sem</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.761006</td>\n",
       "      <td>0.010893</td>\n",
       "      <td>7</td>\n",
       "      <td>0.004117</td>\n",
       "      <td>0.468486</td>\n",
       "      <td>0.038014</td>\n",
       "      <td>7</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.761006</td>\n",
       "      <td>0.010893</td>\n",
       "      <td>7</td>\n",
       "      <td>0.004117</td>\n",
       "      <td>0.051348</td>\n",
       "      <td>0.057273</td>\n",
       "      <td>7</td>\n",
       "      <td>0.021647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.759508</td>\n",
       "      <td>0.024902</td>\n",
       "      <td>6</td>\n",
       "      <td>0.010166</td>\n",
       "      <td>0.548053</td>\n",
       "      <td>0.076185</td>\n",
       "      <td>6</td>\n",
       "      <td>0.031102</td>\n",
       "      <td>0.759508</td>\n",
       "      <td>0.024902</td>\n",
       "      <td>6</td>\n",
       "      <td>0.010166</td>\n",
       "      <td>0.150799</td>\n",
       "      <td>0.110791</td>\n",
       "      <td>6</td>\n",
       "      <td>0.045230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.775910</td>\n",
       "      <td>0.018153</td>\n",
       "      <td>6</td>\n",
       "      <td>0.007411</td>\n",
       "      <td>0.578230</td>\n",
       "      <td>0.114520</td>\n",
       "      <td>6</td>\n",
       "      <td>0.046752</td>\n",
       "      <td>0.775910</td>\n",
       "      <td>0.018153</td>\n",
       "      <td>6</td>\n",
       "      <td>0.007411</td>\n",
       "      <td>0.214988</td>\n",
       "      <td>0.170249</td>\n",
       "      <td>6</td>\n",
       "      <td>0.069504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.030744</td>\n",
       "      <td>5</td>\n",
       "      <td>0.013749</td>\n",
       "      <td>0.711082</td>\n",
       "      <td>0.084724</td>\n",
       "      <td>5</td>\n",
       "      <td>0.037890</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.030744</td>\n",
       "      <td>5</td>\n",
       "      <td>0.013749</td>\n",
       "      <td>0.439245</td>\n",
       "      <td>0.148718</td>\n",
       "      <td>5</td>\n",
       "      <td>0.066509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.057655</td>\n",
       "      <td>5</td>\n",
       "      <td>0.025784</td>\n",
       "      <td>0.683990</td>\n",
       "      <td>0.109603</td>\n",
       "      <td>5</td>\n",
       "      <td>0.049016</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.057655</td>\n",
       "      <td>5</td>\n",
       "      <td>0.025784</td>\n",
       "      <td>0.390248</td>\n",
       "      <td>0.201000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.089890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            accuracy                            f1_macro                  \\\n",
       "                mean       std count       sem      mean       std count   \n",
       "train_size                                                                 \n",
       "10          0.761006  0.010893     7  0.004117  0.468486  0.038014     7   \n",
       "20          0.759508  0.024902     6  0.010166  0.548053  0.076185     6   \n",
       "50          0.775910  0.018153     6  0.007411  0.578230  0.114520     6   \n",
       "100         0.826087  0.030744     5  0.013749  0.711082  0.084724     5   \n",
       "150         0.800000  0.057655     5  0.025784  0.683990  0.109603     5   \n",
       "\n",
       "                      f1_micro                               kappa            \\\n",
       "                 sem      mean       std count       sem      mean       std   \n",
       "train_size                                                                     \n",
       "10          0.014368  0.761006  0.010893     7  0.004117  0.051348  0.057273   \n",
       "20          0.031102  0.759508  0.024902     6  0.010166  0.150799  0.110791   \n",
       "50          0.046752  0.775910  0.018153     6  0.007411  0.214988  0.170249   \n",
       "100         0.037890  0.826087  0.030744     5  0.013749  0.439245  0.148718   \n",
       "150         0.049016  0.800000  0.057655     5  0.025784  0.390248  0.201000   \n",
       "\n",
       "                            \n",
       "           count       sem  \n",
       "train_size                  \n",
       "10             7  0.021647  \n",
       "20             6  0.045230  \n",
       "50             6  0.069504  \n",
       "100            5  0.066509  \n",
       "150            5  0.089890  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_tabpfn_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1_macro</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1_micro</th>\n",
       "      <th colspan=\"4\" halign=\"left\">kappa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>sem</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>4.532467e-17</td>\n",
       "      <td>0.430108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>4.532467e-17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.743848</td>\n",
       "      <td>0.029535</td>\n",
       "      <td>6</td>\n",
       "      <td>1.205773e-02</td>\n",
       "      <td>0.477536</td>\n",
       "      <td>0.076627</td>\n",
       "      <td>6</td>\n",
       "      <td>0.031283</td>\n",
       "      <td>0.743848</td>\n",
       "      <td>0.029535</td>\n",
       "      <td>6</td>\n",
       "      <td>1.205773e-02</td>\n",
       "      <td>0.048408</td>\n",
       "      <td>0.092682</td>\n",
       "      <td>6</td>\n",
       "      <td>0.037837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.743697</td>\n",
       "      <td>0.053081</td>\n",
       "      <td>6</td>\n",
       "      <td>2.167025e-02</td>\n",
       "      <td>0.612356</td>\n",
       "      <td>0.078111</td>\n",
       "      <td>6</td>\n",
       "      <td>0.031889</td>\n",
       "      <td>0.743697</td>\n",
       "      <td>0.053081</td>\n",
       "      <td>6</td>\n",
       "      <td>2.167025e-02</td>\n",
       "      <td>0.235633</td>\n",
       "      <td>0.148388</td>\n",
       "      <td>6</td>\n",
       "      <td>0.060579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.773913</td>\n",
       "      <td>0.052854</td>\n",
       "      <td>5</td>\n",
       "      <td>2.363697e-02</td>\n",
       "      <td>0.667733</td>\n",
       "      <td>0.112836</td>\n",
       "      <td>5</td>\n",
       "      <td>0.050462</td>\n",
       "      <td>0.773913</td>\n",
       "      <td>0.052854</td>\n",
       "      <td>5</td>\n",
       "      <td>2.363697e-02</td>\n",
       "      <td>0.348295</td>\n",
       "      <td>0.206904</td>\n",
       "      <td>5</td>\n",
       "      <td>0.092530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.091161</td>\n",
       "      <td>5</td>\n",
       "      <td>4.076825e-02</td>\n",
       "      <td>0.706604</td>\n",
       "      <td>0.133656</td>\n",
       "      <td>5</td>\n",
       "      <td>0.059773</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.091161</td>\n",
       "      <td>5</td>\n",
       "      <td>4.076825e-02</td>\n",
       "      <td>0.423227</td>\n",
       "      <td>0.257675</td>\n",
       "      <td>5</td>\n",
       "      <td>0.115236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            accuracy                                f1_macro                  \\\n",
       "                mean       std count           sem      mean       std count   \n",
       "train_size                                                                     \n",
       "10          0.754717  0.000000     7  4.532467e-17  0.430108  0.000000     7   \n",
       "20          0.743848  0.029535     6  1.205773e-02  0.477536  0.076627     6   \n",
       "50          0.743697  0.053081     6  2.167025e-02  0.612356  0.078111     6   \n",
       "100         0.773913  0.052854     5  2.363697e-02  0.667733  0.112836     5   \n",
       "150         0.789474  0.091161     5  4.076825e-02  0.706604  0.133656     5   \n",
       "\n",
       "                      f1_micro                                   kappa  \\\n",
       "                 sem      mean       std count           sem      mean   \n",
       "train_size                                                               \n",
       "10          0.000000  0.754717  0.000000     7  4.532467e-17  0.000000   \n",
       "20          0.031283  0.743848  0.029535     6  1.205773e-02  0.048408   \n",
       "50          0.031889  0.743697  0.053081     6  2.167025e-02  0.235633   \n",
       "100         0.050462  0.773913  0.052854     5  2.363697e-02  0.348295   \n",
       "150         0.059773  0.789474  0.091161     5  4.076825e-02  0.423227   \n",
       "\n",
       "                                      \n",
       "                 std count       sem  \n",
       "train_size                            \n",
       "10          0.000000     7  0.000000  \n",
       "20          0.092682     6  0.037837  \n",
       "50          0.148388     6  0.060579  \n",
       "100         0.206904     5  0.092530  \n",
       "150         0.257675     5  0.115236  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_xgboost_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 325x444.984 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# with plt.style.context(matplotx.styles.dufte):\n",
    "fig, ax = plt.subplots(\n",
    "    4, 1, figsize=(ONE_COL_WIDTH_INCH, TWO_COL_GOLDEN_RATIO_HEIGHT_INCH), sharex=\"all\"\n",
    ")\n",
    "\n",
    "# plot the binary case, i.e. num_classes = 2\n",
    "\n",
    "for i, metric in enumerate([\"accuracy\", \"f1_macro\", \"f1_micro\", \"kappa\"]):\n",
    "    ax[i].plot(\n",
    "        grouped_res.loc[ :].index,\n",
    "        grouped_res.loc[:][metric][\"mean\"],\n",
    "        marker=\"o\",\n",
    "        label=\"GPT\",\n",
    "    )\n",
    "    ax[i].fill_between(\n",
    "        grouped_res.loc[ :].index,\n",
    "        grouped_res.loc[:][metric][\"mean\"] - grouped_res.loc[ :][metric][\"sem\"],\n",
    "        grouped_res.loc[ :][metric][\"mean\"] + grouped_res.loc[ :][metric][\"sem\"],\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "    range_frame(\n",
    "        ax[i],\n",
    "        grouped_res.loc[ :].index,\n",
    "        np.stack([\n",
    "            grouped_res.loc[:][metric][\"mean\"],\n",
    "              grouped_xgboost_res.loc[ :][metric][\"mean\"],\n",
    "              grouped_tabpfn_res.loc[ :][metric][\"mean\"], \n",
    "        ]).flatten()\n",
    "    )\n",
    "\n",
    "    ax[i].plot(\n",
    "        grouped_xgboost_res.loc[ :].index,\n",
    "        grouped_xgboost_res.loc[ :][metric][\"mean\"],\n",
    "        marker=\"o\",\n",
    "        label=\"XGBoost\",\n",
    "    )\n",
    "    ax[i].fill_between(\n",
    "        grouped_xgboost_res.loc[ :].index,\n",
    "        grouped_xgboost_res.loc[:][metric][\"mean\"]\n",
    "        - grouped_xgboost_res.loc[ :][metric][\"sem\"],\n",
    "        grouped_xgboost_res.loc[:][metric][\"mean\"]\n",
    "        + grouped_xgboost_res.loc[:][metric][\"sem\"],\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "    ax[i].plot(\n",
    "        grouped_tabpfn_res.loc[ :].index,\n",
    "        grouped_tabpfn_res.loc[ :][metric][\"mean\"],\n",
    "        marker=\"o\",\n",
    "        label=\"TabPFN\",\n",
    "    )\n",
    "    ax[i].fill_between(\n",
    "        grouped_tabpfn_res.loc[ :].index,\n",
    "        grouped_tabpfn_res.loc[:][metric][\"mean\"]\n",
    "        - grouped_tabpfn_res.loc[ :][metric][\"sem\"],\n",
    "        grouped_tabpfn_res.loc[ :][metric][\"mean\"]\n",
    "        + grouped_tabpfn_res.loc[:][metric][\"sem\"],\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "ylabel_top(\"accuracy\", ax=ax[0], x_pad=0.05, y_pad=0.06)\n",
    "ylabel_top(r\"F$_{1}$ macro\", ax=ax[1], x_pad=0.05, y_pad=0.06)\n",
    "ylabel_top(r\"F$_{1}$ micro\", ax=ax[2], x_pad=0.05, y_pad=0.06)\n",
    "ylabel_top(r\"$\\kappa$\", ax=ax[3], x_pad=0.05, y_pad=0.06)\n",
    "ax[-1].set_xlabel(\"number of training points\", labelpad=4)\n",
    "matplotx.line_labels(ax=ax[0])\n",
    "plt.subplots_adjust(hspace=.6, top=1, bottom=.2)\n",
    "\n",
    "fig.savefig(\"mof_water_stability.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.250765306761347"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_learning_curve_intersection(\n",
    "    grouped_res.loc[:][\"f1_macro\"][\"mean\"].values[0],\n",
    "    fit_learning_curve(\n",
    "        grouped_xgboost_res.loc[:].index,\n",
    "        grouped_xgboost_res.loc[ :][\"f1_macro\"][\"mean\"],\n",
    "    )[0],\n",
    ") / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/gptchem/lib/python3.9/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/gptchem/lib/python3.9/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/gptchem/lib/python3.9/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2263\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2273\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 2",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m find_learning_curve_intersection(\n\u001b[0;32m----> 2\u001b[0m     grouped_res\u001b[39m.\u001b[39;49mloc[\u001b[39m2\u001b[39;49m, :][\u001b[39m\"\u001b[39m\u001b[39mf1_macro\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m],\n\u001b[1;32m      3\u001b[0m     fit_learning_curve(\n\u001b[1;32m      4\u001b[0m         grouped_tabpfn_res\u001b[39m.\u001b[39mloc[\u001b[39m2\u001b[39m, :]\u001b[39m.\u001b[39mindex,\n\u001b[1;32m      5\u001b[0m         grouped_tabpfn_res\u001b[39m.\u001b[39mloc[\u001b[39m2\u001b[39m, :][\u001b[39m\"\u001b[39m\u001b[39mf1_macro\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m      6\u001b[0m     )[\u001b[39m0\u001b[39m],\n\u001b[1;32m      7\u001b[0m ) \u001b[39m/\u001b[39m \u001b[39m10\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/gptchem/lib/python3.9/site-packages/pandas/core/indexing.py:1067\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1065\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1066\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[0;32m-> 1067\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[1;32m   1068\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1069\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/gptchem/lib/python3.9/site-packages/pandas/core/indexing.py:1247\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[39mwith\u001b[39;00m suppress(IndexingError):\n\u001b[1;32m   1246\u001b[0m     tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_ellipsis(tup)\n\u001b[0;32m-> 1247\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_lowerdim(tup)\n\u001b[1;32m   1249\u001b[0m \u001b[39m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_tuple_indexer(tup)\n",
      "File \u001b[0;32m~/miniconda3/envs/gptchem/lib/python3.9/site-packages/pandas/core/indexing.py:941\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[39m# we may have a nested tuples indexer here\u001b[39;00m\n\u001b[1;32m    940\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_nested_tuple_indexer(tup):\n\u001b[0;32m--> 941\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_nested_tuple(tup)\n\u001b[1;32m    943\u001b[0m \u001b[39m# we maybe be using a tuple to represent multiple dimensions here\u001b[39;00m\n\u001b[1;32m    944\u001b[0m ax0 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/gptchem/lib/python3.9/site-packages/pandas/core/indexing.py:1047\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_nested_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1044\u001b[0m     axis \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1045\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m-> 1047\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(obj, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\u001b[39m.\u001b[39;49m_getitem_axis(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   1048\u001b[0m axis \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1050\u001b[0m \u001b[39m# if we have a scalar, we are done\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gptchem/lib/python3.9/site-packages/pandas/core/indexing.py:1312\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1310\u001b[0m \u001b[39m# fall thru to straight lookup\u001b[39;00m\n\u001b[1;32m   1311\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m-> 1312\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_label(key, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/miniconda3/envs/gptchem/lib/python3.9/site-packages/pandas/core/indexing.py:1260\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_label\u001b[39m(\u001b[39mself\u001b[39m, label, axis: \u001b[39mint\u001b[39m):\n\u001b[1;32m   1259\u001b[0m     \u001b[39m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[0;32m-> 1260\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49mxs(label, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/miniconda3/envs/gptchem/lib/python3.9/site-packages/pandas/core/generic.py:4056\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   4054\u001b[0m             new_index \u001b[39m=\u001b[39m index[loc]\n\u001b[1;32m   4055\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4056\u001b[0m     loc \u001b[39m=\u001b[39m index\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   4058\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(loc, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m   4059\u001b[0m         \u001b[39mif\u001b[39;00m loc\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mbool_:\n",
      "File \u001b[0;32m~/miniconda3/envs/gptchem/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "find_learning_curve_intersection(\n",
    "    grouped_res.loc[2, :][\"f1_macro\"][\"mean\"].values[0],\n",
    "    fit_learning_curve(\n",
    "        grouped_tabpfn_res.loc[2, :].index,\n",
    "        grouped_tabpfn_res.loc[2, :][\"f1_macro\"][\"mean\"],\n",
    "    )[0],\n",
    ") / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gptchem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f3b9074e5baa1438c27e2ea813f7f53b7516c83bd70840b6d64eae6820ee5df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
