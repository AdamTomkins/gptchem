nohup: ignoring input
2023-01-31 08:59:21.429570: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-01-31 08:59:22.169924: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-01-31 08:59:22.170010: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-01-31 08:59:22.170021: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-01-31 09:01:12.245862: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2023-01-31 09:01:12.263225: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)
2023-01-31 09:01:12.263253: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (kevin-OptiPlex-9020): /proc/driver/nvidia/version does not exist
2023-01-31 09:01:12.263489: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING:tensorflow:From /home/kevin/anaconda3/envs/gptchem/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ -5e-05   │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │  0       │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  1.00002 │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛
Loading model that can be used for inference only
Using a Transformer with 25.82 M parameters
Upload progress:   0%|          | 0.00/4.34k [00:00<?, ?it/s]Upload progress: 100%|██████████| 4.34k/4.34k [00:00<00:00, 4.71Mit/s]
Uploaded file from /home/kevin/Documents/gptchem/experiments/03_classification/bandgap/out/20230131_090123/train.jsonl: file-M5nWJ9gX3ZgIgPTAwA2G8pHN
Ran train size 10 and got accuracy 0.0, XGB baseline 0.5, and TabPFN baseline 0.544
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ -5e-05   │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │  0       │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  1.00002 │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛
Loading model that can be used for inference only
Using a Transformer with 25.82 M parameters
Upload progress:   0%|          | 0.00/12.6k [00:00<?, ?it/s]Upload progress: 100%|██████████| 12.6k/12.6k [00:00<00:00, 13.8Mit/s]
Uploaded file from /home/kevin/Documents/gptchem/experiments/03_classification/bandgap/out/20230131_103828/train.jsonl: file-tZjPQvsyoI9B3Ofg7gKY3kRe
Ran train size 10 and got accuracy 0.0, XGB baseline 0.5, and TabPFN baseline 0.544
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ -5e-05   │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │  0       │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  1.00002 │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛
Loading model that can be used for inference only
Using a Transformer with 25.82 M parameters
Upload progress:   0%|          | 0.00/4.33k [00:00<?, ?it/s]Upload progress: 100%|██████████| 4.33k/4.33k [00:00<00:00, 7.88Mit/s]
Uploaded file from /home/kevin/Documents/gptchem/experiments/03_classification/bandgap/out/20230131_120122/train.jsonl: file-Xh85sDkiSrfaMdYM4MicsMCK
Ran train size 10 and got accuracy 0.0, XGB baseline 0.5, and TabPFN baseline 0.544
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤═════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │   value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪═════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ 0.67507 │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 2.03519 │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │ 0.6714  │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧═════════╛
Loading model that can be used for inference only
Using a Transformer with 25.82 M parameters
Upload progress:   0%|          | 0.00/22.1k [00:00<?, ?it/s]Upload progress: 100%|██████████| 22.1k/22.1k [00:00<00:00, 39.2Mit/s]
Uploaded file from /home/kevin/Documents/gptchem/experiments/03_classification/bandgap/out/20230131_150043/train.jsonl: file-Vv20ZyzJollxfK6tgKkdZVJL
Ran train size 50 and got accuracy 0.0, XGB baseline 0.516, and TabPFN baseline 0.564
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤═════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │   value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪═════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ 0.67507 │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 2.03519 │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │ 0.6714  │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧═════════╛
Loading model that can be used for inference only
Using a Transformer with 25.82 M parameters
Upload progress:   0%|          | 0.00/64.8k [00:00<?, ?it/s]Upload progress: 100%|██████████| 64.8k/64.8k [00:00<00:00, 107Mit/s]
Uploaded file from /home/kevin/Documents/gptchem/experiments/03_classification/bandgap/out/20230131_160534/train.jsonl: file-WiPw80UxAhTexA8pngFHHEDX
Ran train size 50 and got accuracy 0.0, XGB baseline 0.516, and TabPFN baseline 0.564
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤═════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │   value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪═════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ 0.67507 │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 2.03519 │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │ 0.6714  │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧═════════╛
Loading model that can be used for inference only
Using a Transformer with 25.82 M parameters
Upload progress:   0%|          | 0.00/21.5k [00:00<?, ?it/s]Upload progress: 100%|██████████| 21.5k/21.5k [00:00<00:00, 18.6Mit/s]
Uploaded file from /home/kevin/Documents/gptchem/experiments/03_classification/bandgap/out/20230131_172303/train.jsonl: file-gdyUQJEuhSIsw1DTvoOtrBAq
Ran train size 50 and got accuracy 0.0, XGB baseline 0.516, and TabPFN baseline 0.564
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │  2.08353 │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 27.6908  │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.30509 │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛
Loading model that can be used for inference only
Using a Transformer with 25.82 M parameters
Upload progress:   0%|          | 0.00/44.5k [00:00<?, ?it/s]Upload progress: 100%|██████████| 44.5k/44.5k [00:00<00:00, 85.7Mit/s]
Uploaded file from /home/kevin/Documents/gptchem/experiments/03_classification/bandgap/out/20230131_173544/train.jsonl: file-XYaoMcN6J4Krslzuuk9gn8h6
Ran train size 100 and got accuracy 0.0, XGB baseline 0.692, and TabPFN baseline 0.608
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │  2.08353 │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 27.6908  │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.30509 │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛
Loading model that can be used for inference only
Using a Transformer with 25.82 M parameters
Upload progress:   0%|          | 0.00/129k [00:00<?, ?it/s]Upload progress: 100%|██████████| 129k/129k [00:00<00:00, 284Mit/s]
Uploaded file from /home/kevin/Documents/gptchem/experiments/03_classification/bandgap/out/20230131_211925/train.jsonl: file-X1t0jQ6hcFCzR5kQKZ1VTefF
Ran train size 100 and got accuracy 0.0, XGB baseline 0.692, and TabPFN baseline 0.608
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │  2.08353 │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 27.6908  │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.30509 │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛
Loading model that can be used for inference only
Using a Transformer with 25.82 M parameters
Upload progress:   0%|          | 0.00/43.8k [00:00<?, ?it/s]Upload progress: 100%|██████████| 43.8k/43.8k [00:00<00:00, 82.1Mit/s]
Uploaded file from /home/kevin/Documents/gptchem/experiments/03_classification/bandgap/out/20230131_224658/train.jsonl: file-QM2Wo6MZVyXnLzOlSu2BJcMZ
Ran train size 100 and got accuracy 0.0, XGB baseline 0.692, and TabPFN baseline 0.608
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │  2.94087 │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 36.8702  │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.14631 │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛
Loading model that can be used for inference only
Using a Transformer with 25.82 M parameters
Upload progress:   0%|          | 0.00/86.6k [00:00<?, ?it/s]Upload progress: 100%|██████████| 86.6k/86.6k [00:00<00:00, 198Mit/s]
Uploaded file from /home/kevin/Documents/gptchem/experiments/03_classification/bandgap/out/20230201_012414/train.jsonl: file-12eg32tldXlAo2JeUAcTSKsi
Ran train size 200 and got accuracy 0.0, XGB baseline 0.716, and TabPFN baseline 0.58
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │  2.94087 │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 36.8702  │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.14631 │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛
Loading model that can be used for inference only
Using a Transformer with 25.82 M parameters
Upload progress:   0%|          | 0.00/251k [00:00<?, ?it/s]Upload progress: 100%|██████████| 251k/251k [00:00<00:00, 486Mit/s]
Uploaded file from /home/kevin/Documents/gptchem/experiments/03_classification/bandgap/out/20230201_042539/train.jsonl: file-tPS7sB4kG4Zw86TAwr9OuGq3
Ran train size 200 and got accuracy 0.0, XGB baseline 0.716, and TabPFN baseline 0.58
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │  2.94087 │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 36.8702  │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.14631 │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛
Loading model that can be used for inference only
Using a Transformer with 25.82 M parameters
Upload progress:   0%|          | 0.00/85.0k [00:00<?, ?it/s]Upload progress: 100%|██████████| 85.0k/85.0k [00:00<00:00, 175Mit/s]
Uploaded file from /home/kevin/Documents/gptchem/experiments/03_classification/bandgap/out/20230201_063048/train.jsonl: file-nOmBZskpQoCDinfADqryjIVq
Ran train size 200 and got accuracy 0.0, XGB baseline 0.716, and TabPFN baseline 0.58
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │  3.1827  │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 43.8202  │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.15404 │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛
Loading model that can be used for inference only
Using a Transformer with 25.82 M parameters
Upload progress:   0%|          | 0.00/218k [00:00<?, ?it/s]Upload progress: 100%|██████████| 218k/218k [00:00<00:00, 540Mit/s]
Uploaded file from /home/kevin/Documents/gptchem/experiments/03_classification/bandgap/out/20230201_083018/train.jsonl: file-uGWQzHBfGIl2xS9VgIQQLy22
Ran train size 500 and got accuracy 0.0, XGB baseline 0.776, and TabPFN baseline 0.676
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │  3.1827  │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 43.8202  │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.15404 │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛
Loading model that can be used for inference only
Using a Transformer with 25.82 M parameters
Upload progress:   0%|          | 0.00/632k [00:00<?, ?it/s]Upload progress: 100%|██████████| 632k/632k [00:00<00:00, 972Mit/s]
Uploaded file from /home/kevin/Documents/gptchem/experiments/03_classification/bandgap/out/20230201_134430/train.jsonl: file-f9qESrPaUne40jeOsrwmufMY
Ran train size 500 and got accuracy 0.0, XGB baseline 0.776, and TabPFN baseline 0.676
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │  3.1827  │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 43.8202  │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.15404 │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛
Loading model that can be used for inference only
Using a Transformer with 25.82 M parameters
Upload progress:   0%|          | 0.00/214k [00:00<?, ?it/s]Upload progress: 100%|██████████| 214k/214k [00:00<00:00, 404Mit/s]
