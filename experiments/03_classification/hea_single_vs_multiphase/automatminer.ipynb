{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gptchem.data import get_hea_phase_data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_hea_phase_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['composition'] = data['Alloy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['composition', 'phase_binary_encoded']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/utils/data.py:506: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  self.params = pd.read_csv(\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/utils/data.py:555: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_params = self.params.append(new_data, sort=True, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "from automatminer import MatPipe\n",
    "\n",
    "pipe = MatPipe.from_preset(\"express\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, train_size=10, random_state=42, stratify=data['phase_binary_encoded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-18 08:44:04 INFO     Problem type is: classification\n",
      "2023-01-18 08:44:04 INFO     Fitting MatPipe pipeline to data.\n",
      "2023-01-18 08:44:04 INFO     AutoFeaturizer: Starting fitting.\n",
      "2023-01-18 08:44:04 INFO     AutoFeaturizer: Compositions detected as strings. Attempting conversion to Composition objects...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e2b2c555094767bf9f6a8fa3aedc0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "StrToComposition:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-18 08:44:05 INFO     AutoFeaturizer: Guessing oxidation states of compositions, as they were not present in input.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d9f2259f19481e90f0421881921f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CompositionToOxidComposition:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-18 08:44:06 INFO     AutoFeaturizer: Featurizer type structure not in the dataframe to be fitted. Skipping...\n",
      "2023-01-18 08:44:06 INFO     AutoFeaturizer: Featurizer type bandstructure not in the dataframe to be fitted. Skipping...\n",
      "2023-01-18 08:44:06 INFO     AutoFeaturizer: Featurizer type dos not in the dataframe to be fitted. Skipping...\n",
      "2023-01-18 08:44:06 INFO     AutoFeaturizer: Finished fitting.\n",
      "2023-01-18 08:44:06 INFO     AutoFeaturizer: Starting transforming.\n",
      "2023-01-18 08:44:06 INFO     AutoFeaturizer: Featurizing with ElementProperty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82f7d08dd1184e13887be3a3c25fc706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ElementProperty:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-18 08:44:07 INFO     AutoFeaturizer: Featurizing with OxidationStates.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a8122393c354150af756565fc7feb4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "OxidationStates:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-18 08:44:08 INFO     AutoFeaturizer: Featurizing with ElectronAffinity.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bbbc3283f61482488d6a6174fe9449c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ElectronAffinity:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-18 08:44:09 INFO     AutoFeaturizer: Featurizing with IonProperty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1f75996df74a91893b630fbc17c8ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IonProperty:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-18 08:44:10 INFO     AutoFeaturizer: Featurizing with YangSolidSolution.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2996c392fc214076ae823341616c819a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "YangSolidSolution:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-18 08:44:11 INFO     AutoFeaturizer: Featurizing with Miedema.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4776198268484aaf947b72e0593b05b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Miedema:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-18 08:44:15 INFO     AutoFeaturizer: Featurizer type structure not in the dataframe. Skipping...\n",
      "2023-01-18 08:44:15 INFO     AutoFeaturizer: Featurizer type bandstructure not in the dataframe. Skipping...\n",
      "2023-01-18 08:44:15 INFO     AutoFeaturizer: Featurizer type dos not in the dataframe. Skipping...\n",
      "2023-01-18 08:44:15 INFO     AutoFeaturizer: Finished transforming.\n",
      "2023-01-18 08:44:15 INFO     DataCleaner: Starting fitting.\n",
      "2023-01-18 08:44:15 INFO     DataCleaner: Cleaning with respect to samples with sample na_method 'drop'\n",
      "2023-01-18 08:44:15 INFO     DataCleaner: Replacing infinite values with nan for easier screening.\n",
      "2023-01-18 08:44:15 INFO     DataCleaner: Before handling na: 10 samples, 146 features\n",
      "2023-01-18 08:44:15 INFO     DataCleaner: 0 samples did not have target values. They were dropped.\n",
      "2023-01-18 08:44:15 INFO     DataCleaner: Handling feature na by max na threshold of 0.01 with method 'drop'.\n",
      "2023-01-18 08:44:15 INFO     DataCleaner: These 8 features were removed as they had more than 1.0% missing values: {'minimum oxidation state', 'std_dev oxidation state', 'avg anion electron affinity', 'max ionic char', 'avg ionic char', 'compound possible', 'range oxidation state', 'maximum oxidation state'}\n",
      "2023-01-18 08:44:15 INFO     DataCleaner: After handling na: 10 samples, 138 features\n",
      "2023-01-18 08:44:15 INFO     DataCleaner: Finished fitting.\n",
      "2023-01-18 08:44:15 INFO     FeatureReducer: Starting fitting.\n",
      "2023-01-18 08:44:15 INFO     FeatureReducer: 66 features removed due to cross correlation more than 0.95\n",
      "2023-01-18 08:44:17 INFO     TreeFeatureReducer: Finished tree-based feature reduction of 71 initial features to 34\n",
      "2023-01-18 08:44:17 INFO     FeatureReducer: Finished fitting.\n",
      "2023-01-18 08:44:17 INFO     FeatureReducer: Starting transforming.\n",
      "2023-01-18 08:44:17 INFO     FeatureReducer: Finished transforming.\n",
      "2023-01-18 08:44:17 INFO     TPOTAdaptor: Starting fitting.\n",
      "29 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a55dca7ad594e718bc541e1d9235b31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/20 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by Binarizer..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by MinMaxScaler..\n",
      "\n",
      "Generation 1 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by Nystroem..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Solver lbfgs supports only dual=False, got dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by Nystroem..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "\n",
      "Generation 2 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 3 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PolynomialFeatures..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 4 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Negative values in data passed to MultinomialNB (input X).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(9, 1)) while a minimum of 2 is required by FeatureAgglomeration..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "\n",
      "Generation 5 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PolynomialFeatures..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Negative values in data passed to MultinomialNB (input X).\n",
      "\n",
      "Generation 6 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 7 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True.\n",
      "\n",
      "Generation 8 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "\n",
      "Generation 9 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(9, 1)) while a minimum of 2 is required by FeatureAgglomeration..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PCA..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "\n",
      "Generation 10 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only dual=False, got dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(9, 1)) while a minimum of 2 is required by FeatureAgglomeration..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 11 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PolynomialFeatures..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by RobustScaler..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 12 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PolynomialFeatures..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 13 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 14 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 15 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True.\n",
      "\n",
      "Generation 16 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only dual=False, got dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PolynomialFeatures..\n",
      "\n",
      "Generation 17 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Negative values in data passed to MultinomialNB (input X).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(9, 1)) while a minimum of 2 is required by FeatureAgglomeration..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by StandardScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 The 'step' parameter of RFE must be an int in the range (0, inf) or a float in the range (0, 1). Got 1.0 instead..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=2 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 18 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PCA..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(9, 1)) while a minimum of 2 is required by FeatureAgglomeration..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 19 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PolynomialFeatures..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 20 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PCA..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by RBFSampler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(9, 1)) while a minimum of 2 is required by FeatureAgglomeration..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PolynomialFeatures..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 21 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PolynomialFeatures..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PolynomialFeatures..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=3 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "\n",
      "Generation 22 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 23 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "\n",
      "Generation 24 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=2 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PCA..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=2 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 25 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PolynomialFeatures..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(9, 1)) while a minimum of 2 is required by FeatureAgglomeration..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 26 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PCA..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 27 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(9, 1)) while a minimum of 2 is required by FeatureAgglomeration..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "\n",
      "Generation 28 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only dual=False, got dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "\n",
      "Generation 29 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PolynomialFeatures..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "\n",
      "Generation 30 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 The 'step' parameter of RFE must be an int in the range (0, inf) or a float in the range (0, 1). Got 1.0 instead..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "\n",
      "Generation 31 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 32 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PCA..\n",
      "\n",
      "Generation 33 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PolynomialFeatures..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 34 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(9, 1)) while a minimum of 2 is required by FeatureAgglomeration..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(9, 1)) while a minimum of 2 is required by FeatureAgglomeration..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PolynomialFeatures..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PolynomialFeatures..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 35 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by StandardScaler..\n",
      "\n",
      "Generation 36 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by RobustScaler..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 37 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "\n",
      "Generation 38 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by RobustScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=2 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 39 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by RobustScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 40 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _mate_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 41 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PolynomialFeatures..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 42 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 43 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _mate_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _mate_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _mate_operator: num_test=2 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _mate_operator: num_test=3 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _mate_operator: num_test=4 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _mate_operator: num_test=5 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _mate_operator: num_test=6 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _mate_operator: num_test=7 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _mate_operator: num_test=8 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _mate_operator: num_test=9 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by RobustScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 44 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "_pre_test decorator: _mate_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 45 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PolynomialFeatures..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 46 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by StandardScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by RBFSampler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Negative values in data passed to MultinomialNB (input X).\n",
      "\n",
      "Generation 47 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 48 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by RobustScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 49 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 50 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(9, 1)) while a minimum of 2 is required by FeatureAgglomeration..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PolynomialFeatures..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 51 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(9, 1)) while a minimum of 2 is required by FeatureAgglomeration..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PolynomialFeatures..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 52 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PolynomialFeatures..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 53 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PolynomialFeatures..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PolynomialFeatures..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 54 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "\n",
      "Generation 55 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by Nystroem..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by RBFSampler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by RBFSampler..\n",
      "\n",
      "Generation 56 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 The 'step' parameter of RFE must be an int in the range (0, inf) or a float in the range (0, 1). Got 1.0 instead..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "\n",
      "Generation 57 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PolynomialFeatures..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PolynomialFeatures..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by Nystroem..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 58 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 59 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PolynomialFeatures..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by Nystroem..\n",
      "\n",
      "Generation 60 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by RBFSampler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PolynomialFeatures..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Solver lbfgs supports only dual=False, got dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "\n",
      "Generation 61 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by RBFSampler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 62 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 63 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "\n",
      "Generation 64 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PolynomialFeatures..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 65 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only dual=False, got dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by Nystroem..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PolynomialFeatures..\n",
      "\n",
      "Generation 66 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PCA..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only dual=False, got dual=True.\n",
      "\n",
      "Generation 67 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PolynomialFeatures..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 68 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "\n",
      "Generation 69 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by Nystroem..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by Nystroem..\n",
      "\n",
      "Generation 70 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "\n",
      "Generation 71 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by PolynomialFeatures..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=2 X contains negative values..\n",
      "\n",
      "Generation 72 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "\n",
      "Generation 73 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 74 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by Nystroem..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=2 X contains negative values..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(9, 1)) while a minimum of 2 is required by FeatureAgglomeration..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by Nystroem..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "\n",
      "Generation 75 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(9, 0)) while a minimum of 1 is required by RBFSampler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 76 - Current Pareto front scores:\n",
      "\n",
      "-3\t1.0\tLinearSVC(PolynomialFeatures(SelectPercentile(input_matrix, SelectPercentile__percentile=2), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVC__C=15.0, LinearSVC__dual=True, LinearSVC__loss=squared_hinge, LinearSVC__penalty=l2, LinearSVC__tol=0.001)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n"
     ]
    }
   ],
   "source": [
    "pipe.fit(train, 'phase_binary_encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-18 06:37:21 INFO     Beginning MatPipe prediction using fitted pipeline.\n",
      "2023-01-18 06:37:21 INFO     AutoFeaturizer: Starting transforming.\n",
      "2023-01-18 06:37:21 INFO     AutoFeaturizer: Compositions detected as strings. Attempting conversion to Composition objects...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b362c6969434b8db107818fa63cf4e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "StrToComposition:   0%|          | 0/1242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-18 06:37:34 INFO     AutoFeaturizer: Guessing oxidation states of compositions, as they were not present in input.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77288bfb76647faaaa08e62a43aecb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CompositionToOxidComposition:   0%|          | 0/1242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-18 06:38:16 WARNING  AutoFeaturizer: Could not decorate oxidation states due to 'float' object has no attribute 'elements'\n",
      "TO SKIP THESE ERRORS when featurizing specific compounds, set 'ignore_errors=True' when running the batch featurize() operation (e.g., featurize_many(), featurize_dataframe(), etc.).. Some featurizers based on composition oxidstatesmay not work\n",
      "2023-01-18 06:38:16 INFO     AutoFeaturizer: Featurizing with ElementProperty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f748ea511c914570ae310bb072eaa715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ElementProperty:   0%|          | 0/1242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-18 06:38:56 INFO     AutoFeaturizer: Featurizing with OxidationStates.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c12b6c65e92c4d9f90378e72bd2533f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "OxidationStates:   0%|          | 0/1242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-18 06:39:35 INFO     AutoFeaturizer: Featurizing with ElectronAffinity.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd32aea449a64a90bac9211149ff7a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ElectronAffinity:   0%|          | 0/1242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-18 06:40:16 INFO     AutoFeaturizer: Featurizing with IonProperty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0ea32386e2418783a5609658942e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IonProperty:   0%|          | 0/1242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-18 06:41:00 INFO     AutoFeaturizer: Featurizing with YangSolidSolution.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c40cfccfa70402599b0497f6b1981d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "YangSolidSolution:   0%|          | 0/1242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-18 06:41:40 INFO     AutoFeaturizer: Featurizing with Miedema.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83463328b9ab468e94779b237dcbef1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Miedema:   0%|          | 0/1242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/featurizers/composition/alloy.py:198: RuntimeWarning: invalid value encountered in power\n",
      "  alp_a = np.multiply(1.5, np.power(v_a, 2 / 3)) / reduce(lambda x, y: 1 / x + 1 / y, np.power(n_ws, 1 / 3))\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/featurizers/composition/alloy.py:198: RuntimeWarning: invalid value encountered in power\n",
      "  alp_a = np.multiply(1.5, np.power(v_a, 2 / 3)) / reduce(lambda x, y: 1 / x + 1 / y, np.power(n_ws, 1 / 3))\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/featurizers/composition/alloy.py:198: RuntimeWarning: invalid value encountered in power\n",
      "  alp_a = np.multiply(1.5, np.power(v_a, 2 / 3)) / reduce(lambda x, y: 1 / x + 1 / y, np.power(n_ws, 1 / 3))\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/featurizers/composition/alloy.py:198: RuntimeWarning: invalid value encountered in power\n",
      "  alp_a = np.multiply(1.5, np.power(v_a, 2 / 3)) / reduce(lambda x, y: 1 / x + 1 / y, np.power(n_ws, 1 / 3))\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/featurizers/composition/alloy.py:198: RuntimeWarning: invalid value encountered in power\n",
      "  alp_a = np.multiply(1.5, np.power(v_a, 2 / 3)) / reduce(lambda x, y: 1 / x + 1 / y, np.power(n_ws, 1 / 3))\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/featurizers/composition/alloy.py:198: RuntimeWarning: invalid value encountered in power\n",
      "  alp_a = np.multiply(1.5, np.power(v_a, 2 / 3)) / reduce(lambda x, y: 1 / x + 1 / y, np.power(n_ws, 1 / 3))\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/featurizers/composition/alloy.py:198: RuntimeWarning: invalid value encountered in power\n",
      "  alp_a = np.multiply(1.5, np.power(v_a, 2 / 3)) / reduce(lambda x, y: 1 / x + 1 / y, np.power(n_ws, 1 / 3))\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/featurizers/composition/alloy.py:198: RuntimeWarning: invalid value encountered in power\n",
      "  alp_a = np.multiply(1.5, np.power(v_a, 2 / 3)) / reduce(lambda x, y: 1 / x + 1 / y, np.power(n_ws, 1 / 3))\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/featurizers/composition/alloy.py:198: RuntimeWarning: invalid value encountered in power\n",
      "  alp_a = np.multiply(1.5, np.power(v_a, 2 / 3)) / reduce(lambda x, y: 1 / x + 1 / y, np.power(n_ws, 1 / 3))\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/featurizers/composition/alloy.py:198: RuntimeWarning: invalid value encountered in power\n",
      "  alp_a = np.multiply(1.5, np.power(v_a, 2 / 3)) / reduce(lambda x, y: 1 / x + 1 / y, np.power(n_ws, 1 / 3))\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/featurizers/composition/alloy.py:198: RuntimeWarning: invalid value encountered in power\n",
      "  alp_a = np.multiply(1.5, np.power(v_a, 2 / 3)) / reduce(lambda x, y: 1 / x + 1 / y, np.power(n_ws, 1 / 3))\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/featurizers/composition/alloy.py:198: RuntimeWarning: invalid value encountered in power\n",
      "  alp_a = np.multiply(1.5, np.power(v_a, 2 / 3)) / reduce(lambda x, y: 1 / x + 1 / y, np.power(n_ws, 1 / 3))\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/featurizers/composition/alloy.py:198: RuntimeWarning: invalid value encountered in power\n",
      "  alp_a = np.multiply(1.5, np.power(v_a, 2 / 3)) / reduce(lambda x, y: 1 / x + 1 / y, np.power(n_ws, 1 / 3))\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/featurizers/composition/alloy.py:198: RuntimeWarning: invalid value encountered in power\n",
      "  alp_a = np.multiply(1.5, np.power(v_a, 2 / 3)) / reduce(lambda x, y: 1 / x + 1 / y, np.power(n_ws, 1 / 3))\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/featurizers/composition/alloy.py:198: RuntimeWarning: invalid value encountered in power\n",
      "  alp_a = np.multiply(1.5, np.power(v_a, 2 / 3)) / reduce(lambda x, y: 1 / x + 1 / y, np.power(n_ws, 1 / 3))\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/featurizers/composition/alloy.py:198: RuntimeWarning: invalid value encountered in power\n",
      "  alp_a = np.multiply(1.5, np.power(v_a, 2 / 3)) / reduce(lambda x, y: 1 / x + 1 / y, np.power(n_ws, 1 / 3))\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/featurizers/composition/alloy.py:198: RuntimeWarning: invalid value encountered in power\n",
      "  alp_a = np.multiply(1.5, np.power(v_a, 2 / 3)) / reduce(lambda x, y: 1 / x + 1 / y, np.power(n_ws, 1 / 3))\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/featurizers/composition/alloy.py:198: RuntimeWarning: invalid value encountered in power\n",
      "  alp_a = np.multiply(1.5, np.power(v_a, 2 / 3)) / reduce(lambda x, y: 1 / x + 1 / y, np.power(n_ws, 1 / 3))\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/featurizers/composition/alloy.py:198: RuntimeWarning: invalid value encountered in power\n",
      "  alp_a = np.multiply(1.5, np.power(v_a, 2 / 3)) / reduce(lambda x, y: 1 / x + 1 / y, np.power(n_ws, 1 / 3))\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/featurizers/composition/alloy.py:198: RuntimeWarning: invalid value encountered in power\n",
      "  alp_a = np.multiply(1.5, np.power(v_a, 2 / 3)) / reduce(lambda x, y: 1 / x + 1 / y, np.power(n_ws, 1 / 3))\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/featurizers/composition/alloy.py:198: RuntimeWarning: invalid value encountered in power\n",
      "  alp_a = np.multiply(1.5, np.power(v_a, 2 / 3)) / reduce(lambda x, y: 1 / x + 1 / y, np.power(n_ws, 1 / 3))\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/featurizers/composition/alloy.py:198: RuntimeWarning: invalid value encountered in power\n",
      "  alp_a = np.multiply(1.5, np.power(v_a, 2 / 3)) / reduce(lambda x, y: 1 / x + 1 / y, np.power(n_ws, 1 / 3))\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/featurizers/composition/alloy.py:198: RuntimeWarning: invalid value encountered in power\n",
      "  alp_a = np.multiply(1.5, np.power(v_a, 2 / 3)) / reduce(lambda x, y: 1 / x + 1 / y, np.power(n_ws, 1 / 3))\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/featurizers/composition/alloy.py:198: RuntimeWarning: invalid value encountered in power\n",
      "  alp_a = np.multiply(1.5, np.power(v_a, 2 / 3)) / reduce(lambda x, y: 1 / x + 1 / y, np.power(n_ws, 1 / 3))\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/featurizers/composition/alloy.py:198: RuntimeWarning: invalid value encountered in power\n",
      "  alp_a = np.multiply(1.5, np.power(v_a, 2 / 3)) / reduce(lambda x, y: 1 / x + 1 / y, np.power(n_ws, 1 / 3))\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/featurizers/composition/alloy.py:198: RuntimeWarning: invalid value encountered in power\n",
      "  alp_a = np.multiply(1.5, np.power(v_a, 2 / 3)) / reduce(lambda x, y: 1 / x + 1 / y, np.power(n_ws, 1 / 3))\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/featurizers/composition/alloy.py:198: RuntimeWarning: invalid value encountered in power\n",
      "  alp_a = np.multiply(1.5, np.power(v_a, 2 / 3)) / reduce(lambda x, y: 1 / x + 1 / y, np.power(n_ws, 1 / 3))\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/featurizers/composition/alloy.py:198: RuntimeWarning: invalid value encountered in power\n",
      "  alp_a = np.multiply(1.5, np.power(v_a, 2 / 3)) / reduce(lambda x, y: 1 / x + 1 / y, np.power(n_ws, 1 / 3))\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/featurizers/composition/alloy.py:198: RuntimeWarning: invalid value encountered in power\n",
      "  alp_a = np.multiply(1.5, np.power(v_a, 2 / 3)) / reduce(lambda x, y: 1 / x + 1 / y, np.power(n_ws, 1 / 3))\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/featurizers/composition/alloy.py:198: RuntimeWarning: invalid value encountered in power\n",
      "  alp_a = np.multiply(1.5, np.power(v_a, 2 / 3)) / reduce(lambda x, y: 1 / x + 1 / y, np.power(n_ws, 1 / 3))\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/featurizers/composition/alloy.py:198: RuntimeWarning: invalid value encountered in power\n",
      "  alp_a = np.multiply(1.5, np.power(v_a, 2 / 3)) / reduce(lambda x, y: 1 / x + 1 / y, np.power(n_ws, 1 / 3))\n",
      "/Users/kevinmaikjablonka/miniconda3/envs/gptchem/lib/python3.9/site-packages/matminer/featurizers/composition/alloy.py:198: RuntimeWarning: invalid value encountered in power\n",
      "  alp_a = np.multiply(1.5, np.power(v_a, 2 / 3)) / reduce(lambda x, y: 1 / x + 1 / y, np.power(n_ws, 1 / 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-18 06:42:23 INFO     AutoFeaturizer: Featurizer type structure not in the dataframe. Skipping...\n",
      "2023-01-18 06:42:23 INFO     AutoFeaturizer: Featurizer type bandstructure not in the dataframe. Skipping...\n",
      "2023-01-18 06:42:23 INFO     AutoFeaturizer: Featurizer type dos not in the dataframe. Skipping...\n",
      "2023-01-18 06:42:23 INFO     AutoFeaturizer: Finished transforming.\n",
      "2023-01-18 06:42:23 INFO     DataCleaner: Starting transforming.\n",
      "2023-01-18 06:42:23 INFO     DataCleaner: Cleaning with respect to samples with sample na_method 'fill'\n",
      "2023-01-18 06:42:23 INFO     DataCleaner: Replacing infinite values with nan for easier screening.\n",
      "2023-01-18 06:42:23 INFO     DataCleaner: One-hot encoding used for columns ['Alloy', 'Phase']\n",
      "2023-01-18 06:42:23 INFO     DataCleaner: Before handling na: 1242 samples, 1351 features\n",
      "2023-01-18 06:42:23 INFO     DataCleaner: 0 samples did not have target values. They were dropped.\n",
      "2023-01-18 06:42:23 WARNING  DataCleaner: Mismatched columns found in dataframe used for fitting and argument dataframe.\n",
      "2023-01-18 06:42:23 WARNING  DataCleaner: Coercing mismatched columns...\n",
      "2023-01-18 06:42:23 WARNING  DataCleaner: Assuming missing columns in argument df are one-hot encoding issues. Setting to zero the following new columns:\n",
      "['Alloy_Al0.2V0.8', 'Alloy_AuSi', 'Alloy_KLi', 'Alloy_Ni0.25Pd0.75', 'Alloy_OsY', 'Alloy_Pb0.5Tl0.5', 'Alloy_PuTi', 'Alloy_ReTb', 'Alloy_Sc0.25Zr0.75']\n",
      "2023-01-18 06:42:23 WARNING  DataCleaner: Following columns are being dropped:\n",
      "['minimum oxidation state', 'maximum oxidation state', 'range oxidation state', 'std_dev oxidation state', 'avg anion electron affinity', 'compound possible', 'max ionic char', 'avg ionic char', 'Alloy_Ag0.05Rh0.95', 'Alloy_Ag0.05Zr0.95', 'Alloy_Ag0.25Au0.75', 'Alloy_Ag0.25Pd0.75', 'Alloy_Ag0.5Au0.5', 'Alloy_Ag0.5Pd0.5', 'Alloy_Ag0.65Cd0.35', 'Alloy_Ag0.6Li0.4', 'Alloy_Ag0.75Au0.25', 'Alloy_Ag0.75Pd0.25', 'Alloy_Ag0.7Zn0.3', 'Alloy_Ag0.85In0.15', 'Alloy_Ag0.85Zn0.15', 'Alloy_Ag0.8Cd0.2', 'Alloy_Ag0.8Li0.2', 'Alloy_Ag0.8Mg0.2', 'Alloy_Ag0.8Mn0.2', 'Alloy_Ag0.8Pt0.2', 'Alloy_Ag0.90Al0.10', 'Alloy_Ag0.9Mg0.1', 'Alloy_Ag0.9Mn0.1', 'Alloy_Ag0.9Pt0.1', 'Alloy_AgAs', 'Alloy_AgBe', 'Alloy_AgCo', 'Alloy_AgCr', 'Alloy_AgCu', 'Alloy_AgFe', 'Alloy_AgGe', 'Alloy_AgMn', 'Alloy_AgMo', 'Alloy_AgNi', 'Alloy_AgOs', 'Alloy_AgPb', 'Alloy_AgPt', 'Alloy_AgRe', 'Alloy_AgRh', 'Alloy_AgSb', 'Alloy_AgSi', 'Alloy_AgSn', 'Alloy_AgW', 'Alloy_Al0.03Mg0.97', 'Alloy_Al0.03Sc0.97', 'Alloy_Al0.05Co0.95', 'Alloy_Al0.08Pt0.92', 'Alloy_Al0.15Cr0.85', 'Alloy_Al0.15Cu0.85', 'Alloy_Al0.1Fe0.9', 'Alloy_Al0.1Hf0.9', 'Alloy_Al0.1Ni0.9', 'Alloy_Al0.1Pd0.9', 'Alloy_Al0.1Ti0.9', 'Alloy_Al0.1W0.9', 'Alloy_Al0.25Co1Cr1Cu0.75Fe1Ni1', 'Alloy_Al0.25Co1Cr1Cu0.75Fe1Ni1Ti0.5', 'Alloy_Al0.25Co1Cr1Fe1Ni1', 'Alloy_Al0.25Cr1Cu1Fe1Ni2', 'Alloy_Al0.2Co1.5Cr1Fe1Ni1.5Ti0.5', 'Alloy_Al0.2Co1.5Cr1Fe1Ni1.5Ti1', 'Alloy_Al0.2Fe0.8', 'Alloy_Al0.2Ti0.8', 'Alloy_Al0.375Co1Cr1Fe1Ni1', 'Alloy_Al0.3Co1Cr1Cu1Fe1Ni1', 'Alloy_Al0.3Co1Cr1Fe1Mo0.1Ni1', 'Alloy_Al0.3Co1Cr1Fe1Ni1', 'Alloy_Al0.3Co1Cr1Fe1Ni1Ti0.1', 'Alloy_Al0.3Co1Cr2Fe1Ni1', 'Alloy_Al0.3Cr0.7', 'Alloy_Al0.3Cr1Fe1.5Mn1Ni0.5', 'Alloy_Al0.3Cr1Fe1Ni1V1', 'Alloy_Al0.3Nb1Ta0.8Ti1.4V0.2Zr1.3', 'Alloy_Al0.4Co1Cr1Fe1Mn1Ni1V1', 'Alloy_Al0.4Hf0.6Nb1Ta1Ti1Zr1', 'Alloy_Al0.4V0.6', 'Alloy_Al0.55V0.45', 'Alloy_Al0.5B0.2Co1Cr1Cu1Fe1Ni1', 'Alloy_Al0.5B0.6Co1Cr1Cu1Fe1Ni1', 'Alloy_Al0.5B1Co1Cr1Cu1Fe1Ni1', 'Alloy_Al0.5Ce1Co1Cu0.5Fe1Ni1Ti0.5', 'Alloy_Al0.5Co1Cr1Cu0.5Fe1Ni1', 'Alloy_Al0.5Co1Cr1Cu1Fe1Ni1', 'Alloy_Al0.5Co1Cr1Cu1Fe1Ni1Ti0.8', 'Alloy_Al0.5Co1Cr1Cu1Fe1Ni1V0.2', 'Alloy_Al0.5Co1Cr1Cu1Fe1Ni1V0.4', 'Alloy_Al0.5Co1Cr1Cu1Fe1Ni1V0.6', 'Alloy_Al0.5Co1Cr1Cu1Fe1Ni1V0.8', 'Alloy_Al0.5Co1Cr1Cu1Fe1Ni1V1', 'Alloy_Al0.5Co1Cr1Cu1Fe1Ni1V1.2', 'Alloy_Al0.5Co1Cr1Cu1Fe1Ni1V1.4', 'Alloy_Al0.5Co1Cr1Cu1Fe1Ni1V1.6', 'Alloy_Al0.5Co1Cr1Cu1Fe1Ni1V1.8', 'Alloy_Al0.5Co1Cr1Cu1Fe1Ni1V2', 'Alloy_Al0.5Co1Cr1Fe1Ni1', 'Alloy_Al0.5Co1Cr1Fe1Ni1Ti1', 'Alloy_Al0.5Cr1Cu1Fe1Ni2', 'Alloy_Al0.5Cr1Fe1.5Mn1Ni0.5', 'Alloy_Al0.5Cr1Fe1Ni1Ti1V1', 'Alloy_Al0.5Cr1Fe1Ni1V1', 'Alloy_Al0.5Nb1Ta0.8Ti1.5V0.2Zr1', 'Alloy_Al0.5Nb1Ti1V1Zr1', 'Alloy_Al0.75Co1Cr1Cu0.25Fe1Ni1', 'Alloy_Al0.75Co1Cr1Cu0.25Fe1Ni1Ti0.5', 'Alloy_Al0.75Co1Cr1Fe1Ni1', 'Alloy_Al0.75Hf1Nb1Ta1Ti1Zr1', 'Alloy_Al0.875Co1Cr1Fe1Ni1', 'Alloy_Al0.8Co1Cr1Cu1Fe1Ni1', 'Alloy_Al0.8Cr1Cu1Fe1Ni2', 'Alloy_Al0.8Cr1Fe1.5Mn1Ni0.5', 'Alloy_Al0.8Zn0.2', 'Alloy_Al0.95Li0.05', 'Alloy_Al0.95Mg0.05', 'Alloy_Al0.9Zn0.1', 'Alloy_Al1.17Co1Cr1Fe1Ni1', 'Alloy_Al1.25Co1Cr1Fe1Ni1', 'Alloy_Al1.3Co1Cr1Cu1Fe1Ni1', 'Alloy_Al1.3Cr1Cu1Fe1Ni2', 'Alloy_Al1.5Co1Cr1Cu1Fe1Ni1', 'Alloy_Al1.5Co1Cr1Fe1Ni1', 'Alloy_Al1.5Co1Cr1Fe1Ni1Ti1', 'Alloy_Al1.5Cr1Cu1Fe1Ni2', 'Alloy_Al1.5Cr1Fe1.5Mn1Ni0.5', 'Alloy_Al1.5Cr1Fe1Mn1Ti1', 'Alloy_Al1.5Nb1Ti1V1Zr1', 'Alloy_Al1.8Co1Cr1Cu1Fe1Ni1', 'Alloy_Al1Au1Co1Cr1Cu1Ni1', 'Alloy_Al1Co0.5Cr0.5Fe0.5Mn1Ni1V0.5', 'Alloy_Al1Co0.5Cr0.5Fe0.5Mn1Ni1V1', 'Alloy_Al1Co0.5Cr1Cu1Fe1Ni1', 'Alloy_Al1Co0.5Cr1Fe1Mo0.5Ni1', 'Alloy_Al1Co1.5Cr1Fe1Mo0.5Ni1', 'Alloy_Al1Co1.5Cr1Fe1Ni1Ti0.5', 'Alloy_Al1Co1.5Cr2Fe1.5Mn2Ni1V1', 'Alloy_Al1Co1Cr0.5Cu1Fe1Ni1', 'Alloy_Al1Co1Cr0.5Fe1Mo0.5Ni1', 'Alloy_Al1Co1Cr1.5Fe1Mo0.5Ni1', 'Alloy_Al1Co1Cr1Cu0.25Fe1Ni1', 'Alloy_Al1Co1Cr1Cu0.25Fe1Ni1Ti0.5', 'Alloy_Al1Co1Cr1Cu0.5Fe1Ni1', 'Alloy_Al1Co1Cr1Cu0.5Fe1Ni1Ti0.5', 'Alloy_Al1Co1Cr1Cu0.5Ni1', 'Alloy_Al1Co1Cr1Cu1Fe0.5Ni1', 'Alloy_Al1Co1Cr1Cu1Fe1Mn1Ni1', 'Alloy_Al1Co1Cr1Cu1Fe1Mn1Ni1Ti1V1', 'Alloy_Al1Co1Cr1Cu1Fe1Mo0.2Ni1', 'Alloy_Al1Co1Cr1Cu1Fe1Mo0.4Ni1', 'Alloy_Al1Co1Cr1Cu1Fe1Mo0.6Ni1', 'Alloy_Al1Co1Cr1Cu1Fe1Mo0.8Ni1', 'Alloy_Al1Co1Cr1Cu1Fe1Mo1Ni1', 'Alloy_Al1Co1Cr1Cu1Fe1Ni0.5', 'Alloy_Al1Co1Cr1Cu1Fe1Ni1', 'Alloy_Al1Co1Cr1Cu1Fe1Ni1Si1', 'Alloy_Al1Co1Cr1Cu1Fe1Ni1Ti1', 'Alloy_Al1Co1Cr1Cu1Fe1Ni1Ti1V1', 'Alloy_Al1Co1Cr1Cu1Fe1Ni1V1', 'Alloy_Al1Co1Cr1Cu1Ni1', 'Alloy_Al1Co1Cr1Cu1Ni1Ti1Y0.5', 'Alloy_Al1Co1Cr1Cu1Ni1Ti1Y0.8', 'Alloy_Al1Co1Cr1Cu1Ni1Ti1Y1', 'Alloy_Al1Co1Cr1Fe0.6Mo0.5Ni1', 'Alloy_Al1Co1Cr1Fe1.5Mo0.5Ni1', 'Alloy_Al1Co1Cr1Fe1Mo0.1Ni1', 'Alloy_Al1Co1Cr1Fe1Mo0.2Ni1', 'Alloy_Al1Co1Cr1Fe1Mo0.3Ni1', 'Alloy_Al1Co1Cr1Fe1Mo0.4Ni1', 'Alloy_Al1Co1Cr1Fe1Mo0.5Ni1', 'Alloy_Al1Co1Cr1Fe1Nb0.1Ni1', 'Alloy_Al1Co1Cr1Fe1Nb0.25Ni1', 'Alloy_Al1Co1Cr1Fe1Nb0.5Ni1', 'Alloy_Al1Co1Cr1Fe1Nb0.75Ni1', 'Alloy_Al1Co1Cr1Fe1Ni1', 'Alloy_Al1Co1Cr1Fe1Ni1Si0.2', 'Alloy_Al1Co1Cr1Fe1Ni1Si0.4', 'Alloy_Al1Co1Cr1Fe1Ni1Si0.6', 'Alloy_Al1Co1Cr1Fe1Ni1Si0.8', 'Alloy_Al1Co1Cr1Fe1Ni1Si1', 'Alloy_Al1Co1Cr1Fe1Ni1Ti0.5', 'Alloy_Al1Co1Cr1Fe1Ni1Ti1', 'Alloy_Al1Co1Cr1Fe1Ni1Ti1.5', 'Alloy_Al1Co1Cr1Fe2Mo0.5Ni1', 'Alloy_Al1Co1Cr2Fe1Mo0.5Ni1', 'Alloy_Al1Co1Cu1Fe1Ni1', 'Alloy_Al1Co1Cu1Fe1Ni1Ti1', 'Alloy_Al1Co1Cu1Ni1', 'Alloy_Al1Co1Cu1Ni1Ti1Zn1', 'Alloy_Al1Co1Fe1Mn1Ni1', 'Alloy_Al1Co1Fe1Mo0.5Ni1', 'Alloy_Al1Co2Cr1Fe1Mo0.5Ni1', 'Alloy_Al1Co2Cr1Fe1Ni1Ti0.5', 'Alloy_Al1Co3Cr1Fe1Ni1Ti0.5', 'Alloy_Al1Cr0.5Cu1Fe1Ni1Ti1', 'Alloy_Al1Cr0.5Nb1Ti1V1', 'Alloy_Al1Cr1.5Cu1Fe1Ni1Ti1', 'Alloy_Al1Cr1.5Nb1Ti1V1', 'Alloy_Al1Cr1Cu1Fe1Mn1Ni1', 'Alloy_Al1Cr1Cu1Fe1Ni1Ti1', 'Alloy_Al1Cr1Cu1Fe1Ni2', 'Alloy_Al1Cr1Fe1Mn1Ti0.25', 'Alloy_Al1Cr1Mo1Nb1Ti1', 'Alloy_Al1Cr1Mo1Si1Ti1', 'Alloy_Al1Cr1Mo1Ti1W1', 'Alloy_Al1Cr1Nb1Ti1V1', 'Alloy_Al1Cr2Cu1Fe1Ni1Ti1', 'Alloy_Al1Cr3Cu1Fe1Ni1Ti1', 'Alloy_Al1Cu0.2Li0.5Mg1Zn0.5', 'Alloy_Al1Cu0.5Li0.5Mg1Sn0.2', 'Alloy_Al1Cu1Ni1', 'Alloy_Al1Fe1Mg1Ti1Zn1', 'Alloy_Al1Li0.5Mg1Sn0.2Zn0.5', 'Alloy_Al1Li1Mg1Sn1Zn1', 'Alloy_Al1Mo0.5Nb1Ta0.5Ti1Zr1', 'Alloy_Al1Nb1.5Ta0.5Ti1.5Zr0.5', 'Alloy_Al1Nb1Ta1Ti1V1', 'Alloy_Al1Nb1Ti1V1', 'Alloy_Al1Nb1Ti1V1Zr1', 'Alloy_Al1Ti1V1Y1Zr1', 'Alloy_Al2.3Co1Cr1Cu1Fe1Ni1', 'Alloy_Al2.5Co1Cr1Cu1Fe1Ni1', 'Alloy_Al2.5Co1Cr1Fe1Ni1', 'Alloy_Al2.8Co1Cr1Cu1Fe1Ni1', 'Alloy_Al20Co10Cr10Cu10Fe10Mn10Ni10Ti10V10', 'Alloy_Al20Li20Mg10Sc20Ti30', 'Alloy_Al2Co1Cr1Cu1Fe1Ni1', 'Alloy_Al2Co1Cr1Fe1Ni1', 'Alloy_Al2Co1Cr1Fe1Ni1Ti1', 'Alloy_Al2Cr1Cu1Fe1Ni2', 'Alloy_Al2Cr1Fe1Mn1Ti0.25', 'Alloy_Al2Cr1Fe1Mn1Ti1', 'Alloy_Al3Co1Cr1Cu1Fe1Ni1', 'Alloy_Al3Co1Cr1Fe1Ni1', 'Alloy_Al3Cr1Cu1Fe1Ni2', 'Alloy_Al3Cr1Fe1Mn1Ti025', 'Alloy_Al40Co7.5Cr7.5Cu7.5Fe7.5Mn7.5Ni7.5Ti7.5V7.5', 'Alloy_Al4Cr1Fe1Mn1Ti0.25', 'Alloy_Al80Cu5Li5Mg5Zn5', 'Alloy_Al80Li5Mg5Sn5Zn5', 'Alloy_AlBa', 'Alloy_AlBe', 'Alloy_AlBi', 'Alloy_AlCa', 'Alloy_AlCd', 'Alloy_AlCr', 'Alloy_AlGa', 'Alloy_AlGe', 'Alloy_AlIn', 'Alloy_AlNb', 'Alloy_AlPb', 'Alloy_AlSe', 'Alloy_AlSi', 'Alloy_AlSn', 'Alloy_AlSr', 'Alloy_AlW', 'Alloy_AlYb', 'Alloy_AsCd', 'Alloy_AsCu', 'Alloy_AsMo', 'Alloy_AsPb', 'Alloy_AsPd', 'Alloy_AsTe', 'Alloy_AsTh', 'Alloy_AsZn', 'Alloy_Au0.05Ta0.95', 'Alloy_Au0.05Ti0.95', 'Alloy_Au0.08V0.92', 'Alloy_Au0.1Nb0.9', 'Alloy_Au0.1Zr0.9', 'Alloy_Au0.25Cu0.75', 'Alloy_Au0.25Pd0.75', 'Alloy_Au0.53V0.47', 'Alloy_Au0.5Cu0.5', 'Alloy_Au0.5Pd0.5', 'Alloy_Au0.71V0.29', 'Alloy_Au0.75Cu0.25', 'Alloy_Au0.7Fe0.3', 'Alloy_Au0.85Fe0.15', 'Alloy_Au0.85Li0.15', 'Alloy_Au0.85Pt0.15', 'Alloy_Au0.8Cr0.2', 'Alloy_Au0.8Ni0.2', 'Alloy_Au0.95Ta0.05', 'Alloy_Au0.9Cr0.1', 'Alloy_Au0.9Mn0.1', 'Alloy_Au0.9Nb0.1', 'Alloy_Au0.9Ni0.1', 'Alloy_Au0.9V0.1', 'Alloy_Au0.9Zn0.1', 'Alloy_AuBi', 'Alloy_AuCo', 'Alloy_AuCr', 'Alloy_AuMo', 'Alloy_AuPb', 'Alloy_AuSb', 'Alloy_AuTa', 'Alloy_AuTe', 'Alloy_AuW', 'Alloy_Ba0.25Ca0.75', 'Alloy_Ba0.25Eu0.75', 'Alloy_Ba0.25Sr0.75', 'Alloy_Ba0.25Yb0.75', 'Alloy_Ba0.5Ca0.5', 'Alloy_Ba0.5Eu0.5', 'Alloy_Ba0.5Sr0.5', 'Alloy_Ba0.5Yb0.5', 'Alloy_Ba0.75Ca0.25', 'Alloy_Ba0.75Eu0.25', 'Alloy_Ba0.75Sr0.25', 'Alloy_Ba0.75Yb0.25', 'Alloy_BaFe', 'Alloy_BaMg', 'Alloy_BaMo', 'Alloy_BaSc', 'Alloy_BaSn', 'Alloy_BaTi', 'Alloy_BaV', 'Alloy_BaY', 'Alloy_Be0.02W0.98', 'Alloy_Be0.48Cu0.52', 'Alloy_Be0.4Co0.6', 'Alloy_Be1Cu1Ni1Ti1V1Zr1', 'Alloy_BeBi', 'Alloy_BeCr', 'Alloy_BeFe', 'Alloy_BeGa', 'Alloy_BeGe', 'Alloy_BeHf', 'Alloy_BeIn', 'Alloy_BeLi', 'Alloy_BeMg', 'Alloy_BeMo', 'Alloy_BeNb', 'Alloy_BeRu', 'Alloy_BeSi', 'Alloy_BeSr', 'Alloy_BeTa', 'Alloy_BeTh', 'Alloy_Ca0.25Sr0.75', 'Alloy_Ca0.25Yb0.75', 'Alloy_Ca0.5Sr0.5', 'Alloy_Ca0.5Yb0.5', 'Alloy_Ca0.75Sr0.25', 'Alloy_Ca0.7Yb0.3', 'Alloy_Ca0.85Yb0.15', 'Alloy_CaLa', 'Alloy_CaLi', 'Alloy_CaLu', 'Alloy_CaMg', 'Alloy_CaMo', 'Alloy_CaNa', 'Alloy_CaNd', 'Alloy_CaNi', 'Alloy_CaPt', 'Alloy_CaSb', 'Alloy_CaSc', 'Alloy_CaTi', 'Alloy_CaTm', 'Alloy_CaV', 'Alloy_CaY', 'Alloy_Cd0.25Mg0.75', 'Alloy_Cd0.5Mg0.5', 'Alloy_Cd0.75Mg0.25', 'Alloy_CdEu', 'Alloy_CdFe', 'Alloy_CdGa', 'Alloy_CdIn', 'Alloy_CdMo', 'Alloy_CdNa', 'Alloy_CdPb', 'Alloy_CdRb', 'Alloy_CdSn', 'Alloy_CdTl', 'Alloy_CdV', 'Alloy_CdZn', 'Alloy_CeCo', 'Alloy_CeCr', 'Alloy_CeFe', 'Alloy_CeHf', 'Alloy_CeIn', 'Alloy_CeIr', 'Alloy_CeLi', 'Alloy_CeMn', 'Alloy_CeMo', 'Alloy_CePu', 'Alloy_CeTa', 'Alloy_CeTi', 'Alloy_CeU', 'Alloy_CeV', 'Alloy_CeW', 'Alloy_Co0.1Cr0.9', 'Alloy_Co0.25Fe0.75', 'Alloy_Co0.25Ni0.75', 'Alloy_Co0.25Os0.75', 'Alloy_Co0.25Pd0.75', 'Alloy_Co0.25Pt0.75', 'Alloy_Co0.25Re0.75', 'Alloy_Co0.25Rh0.75', 'Alloy_Co0.25Ru0.75', 'Alloy_Co0.2Ir0.8', 'Alloy_Co0.56Cr0.44', 'Alloy_Co0.5Cr1Fe1Mn1.5Ni1', 'Alloy_Co0.5Fe0.5', 'Alloy_Co0.5Ni0.5', 'Alloy_Co0.5Os0.5', 'Alloy_Co0.5Pd0.5', 'Alloy_Co0.5Pt0.5', 'Alloy_Co0.5Re0.5', 'Alloy_Co0.5Rh0.5', 'Alloy_Co0.5Ru0.5', 'Alloy_Co0.75Fe0.25', 'Alloy_Co0.75Ni0.25', 'Alloy_Co0.75Os0.25', 'Alloy_Co0.75Pd0.25', 'Alloy_Co0.75Pt0.25', 'Alloy_Co0.75Re0.25', 'Alloy_Co0.75Rh0.25', 'Alloy_Co0.75Ru0.25', 'Alloy_Co0.7Cr0.3', 'Alloy_Co0.7Ir0.3', 'Alloy_Co0.85Cr0.15', 'Alloy_Co0.8Rh0.2', 'Alloy_Co0.9Ga0.1', 'Alloy_Co0.9Ge0.1', 'Alloy_Co1.5Cr0.5Fe1Mn0.5Ni1', 'Alloy_Co1.5Cr1Fe1Mo0.1Ni1.5Ti0.5', 'Alloy_Co1.5Cr1Fe1Mo0.5Ni1.5Ti0.5', 'Alloy_Co1.5Cr1Fe1Mo0.8Ni1.5Ti0.5', 'Alloy_Co1.5Cr1Fe1Ni1.5Ti0.5', 'Alloy_Co1.5Cr1Fe1Ni1.5Ti1', 'Alloy_Co1Cr0.75Fe1Mn0.75Ni1', 'Alloy_Co1Cr1.25Fe1Mn0.25Ni1', 'Alloy_Co1Cr1Cu0.5Fe1Ni1', 'Alloy_Co1Cr1Cu1Fe1Mn1', 'Alloy_Co1Cr1Cu1Fe1Mn1Ni1', 'Alloy_Co1Cr1Cu1Fe1Mn1Ni1Ti1V1', 'Alloy_Co1Cr1Cu1Fe1Ni1', 'Alloy_Co1Cr1Cu1Fe1Ni1Ti0.5', 'Alloy_Co1Cr1Cu1Fe1Ni1Ti0.8', 'Alloy_Co1Cr1Cu1Fe1Ni1Ti1', 'Alloy_Co1Cr1Cu1Fe1Ni1Ti2', 'Alloy_Co1Cr1Fe0.5Mn0.5Ni1.5', 'Alloy_Co1Cr1Fe1Ge1Mn1Ni1', 'Alloy_Co1Cr1Fe1Hf1Ni1', 'Alloy_Co1Cr1Fe1Mn1Ni1', 'Alloy_Co1Cr1Fe1Mo0.1Ni1', 'Alloy_Co1Cr1Fe1Mo0.2Ni1', 'Alloy_Co1Cr1Fe1Mo0.3Ni1', 'Alloy_Co1Cr1Fe1Mo1Ni1', 'Alloy_Co1Cr1Fe1Nb1Ni1', 'Alloy_Co1Cr1Fe1Ni1', 'Alloy_Co1Cr1Fe1Ni1Pd1', 'Alloy_Co1Cr1Fe1Ni1Pd2', 'Alloy_Co1Cr1Fe1Ni1Ta1', 'Alloy_Co1Cr1Fe1Ni1Ti0.3', 'Alloy_Co1Cr1Fe1Ni1Ti0.5', 'Alloy_Co1Cr1Fe1Ni1Ti1', 'Alloy_Co1Cr1Fe1Ni1V1', 'Alloy_Co1Cr1Fe1Ni1W1', 'Alloy_Co1Cr1Fe1Ni1Y1', 'Alloy_Co1Cr1Fe1Ni1Zr1', 'Alloy_Co1Cr1Mn1Ni1', 'Alloy_Co1Cr1Mn1Ni1V1', 'Alloy_Co1Cr1Ni1', 'Alloy_Co1Cr2Fe1Ni1', 'Alloy_Co1Cu1Fe1Ni1V1', 'Alloy_Co1Cu1Hf1Ti1Zr1', 'Alloy_Co1Fe1Ga1Mn1Ni1', 'Alloy_Co1Fe1Mn1Mo1Ni1', 'Alloy_Co1Fe1Mn1Ni1', 'Alloy_Co1Fe1Mn1Ni1Sn1', 'Alloy_Co1Fe1Mn1Ni1V1', 'Alloy_Co1Fe1Ni1', 'Alloy_Co1Fe1Ni1Pd1', 'Alloy_Co1Fe1Re1Ru1', 'Alloy_CoDy', 'Alloy_CoEr', 'Alloy_CoGd', 'Alloy_CoIn', 'Alloy_CoLa', 'Alloy_CoLu', 'Alloy_CoNd', 'Alloy_CoPr', 'Alloy_CoSc', 'Alloy_CoSm', 'Alloy_CoTa', 'Alloy_CoTe', 'Alloy_CoW', 'Alloy_CoYb', 'Alloy_Cr0.05Re0.95', 'Alloy_Cr0.05Ta0.95', 'Alloy_Cr0.1Ir0.9', 'Alloy_Cr0.1Nb0.9', 'Alloy_Cr0.1Rh0.9', 'Alloy_Cr0.25Fe0.75', 'Alloy_Cr0.25Ir0.75', 'Alloy_Cr0.25Mo0.75', 'Alloy_Cr0.25Os0.75', 'Alloy_Cr0.25Pt0.75', 'Alloy_Cr0.25V0.75', 'Alloy_Cr0.2Rh0.8', 'Alloy_Cr0.2Ru0.8', 'Alloy_Cr0.2W0.8', 'Alloy_Cr0.3Pd0.7', 'Alloy_Cr0.3Rh0.7', 'Alloy_Cr0.45Os0.55', 'Alloy_Cr0.4Ir0.6', 'Alloy_Cr0.4Rh0.6', 'Alloy_Cr0.4Ru0.6', 'Alloy_Cr0.56Ni0.44', 'Alloy_Cr0.5Fe0.5', 'Alloy_Cr0.5Ir0.5', 'Alloy_Cr0.5Mn0.5', 'Alloy_Cr0.5Mo0.5', 'Alloy_Cr0.5Pt0.5', 'Alloy_Cr0.5Rh0.5', 'Alloy_Cr0.5V0.5', 'Alloy_Cr0.75Fe0.25', 'Alloy_Cr0.75Mn0.25', 'Alloy_Cr0.75Mo0.25', 'Alloy_Cr0.75V0.25', 'Alloy_Cr0.85Ru0.15', 'Alloy_Cr0.8Re0.2', 'Alloy_Cr0.95Ir0.05', 'Alloy_Cr0.9Os0.1', 'Alloy_Cr0.9W0.1', 'Alloy_Cr1Cu1Fe1Mn1Ni1', 'Alloy_Cr1Cu1Fe1Mn2Ni2', 'Alloy_Cr1Cu1Fe1Mo1Ni1', 'Alloy_Cr1Cu1Fe1Ni1Zr1', 'Alloy_Cr1Cu1Fe1Ni2', 'Alloy_Cr1Cu2Fe2Mn1Ni2', 'Alloy_Cr1Cu2Fe2Mn2Ni1', 'Alloy_Cr1Fe1.5Mn1Ni0.5', 'Alloy_Cr1Fe1Mn1Ni1Ti1', 'Alloy_Cr1Fe1Ni1', 'Alloy_Cr1Mo0.5Nb1Ta0.5Ti1Zr1', 'Alloy_Cr1Mo1Nb1Re1Ta1V1W1', 'Alloy_Cr1Mo1Nb1Ta1V1W1', 'Alloy_Cr1Nb1Ti1V1Zr1', 'Alloy_Cr1Nb1Ti1Zr1', 'Alloy_Cr2Cu1Fe2Mn1Ni1', 'Alloy_Cr2Cu1Fe2Mn2Ni2', 'Alloy_Cr2Cu2Fe1Mn2Ni2', 'Alloy_Cr2Cu2Fe2Mn1Ni2', 'Alloy_CrCu', 'Alloy_CrHf', 'Alloy_CrMg', 'Alloy_CrNb', 'Alloy_CrSe', 'Alloy_CrTa', 'Alloy_CrTe', 'Alloy_CrY', 'Alloy_CrZr', 'Alloy_Cs0.25Rb0.75', 'Alloy_Cs0.5Rb0.5', 'Alloy_Cs0.75Rb0.25', 'Alloy_CsGa', 'Alloy_CsHf', 'Alloy_CsIn', 'Alloy_CsLi', 'Alloy_CsMg', 'Alloy_CsMo', 'Alloy_CsNa', 'Alloy_CsNb', 'Alloy_CsTa', 'Alloy_CsTe', 'Alloy_CsTl', 'Alloy_CsV', 'Alloy_Cu0.1Rh0.9', 'Alloy_Cu0.25Ni0.75', 'Alloy_Cu0.25Pd0.75', 'Alloy_Cu0.25Pt0.75', 'Alloy_Cu0.5Mn0.5', 'Alloy_Cu0.5Ni0.5', 'Alloy_Cu0.5Pd0.5', 'Alloy_Cu0.5Pt0.5', 'Alloy_Cu0.75Mn0.25', 'Alloy_Cu0.75Ni0.25', 'Alloy_Cu0.75Pd0.25', 'Alloy_Cu0.75Pt0.25', 'Alloy_Cu0.85Li0.15', 'Alloy_Cu0.8Rh0.2', 'Alloy_Cu1Fe1Hf1Ti1Zr1', 'Alloy_CuFe', 'Alloy_CuGa', 'Alloy_CuGe', 'Alloy_Dy1Gd1Ho1Tb1Y1', 'Alloy_Dy1Gd1Lu1Tb1Tm1', 'Alloy_Dy1Gd1Lu1Tb1Y1', 'Alloy_DyTa', 'Alloy_DyV', 'Alloy_DyW', 'Alloy_DyZr', 'Alloy_ErFe', 'Alloy_ErHf', 'Alloy_ErMn', 'Alloy_ErRe', 'Alloy_ErRu', 'Alloy_ErSn', 'Alloy_ErTa', 'Alloy_ErTi', 'Alloy_ErV', 'Alloy_ErW', 'Alloy_ErZr', 'Alloy_EuFe', 'Alloy_EuLa', 'Alloy_EuMo', 'Alloy_EuRh', 'Alloy_EuTa', 'Alloy_EuV', 'Alloy_EuW', 'Alloy_Fe0.15Pt0.85', 'Alloy_Fe0.1V0.9', 'Alloy_Fe0.25Ir0.75', 'Alloy_Fe0.25Ni0.75', 'Alloy_Fe0.25Pd0.75', 'Alloy_Fe0.25Rh0.75', 'Alloy_Fe0.2Os0.8', 'Alloy_Fe0.2Ru0.8', 'Alloy_Fe0.4Mo0.6', 'Alloy_Fe0.5Ir0.5', 'Alloy_Fe0.5Mn0.5', 'Alloy_Fe0.5Ni0.5', 'Alloy_Fe0.5Os0.5', 'Alloy_Fe0.5Pd0.5', 'Alloy_Fe0.5Ru0.5', 'Alloy_Fe0.6Os0.4', 'Alloy_Fe0.6Ru0.4', 'Alloy_Fe0.6Se0.4', 'Alloy_Fe0.75Ir0.25', 'Alloy_Fe0.75Mn0.25', 'Alloy_Fe0.75Ni0.25', 'Alloy_Fe0.75Pd0.25', 'Alloy_Fe0.75Rh0.25', 'Alloy_Fe0.7Pt0.3', 'Alloy_Fe0.85Pt0.15', 'Alloy_Fe0.85Zn0.15', 'Alloy_Fe0.8V0.2', 'Alloy_Fe0.93Si0.07', 'Alloy_Fe0.9Ga0.1', 'Alloy_Fe0.9Os0.1', 'Alloy_Fe0.9Rh0.1', 'Alloy_Fe0.9Ru0.1', 'Alloy_FeGa', 'Alloy_FeGd', 'Alloy_FeHf', 'Alloy_FeHo', 'Alloy_FeIn', 'Alloy_FeLa', 'Alloy_FeLi', 'Alloy_FeLu', 'Alloy_FeMg', 'Alloy_FeNa', 'Alloy_FeNb', 'Alloy_FePr', 'Alloy_FePu', 'Alloy_FeSb', 'Alloy_FeSc', 'Alloy_FeSm', 'Alloy_FeTa', 'Alloy_FeTb', 'Alloy_FeTh', 'Alloy_FeTm', 'Alloy_FeU', 'Alloy_FeY', 'Alloy_FeYb', 'Alloy_FeZn', 'Alloy_Ga0.15Ti0.85', 'Alloy_GaGe', 'Alloy_GaIn', 'Alloy_GaNa', 'Alloy_GaNb', 'Alloy_GaPb', 'Alloy_GaRb', 'Alloy_GaSn', 'Alloy_GaSr', 'Alloy_GaTl', 'Alloy_GaZn', 'Alloy_Gd1Ho1La1Tb1Y1', 'Alloy_GdIn', 'Alloy_GdMn', 'Alloy_GdPb', 'Alloy_GdRe', 'Alloy_GdRu', 'Alloy_GdSn', 'Alloy_GdTi', 'Alloy_GdV', 'Alloy_GdW', 'Alloy_GdYb', 'Alloy_GdZr', 'Alloy_GeIn', 'Alloy_GeLu', 'Alloy_GeMn', 'Alloy_GeMo', 'Alloy_GeNb', 'Alloy_GePb', 'Alloy_GeRe', 'Alloy_GeSb', 'Alloy_GeTi', 'Alloy_GeTl', 'Alloy_GeYb', 'Alloy_GeZn', 'Alloy_Hf0.25Nb0.75', 'Alloy_Hf0.25Sc0.75', 'Alloy_Hf0.25Ta0.75', 'Alloy_Hf0.25Ti0.75', 'Alloy_Hf0.25Zr0.75', 'Alloy_Hf0.5Nb0.5', 'Alloy_Hf0.5Sc0.5', 'Alloy_Hf0.5Ta0.5', 'Alloy_Hf0.5Ti0.5', 'Alloy_Hf0.5Zr0.5', 'Alloy_Hf0.75Nb0.25', 'Alloy_Hf0.75Sc0.25', 'Alloy_Hf0.75Ta0.25', 'Alloy_Hf0.75Ti0.25', 'Alloy_Hf0.75Zr0.25', 'Alloy_Hf1Mo1Nb1Ti1Zr1', 'Alloy_Hf1Nb1Ta1Ti1V1Zr1', 'Alloy_Hf1Nb1Ta1Ti1Zr1', 'Alloy_Hf1Nb1Ta1Zr1', 'Alloy_Hf1Nb1Ti1V1Zr1', 'Alloy_Hf1Nb1Ti1Zr1', 'Alloy_HfLi', 'Alloy_HfMn', 'Alloy_HfMo', 'Alloy_HfPu', 'Alloy_HfRb', 'Alloy_HfTh', 'Alloy_HfV', 'Alloy_HfY', 'Alloy_HoMn', 'Alloy_HoMo', 'Alloy_HoSn', 'Alloy_InMn', 'Alloy_InNb', 'Alloy_InRb', 'Alloy_InSi', 'Alloy_InSn', 'Alloy_InTa', 'Alloy_InV', 'Alloy_InZn', 'Alloy_Ir0.02W0.98', 'Alloy_Ir0.05Mo0.95', 'Alloy_Ir0.05Nb0.95', 'Alloy_Ir0.05Ta0.95', 'Alloy_Ir0.05Ti0.95', 'Alloy_Ir0.1V0.9', 'Alloy_Ir0.25Ni0.75', 'Alloy_Ir0.25Pt0.75', 'Alloy_Ir0.25Rh0.75', 'Alloy_Ir0.25Tc0.75', 'Alloy_Ir0.2Ru0.8', 'Alloy_Ir0.4Ru0.6', 'Alloy_Ir0.5Mo0.5', 'Alloy_Ir0.5Ni0.5', 'Alloy_Ir0.5Pt0.5', 'Alloy_Ir0.5Rh0.5', 'Alloy_Ir0.5Tc0.5', 'Alloy_Ir0.5W0.5', 'Alloy_Ir0.6W0.4', 'Alloy_Ir0.75Ni0.25', 'Alloy_Ir0.75Pt0.25', 'Alloy_Ir0.75Rh0.25', 'Alloy_Ir0.7Ru0.30', 'Alloy_Ir0.7W0.3', 'Alloy_Ir0.85Ru0.15', 'Alloy_Ir0.85W0.15', 'Alloy_Ir0.8Mo0.2', 'Alloy_Ir0.8Pd0.2', 'Alloy_Ir0.95Ti0.05', 'Alloy_Ir0.9Mo0.1', 'Alloy_Ir0.9Nb0.1', 'Alloy_Ir0.9Pd0.1', 'Alloy_Ir0.9Ta0.1', 'Alloy_Ir0.9V0.1', 'Alloy_IrNb', 'Alloy_IrPr', 'Alloy_IrRu', 'Alloy_IrTa', 'Alloy_KMg', 'Alloy_KMo', 'Alloy_KNa', 'Alloy_KNb', 'Alloy_KTa', 'Alloy_KTi', 'Alloy_KV', 'Alloy_KZn', 'Alloy_KZr', 'Alloy_LaLi', 'Alloy_LaMn', 'Alloy_LaMo', 'Alloy_LaNb', 'Alloy_LaTa', 'Alloy_LaTi', 'Alloy_LaV', 'Alloy_LaW', 'Alloy_Li0.1Mg0.9', 'Alloy_Li0.35Mg0.65', 'Alloy_Li0.5Mg0.5', 'Alloy_Li0.85Mg0.15', 'Alloy_LiMn', 'Alloy_LiMo', 'Alloy_LiNa', 'Alloy_LiNi', 'Alloy_LiPr', 'Alloy_LiPu', 'Alloy_LiRb', 'Alloy_LiSb', 'Alloy_LiSe', 'Alloy_LiSi', 'Alloy_LiTa', 'Alloy_LiTe', 'Alloy_LiTi', 'Alloy_LiZr', 'Alloy_LuPb', 'Alloy_LuV', 'Alloy_LuW', 'Alloy_LuYb', 'Alloy_MgNa', 'Alloy_MgNb', 'Alloy_MgNi', 'Alloy_MgPb', 'Alloy_MgRb', 'Alloy_MgSb', 'Alloy_MgSn', 'Alloy_MgSr', 'Alloy_MgTh', 'Alloy_MgV', 'Alloy_MgYb', 'Alloy_MgZn', 'Alloy_Mn0.25V0.75', 'Alloy_Mn0.5V0.5', 'Alloy_Mn0.6V0.4', 'Alloy_Mn0.7V0.3', 'Alloy_MnMo', 'Alloy_MnNd', 'Alloy_MnPr', 'Alloy_MnPu', 'Alloy_MnSm', 'Alloy_MnSr', 'Alloy_MnTb', 'Alloy_MnY', 'Alloy_Mo0.07Re0.93', 'Alloy_Mo0.15Pd0.85', 'Alloy_Mo0.1Rh0.9', 'Alloy_Mo0.1Ru0.9', 'Alloy_Mo0.25Nb0.75', 'Alloy_Mo0.25Rh0.75', 'Alloy_Mo0.25Ru0.75', 'Alloy_Mo0.25Ta0.75', 'Alloy_Mo0.25Ti0.75', 'Alloy_Mo0.25V0.75', 'Alloy_Mo0.25W0.75', 'Alloy_Mo0.2Os0.8', 'Alloy_Mo0.2Rh0.8', 'Alloy_Mo0.2Ru0.8', 'Alloy_Mo0.35Os0.65', 'Alloy_Mo0.35Ru0.65', 'Alloy_Mo0.3Os0.7', 'Alloy_Mo0.3Pd0.7', 'Alloy_Mo0.3Rh0.7', 'Alloy_Mo0.3Ru0.7', 'Alloy_Mo0.4Rh0.6', 'Alloy_Mo0.5Nb0.5', 'Alloy_Mo0.5Pd0.5', 'Alloy_Mo0.5Rh0.5', 'Alloy_Mo0.5Ta0.5', 'Alloy_Mo0.5Ti0.5', 'Alloy_Mo0.5V0.5', 'Alloy_Mo0.5W0.5', 'Alloy_Mo0.75Nb0.25', 'Alloy_Mo0.75Re0.25', 'Alloy_Mo0.75Ta0.25', 'Alloy_Mo0.75Ti0.25', 'Alloy_Mo0.75V0.25', 'Alloy_Mo0.75W0.25', 'Alloy_Mo0.7Tc0.3', 'Alloy_Mo0.8Tc0.2', 'Alloy_Mo0.95Os0.05', 'Alloy_Mo0.95Rh0.05', 'Alloy_Mo0.98Pd0.02', 'Alloy_Mo0.9Re0.1', 'Alloy_Mo0.9Ru0.1', 'Alloy_Mo0.9Tc0.1', 'Alloy_Mo1Nb1Re1Ta1Ti1V1W1', 'Alloy_Mo1Nb1Re1Ta1V1W1', 'Alloy_Mo1Nb1Re1Ta1W1', 'Alloy_Mo1Nb1Ta1Ti1V1', 'Alloy_Mo1Nb1Ta1Ti1V1W1', 'Alloy_Mo1Nb1Ta1V1', 'Alloy_Mo1Nb1Ta1V1W1', 'Alloy_Mo1Nb1Ta1W1', 'Alloy_Mo1Nb1Ti1V1Zr1', 'Alloy_Mo1Pd1Rh1Ru1', 'Alloy_Mo21.7Nb20.6Ta15.6V21W21.1', 'Alloy_Mo25.6Nb22.7Ta24.4W27.3', 'Alloy_MoNd', 'Alloy_MoPa', 'Alloy_MoPb', 'Alloy_Nb0.05Ni0.95', 'Alloy_Nb0.1Os0.9', 'Alloy_Nb0.1Rh0.9', 'Alloy_Nb0.25Ta0.75', 'Alloy_Nb0.25Ti0.75', 'Alloy_Nb0.25W0.75', 'Alloy_Nb0.25Zr0.75', 'Alloy_Nb0.2Os0.8', 'Alloy_Nb0.5Ta0.5', 'Alloy_Nb0.5Ti0.5', 'Alloy_Nb0.5W0.5', 'Alloy_Nb0.5Zr0.5', 'Alloy_Nb0.65Ru0.35', 'Alloy_Nb0.6Re0.4', 'Alloy_Nb0.75Re0.25', 'Alloy_Nb0.75Ta0.25', 'Alloy_Nb0.75Ti0.25', 'Alloy_Nb0.75W0.25', 'Alloy_Nb0.75Zr0.25', 'Alloy_Nb0.8Pd0.2', 'Alloy_Nb0.9Os0.1', 'Alloy_Nb0.9Pd0.1', 'Alloy_Nb0.9Re0.1', 'Alloy_Nb0.9Rh0.1', 'Alloy_Nb0.9Ru0.1', 'Alloy_Nb1Re1Ta1Ti1V1', 'Alloy_Nb1Ta1Ti1V1', 'Alloy_Nb1Ta1Ti1V1W1', 'Alloy_Nb1Ta1V1W1', 'Alloy_Nb1Ti1V1Zr1', 'Alloy_Nb1Ti1V2Zr1', 'Alloy_Nd0.25Th0.75', 'Alloy_Nd0.5Th0.5', 'Alloy_Nd0.75Th0.25', 'Alloy_Ni0.1Os0.9', 'Alloy_Ni0.1Ru0.9', 'Alloy_Ni0.1Tc0.9', 'Alloy_Ni0.25Os0.75', 'Alloy_Ni0.25Pt0.75', 'Alloy_Ni0.25Rh0.75', 'Alloy_Ni0.25Tc0.75', 'Alloy_Ni0.2Ru0.8', 'Alloy_Ni0.3Ru0.7', 'Alloy_Ni0.4Tc0.6', 'Alloy_Ni0.5Pd0.5', 'Alloy_Ni0.5Pt0.5', 'Alloy_Ni0.5Rh0.5', 'Alloy_Ni0.75Pd0.25', 'Alloy_Ni0.75Pt0.25', 'Alloy_Ni0.75Rh0.25', 'Alloy_Ni0.75Zn0.25', 'Alloy_Ni0.85Tc0.15', 'Alloy_Ni0.85V0.15', 'Alloy_Ni0.9Mo0.1', 'Alloy_Ni0.9V0.1', 'Alloy_Ni0.9W0.1', 'Alloy_Ni0.9Zn0.1', 'Alloy_Os0.05W0.95', 'Alloy_Os0.15Ta0.85', 'Alloy_Os0.15Ti0.85', 'Alloy_Os0.1Pt0.9', 'Alloy_Os0.1Rh0.9', 'Alloy_Os0.25Re0.75', 'Alloy_Os0.25Rh0.75', 'Alloy_Os0.25Ru0.75', 'Alloy_Os0.2Pt0.8', 'Alloy_Os0.2Rh0.8', 'Alloy_Os0.45Rh0.55', 'Alloy_Os0.4Rh0.6', 'Alloy_Os0.5Re0.5', 'Alloy_Os0.5Ru0.5', 'Alloy_Os0.75Re0.25', 'Alloy_Os0.75Ru0.25', 'Alloy_Os0.7V0.3', 'Alloy_Os0.7W0.3', 'Alloy_Os0.85Rh0.15', 'Alloy_Os0.8Ta0.2', 'Alloy_Os0.8V0.2', 'Alloy_Os0.8W0.2', 'Alloy_Os0.9Ti0.1', 'Alloy_Os0.9V0.1', 'Alloy_Os0.9W0.1', 'Alloy_OsPd', 'Alloy_OsPt', 'Alloy_OsPu', 'Alloy_OsTh', 'Alloy_OsU', 'Alloy_OsYb', 'Alloy_Pb0.25Tl0.75', 'Alloy_Pb0.75Tl0.25', 'Alloy_PbPr', 'Alloy_PbPu', 'Alloy_PbSb', 'Alloy_PbSc', 'Alloy_PbSi', 'Alloy_PbSm', 'Alloy_PbSn', 'Alloy_PbTh', 'Alloy_PbZn', 'Alloy_Pd0.1V0.9', 'Alloy_Pd0.25Pt0.75', 'Alloy_Pd0.25Rh0.75', 'Alloy_Pd0.2V0.8', 'Alloy_Pd0.4Si0.6', 'Alloy_Pd0.4U0.6', 'Alloy_Pd0.5Pt0.5', 'Alloy_Pd0.5Rh0.5', 'Alloy_Pd0.6Pu0.4', 'Alloy_Pd0.6V0.4', 'Alloy_Pd0.75Pt0.25', 'Alloy_Pd0.75Rh0.25', 'Alloy_Pd0.8V0.2', 'Alloy_PdRu', 'Alloy_PdW', 'Alloy_PmRh', 'Alloy_PmRu', 'Alloy_PmV', 'Alloy_Pr0.25Th0.75', 'Alloy_Pr0.5Th0.5', 'Alloy_Pr0.75Th0.25', 'Alloy_PrPu', 'Alloy_PrTa', 'Alloy_PrTi', 'Alloy_PrU', 'Alloy_PrV', 'Alloy_PrW', 'Alloy_Pt0.05V0.95', 'Alloy_Pt0.15Ru0.85', 'Alloy_Pt0.1Re0.9', 'Alloy_Pt0.25Re0.75', 'Alloy_Pt0.25Rh0.75', 'Alloy_Pt0.35Re0.65', 'Alloy_Pt0.5Rh0.5', 'Alloy_Pt0.5Ru0.5', 'Alloy_Pt0.6V0.4', 'Alloy_Pt0.75Rh0.25', 'Alloy_Pt0.75Ru0.25', 'Alloy_Pt0.7Re0.3', 'Alloy_Pt0.85Zn0.15', 'Alloy_Pt0.85Zr0.15', 'Alloy_Pt0.8Re0.2', 'Alloy_Pt0.8V0.2', 'Alloy_Pt0.9Re0.1', 'Alloy_PtRe', 'Alloy_PtSr', 'Alloy_PtZn', 'Alloy_Pu0.1Sc0.9', 'Alloy_Pu0.25Sc0.75', 'Alloy_Pu0.25Zr0.75', 'Alloy_Pu0.5Sc0.5', 'Alloy_Pu0.5Zr0.5', 'Alloy_Pu0.75Sc0.25', 'Alloy_Pu0.75Zr0.25', 'Alloy_PuSm', 'Alloy_PuTa', 'Alloy_PuV', 'Alloy_RbTa', 'Alloy_RbTi', 'Alloy_RbTl', 'Alloy_RbV', 'Alloy_RbZn', 'Alloy_Re0.1Ta0.9', 'Alloy_Re0.1Ti0.9', 'Alloy_Re0.1V0.9', 'Alloy_Re0.1W0.9', 'Alloy_Re0.25Ru0.75', 'Alloy_Re0.25Tc0.75', 'Alloy_Re0.25Ti0.75', 'Alloy_Re0.25V0.75', 'Alloy_Re0.25W0.75', 'Alloy_Re0.2Ta0.8', 'Alloy_Re0.4Ta0.6', 'Alloy_Re0.4Ti0.6', 'Alloy_Re0.5Ru0.5', 'Alloy_Re0.5Tc0.5', 'Alloy_Re0.5V0.5', 'Alloy_Re0.6Ti0.4', 'Alloy_Re0.75Ru0.25', 'Alloy_Re0.75Tc0.25', 'Alloy_Re0.9W0.1', 'Alloy_ReSb', 'Alloy_ReSc', 'Alloy_ReTh', 'Alloy_ReU', 'Alloy_ReY', 'Alloy_ReZr', 'Alloy_Rh0.15Ti0.85', 'Alloy_Rh0.1Ta0.9', 'Alloy_Rh0.1V0.9', 'Alloy_Rh0.25Ru0.75', 'Alloy_Rh0.25Tc0.75', 'Alloy_Rh0.45Ta0.55', 'Alloy_Rh0.5Ru0.5', 'Alloy_Rh0.5Tc0.5', 'Alloy_Rh0.6W0.4', 'Alloy_Rh0.7Ru0.3', 'Alloy_Rh0.85Ru0.15', 'Alloy_Rh0.9Ta0.1', 'Alloy_Rh0.9V0.1', 'Alloy_Rh0.9W0.1', 'Alloy_RhU', 'Alloy_Ru0.1Ta0.9', 'Alloy_Ru0.1Ti0.9', 'Alloy_Ru0.1W0.9', 'Alloy_Ru0.2Ta0.8', 'Alloy_Ru0.2Ti0.8', 'Alloy_Ru0.2W0.8', 'Alloy_Ru0.7W0.3', 'Alloy_Ru0.85Ta0.15', 'Alloy_Ru0.8V0.2', 'Alloy_Ru0.8W0.2', 'Alloy_Ru0.9V0.1', 'Alloy_Ru0.9W0.1', 'Alloy_RuSn', 'Alloy_RuW', 'Alloy_SbSe', 'Alloy_SbSi', 'Alloy_SbZr', 'Alloy_Sc0.1Th0.9', 'Alloy_Sc0.25Th0.75', 'Alloy_Sc0.25Ti0.75', 'Alloy_Sc0.25Y0.75', 'Alloy_Sc0.2Zr0.8', 'Alloy_Sc0.3Th0.7', 'Alloy_Sc0.4Zr0.6', 'Alloy_Sc0.5Th0.5', 'Alloy_Sc0.5Ti0.5', 'Alloy_Sc0.5Y0.5', 'Alloy_Sc0.5Zr0.5', 'Alloy_Sc0.75Th0.25', 'Alloy_Sc0.75Ti0.25', 'Alloy_Sc0.75Y0.25', 'Alloy_Sc0.75Zr0.25', 'Alloy_ScSr', 'Alloy_ScU', 'Alloy_ScV', 'Alloy_ScW', 'Alloy_SiSn', 'Alloy_SiTa', 'Alloy_SiTe', 'Alloy_SiTl', 'Alloy_SiV', 'Alloy_SiW', 'Alloy_SiZn', 'Alloy_Sm0.25Y0.75', 'Alloy_Sm0.5Y0.5', 'Alloy_SmSn', 'Alloy_SmU', 'Alloy_SnTi', 'Alloy_SnV', 'Alloy_SnY', 'Alloy_SnZn', 'Alloy_SrTi', 'Alloy_SrV', 'Alloy_SrY', 'Alloy_Ta0.25Ti0.75', 'Alloy_Ta0.25V0.75', 'Alloy_Ta0.25W0.75', 'Alloy_Ta0.25Zr0.75', 'Alloy_Ta0.5Ti0.5', 'Alloy_Ta0.5V0.5', 'Alloy_Ta0.5W0.5', 'Alloy_Ta0.5Zr0.5', 'Alloy_Ta0.75Ti0.25', 'Alloy_Ta0.75V0.25', 'Alloy_Ta0.75W0.25', 'Alloy_Ta0.75Zr0.25', 'Alloy_TaTb', 'Alloy_TaTl', 'Alloy_TaTm', 'Alloy_Ta_Th', 'Alloy_Tb0.25Th0.75', 'Alloy_Tb0.25Tm0.75', 'Alloy_Tb0.25Y0.75', 'Alloy_Tb0.5Th0.5', 'Alloy_Tb0.5Tm0.5', 'Alloy_Tb0.5Y0.5', 'Alloy_Tb0.75Th0.25', 'Alloy_Tb0.75Tm0.25', 'Alloy_Tb0.75Y0.25', 'Alloy_Th0.25Zr0.75', 'Alloy_Th0.5Zr0.5', 'Alloy_Th0.75Zr0.25', 'Alloy_Ti0.25U0.75', 'Alloy_Ti0.25V0.75', 'Alloy_Ti0.25W0.75', 'Alloy_Ti0.25Zr0.75', 'Alloy_Ti0.5U0.5', 'Alloy_Ti0.5V0.5', 'Alloy_Ti0.5W0.5', 'Alloy_Ti0.5Zr0.5', 'Alloy_Ti0.75U0.25', 'Alloy_Ti0.75V0.25', 'Alloy_Ti0.75W0.25', 'Alloy_Ti0.75Zr0.25', 'Alloy_U0.25Zr0.75', 'Alloy_U0.5Zr0.5', 'Alloy_U0.75Zr0.25', 'Alloy_V0.1Zr0.9', 'Alloy_V0.25W0.75', 'Alloy_V0.5W0.5', 'Alloy_V0.75W0.25']\n",
      "2023-01-18 06:42:23 INFO     DataCleaner: After handling na: 1242 samples, 153 features\n",
      "2023-01-18 06:42:23 INFO     DataCleaner: Reordering columns...\n",
      "2023-01-18 06:42:23 INFO     DataCleaner: Finished transforming.\n",
      "2023-01-18 06:42:23 INFO     FeatureReducer: Starting transforming.\n",
      "2023-01-18 06:42:23 INFO     FeatureReducer: Finished transforming.\n",
      "2023-01-18 06:42:23 INFO     TPOTAdaptor: Starting predicting.\n",
      "2023-01-18 06:42:23 INFO     TPOTAdaptor: Prediction finished successfully.\n",
      "2023-01-18 06:42:23 INFO     TPOTAdaptor: Finished predicting.\n",
      "2023-01-18 06:42:23 INFO     MatPipe prediction completed.\n"
     ]
    }
   ],
   "source": [
    "predictions = pipe.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycm import ConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ConfusionMatrix(actual_vector=test['phase_binary_encoded'].values, predict_vector=predictions['phase_binary_encoded predicted'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict   0         1         \n",
      "Actual\n",
      "0         622       0         \n",
      "\n",
      "1         0         620       \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overall Statistics : \n",
      "\n",
      "95% CI                                                            (1.0,1.0)\n",
      "ACC Macro                                                         1.0\n",
      "ARI                                                               1.0\n",
      "AUNP                                                              1.0\n",
      "AUNU                                                              1.0\n",
      "Bangdiwala B                                                      1.0\n",
      "Bennett S                                                         1.0\n",
      "CBA                                                               1.0\n",
      "CSI                                                               1.0\n",
      "Chi-Squared                                                       1242.0\n",
      "Chi-Squared DF                                                    1\n",
      "Conditional Entropy                                               -0.0\n",
      "Cramer V                                                          1.0\n",
      "Cross Entropy                                                     1.0\n",
      "F1 Macro                                                          1.0\n",
      "F1 Micro                                                          1.0\n",
      "FNR Macro                                                         0.0\n",
      "FNR Micro                                                         0.0\n",
      "FPR Macro                                                         0.0\n",
      "FPR Micro                                                         0.0\n",
      "Gwet AC1                                                          1.0\n",
      "Hamming Loss                                                      0.0\n",
      "Joint Entropy                                                     1.0\n",
      "KL Divergence                                                     0.0\n",
      "Kappa                                                             1.0\n",
      "Kappa 95% CI                                                      (1.0,1.0)\n",
      "Kappa No Prevalence                                               1.0\n",
      "Kappa Standard Error                                              0.0\n",
      "Kappa Unbiased                                                    1.0\n",
      "Krippendorff Alpha                                                1.0\n",
      "Lambda A                                                          1.0\n",
      "Lambda B                                                          1.0\n",
      "Mutual Information                                                1.0\n",
      "NIR                                                               0.50081\n",
      "Overall ACC                                                       1.0\n",
      "Overall CEN                                                       0.0\n",
      "Overall J                                                         (2.0,1.0)\n",
      "Overall MCC                                                       1.0\n",
      "Overall MCEN                                                      0.0\n",
      "Overall RACC                                                      0.5\n",
      "Overall RACCU                                                     0.5\n",
      "P-Value                                                           None\n",
      "PPV Macro                                                         1.0\n",
      "PPV Micro                                                         1.0\n",
      "Pearson C                                                         0.70711\n",
      "Phi-Squared                                                       1.0\n",
      "RCI                                                               1.0\n",
      "RR                                                                621.0\n",
      "Reference Entropy                                                 1.0\n",
      "Response Entropy                                                  1.0\n",
      "SOA1(Landis & Koch)                                               Almost Perfect\n",
      "SOA2(Fleiss)                                                      Excellent\n",
      "SOA3(Altman)                                                      Very Good\n",
      "SOA4(Cicchetti)                                                   Excellent\n",
      "SOA5(Cramer)                                                      Very Strong\n",
      "SOA6(Matthews)                                                    Very Strong\n",
      "Scott PI                                                          1.0\n",
      "Standard Error                                                    0.0\n",
      "TNR Macro                                                         1.0\n",
      "TNR Micro                                                         1.0\n",
      "TPR Macro                                                         1.0\n",
      "TPR Micro                                                         1.0\n",
      "Zero-one Loss                                                     0\n",
      "\n",
      "Class Statistics :\n",
      "\n",
      "Classes                                                           0             1             \n",
      "ACC(Accuracy)                                                     1.0           1.0           \n",
      "AGF(Adjusted F-score)                                             1.0           1.0           \n",
      "AGM(Adjusted geometric mean)                                      1.0           1.0           \n",
      "AM(Difference between automatic and manual classification)        0             0             \n",
      "AUC(Area under the ROC curve)                                     1.0           1.0           \n",
      "AUCI(AUC value interpretation)                                    Excellent     Excellent     \n",
      "AUPR(Area under the PR curve)                                     1.0           1.0           \n",
      "BB(Braun-Blanquet similarity)                                     1.0           1.0           \n",
      "BCD(Bray-Curtis dissimilarity)                                    0.0           0.0           \n",
      "BM(Informedness or bookmaker informedness)                        1.0           1.0           \n",
      "CEN(Confusion entropy)                                            0             0             \n",
      "DOR(Diagnostic odds ratio)                                        None          None          \n",
      "DP(Discriminant power)                                            None          None          \n",
      "DPI(Discriminant power interpretation)                            None          None          \n",
      "ERR(Error rate)                                                   0.0           0.0           \n",
      "F0.5(F0.5 score)                                                  1.0           1.0           \n",
      "F1(F1 score - harmonic mean of precision and sensitivity)         1.0           1.0           \n",
      "F2(F2 score)                                                      1.0           1.0           \n",
      "FDR(False discovery rate)                                         0.0           0.0           \n",
      "FN(False negative/miss/type 2 error)                              0             0             \n",
      "FNR(Miss rate or false negative rate)                             0.0           0.0           \n",
      "FOR(False omission rate)                                          0.0           0.0           \n",
      "FP(False positive/type 1 error/false alarm)                       0             0             \n",
      "FPR(Fall-out or false positive rate)                              0.0           0.0           \n",
      "G(G-measure geometric mean of precision and sensitivity)          1.0           1.0           \n",
      "GI(Gini index)                                                    1.0           1.0           \n",
      "GM(G-mean geometric mean of specificity and sensitivity)          1.0           1.0           \n",
      "HD(Hamming distance)                                              0             0             \n",
      "IBA(Index of balanced accuracy)                                   1.0           1.0           \n",
      "ICSI(Individual classification success index)                     1.0           1.0           \n",
      "IS(Information score)                                             0.99768       1.00233       \n",
      "J(Jaccard index)                                                  1.0           1.0           \n",
      "LS(Lift score)                                                    1.99678       2.00323       \n",
      "MCC(Matthews correlation coefficient)                             1.0           1.0           \n",
      "MCCI(Matthews correlation coefficient interpretation)             Very Strong   Very Strong   \n",
      "MCEN(Modified confusion entropy)                                  0             0             \n",
      "MK(Markedness)                                                    1.0           1.0           \n",
      "N(Condition negative)                                             620           622           \n",
      "NLR(Negative likelihood ratio)                                    0.0           0.0           \n",
      "NLRI(Negative likelihood ratio interpretation)                    Good          Good          \n",
      "NPV(Negative predictive value)                                    1.0           1.0           \n",
      "OC(Overlap coefficient)                                           1.0           1.0           \n",
      "OOC(Otsuka-Ochiai coefficient)                                    1.0           1.0           \n",
      "OP(Optimized precision)                                           1.0           1.0           \n",
      "P(Condition positive or support)                                  622           620           \n",
      "PLR(Positive likelihood ratio)                                    None          None          \n",
      "PLRI(Positive likelihood ratio interpretation)                    None          None          \n",
      "POP(Population)                                                   1242          1242          \n",
      "PPV(Precision or positive predictive value)                       1.0           1.0           \n",
      "PRE(Prevalence)                                                   0.50081       0.49919       \n",
      "Q(Yule Q - coefficient of colligation)                            None          None          \n",
      "QI(Yule Q interpretation)                                         None          None          \n",
      "RACC(Random accuracy)                                             0.25081       0.2492        \n",
      "RACCU(Random accuracy unbiased)                                   0.25081       0.2492        \n",
      "TN(True negative/correct rejection)                               620           622           \n",
      "TNR(Specificity or true negative rate)                            1.0           1.0           \n",
      "TON(Test outcome negative)                                        620           622           \n",
      "TOP(Test outcome positive)                                        622           620           \n",
      "TP(True positive/hit)                                             622           620           \n",
      "TPR(Sensitivity, recall, hit rate, or true positive rate)         1.0           1.0           \n",
      "Y(Youden index)                                                   1.0           1.0           \n",
      "dInd(Distance index)                                              0.0           0.0           \n",
      "sInd(Similarity index)                                            1.0           1.0           \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gptchem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f3b9074e5baa1438c27e2ea813f7f53b7516c83bd70840b6d64eae6820ee5df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
