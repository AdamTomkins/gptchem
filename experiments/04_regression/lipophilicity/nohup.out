nohup: ignoring input
2023-01-31 09:00:42.745360: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-01-31 09:00:43.556296: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-01-31 09:00:43.556387: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-01-31 09:00:43.556399: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-01-31 09:00:46.308170: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2023-01-31 09:00:46.308211: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)
2023-01-31 09:00:46.308232: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (kevin-OptiPlex-9020): /proc/driver/nvidia/version does not exist
2023-01-31 09:00:46.308471: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING:tensorflow:From /home/kevin/anaconda3/envs/gptchem/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤═════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │   value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪═════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │       0 │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │       0 │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │       1 │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧═════════╛
Upload progress:   0%|          | 0.00/1.84k [00:00<?, ?it/s]Upload progress: 100%|██████████| 1.84k/1.84k [00:00<00:00, 2.17Mit/s]
2023-01-31 09:00:49.329 | DEBUG    | gptchem.tuner:tune:188 - Requested fine tuning. {
  "created_at": 1675152049,
  "events": [
    {
      "created_at": 1675152049,
      "level": "info",
      "message": "Created fine-tune: ft-ImkxzeKKyOTHF7ibQ3KAvMEX",
      "object": "fine-tune-event"
    }
  ],
  "fine_tuned_model": null,
  "hyperparams": {
    "batch_size": null,
    "learning_rate_multiplier": 0.02,
    "n_epochs": 8,
    "prompt_loss_weight": 0.01
  },
  "id": "ft-ImkxzeKKyOTHF7ibQ3KAvMEX",
  "model": "ada",
  "object": "fine-tune",
  "organization_id": "org-TFRJXw3PPQocOWbu71eI2t9U",
  "result_files": [],
  "status": "pending",
  "training_files": [
    {
      "bytes": 1840,
      "created_at": 1675152049,
      "filename": "/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_090048/train.jsonl",
      "id": "file-ShUem5K8roxwDRRJA5mwnfEm",
      "object": "file",
      "purpose": "fine-tune",
      "status": "uploaded",
      "status_details": null
    }
  ],
  "updated_at": 1675152049,
  "validation_files": []
}
2023-01-31 09:00:49.501 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:02:50.034 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:04:50.573 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:06:51.136 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:08:51.602 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:10:52.135 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:12:52.592 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:14:53.133 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:16:53.675 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:18:54.229 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:20:54.762 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:22:55.216 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:24:55.663 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:26:56.178 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:28:56.659 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:30:57.151 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:32:57.680 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:34:58.219 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:36:58.721 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:38:59.154 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:40:59.696 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:43:00.153 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:45:00.654 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:47:01.103 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:49:01.596 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:51:02.057 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:53:02.572 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:55:03.103 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:57:03.637 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:59:04.172 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:01:04.630 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:03:05.125 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:05:05.586 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:07:06.136 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:09:06.570 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:11:07.058 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:13:07.543 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:15:08.090 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:17:08.620 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:19:09.175 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:21:09.712 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:23:10.235 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:25:10.709 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:27:11.228 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:29:11.756 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:31:12.254 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:33:12.734 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:35:13.260 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-01-31 10:37:13.789 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: succeeded
2023-01-31 10:37:13.806 | DEBUG    | gptchem.tuner:tune:207 - Fine tuning completed. {'base_model': 'ada', 'batch_size': None, 'n_epochs': 8, 'learning_rate_multiplier': 0.02, 'run_name': None, 'wandb_sync': False, 'outdir': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_090048', 'train_filename': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_090048/train.jsonl', 'valid_filename': 'None', 'model_name': 'ada:ft-lsmoepfl-2023-01-31-09-35-13', 'ft_id': 'ft-ImkxzeKKyOTHF7ibQ3KAvMEX', 'date': '20230131_103713', 'train_file_id': 'file-ShUem5K8roxwDRRJA5mwnfEm', 'valid_file_id': None}
Uploaded file from /home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_090048/train.jsonl: file-ShUem5K8roxwDRRJA5mwnfEm
Ran train size 10 and got MAE 1.00472, GPR baseline 0.9922560019573307
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ -1e-05   │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │  0       │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.99998 │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛
Upload progress:   0%|          | 0.00/9.10k [00:00<?, ?it/s]Upload progress: 100%|██████████| 9.10k/9.10k [00:00<00:00, 6.81Mit/s]
2023-01-31 10:37:20.106 | DEBUG    | gptchem.tuner:tune:188 - Requested fine tuning. {
  "created_at": 1675157839,
  "events": [
    {
      "created_at": 1675157840,
      "level": "info",
      "message": "Created fine-tune: ft-kppCFXjayEYdatfvT6NBFyEV",
      "object": "fine-tune-event"
    }
  ],
  "fine_tuned_model": null,
  "hyperparams": {
    "batch_size": null,
    "learning_rate_multiplier": 0.02,
    "n_epochs": 8,
    "prompt_loss_weight": 0.01
  },
  "id": "ft-kppCFXjayEYdatfvT6NBFyEV",
  "model": "ada",
  "object": "fine-tune",
  "organization_id": "org-TFRJXw3PPQocOWbu71eI2t9U",
  "result_files": [],
  "status": "pending",
  "training_files": [
    {
      "bytes": 9102,
      "created_at": 1675157839,
      "filename": "/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_103718/train.jsonl",
      "id": "file-OEyg22jQbGzaBN9NtbiGdJU3",
      "object": "file",
      "purpose": "fine-tune",
      "status": "uploaded",
      "status_details": null
    }
  ],
  "updated_at": 1675157840,
  "validation_files": []
}
2023-01-31 10:37:20.276 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:39:20.817 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:41:21.281 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:43:21.791 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:45:22.305 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:47:22.772 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:49:23.309 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:51:23.859 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:53:24.315 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:55:24.840 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:57:25.401 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:59:25.964 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:01:26.482 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:03:27.040 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:05:27.544 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:07:28.034 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:09:28.583 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:11:29.036 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:13:29.480 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:15:29.930 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:17:30.409 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:19:30.968 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:21:31.396 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:23:31.923 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:25:32.443 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:27:32.925 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:29:33.435 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:31:33.992 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:33:34.462 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:35:34.992 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:37:35.472 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:39:36.034 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:41:36.539 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:43:37.055 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:45:37.553 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:47:38.097 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:49:38.612 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:51:39.079 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:53:39.583 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:55:40.088 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:57:40.553 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-01-31 11:59:41.006 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: succeeded
2023-01-31 11:59:41.007 | DEBUG    | gptchem.tuner:tune:207 - Fine tuning completed. {'base_model': 'ada', 'batch_size': None, 'n_epochs': 8, 'learning_rate_multiplier': 0.02, 'run_name': None, 'wandb_sync': False, 'outdir': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_103718', 'train_filename': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_103718/train.jsonl', 'valid_filename': 'None', 'model_name': 'ada:ft-lsmoepfl-2023-01-31-10-58-05', 'ft_id': 'ft-kppCFXjayEYdatfvT6NBFyEV', 'date': '20230131_115941', 'train_file_id': 'file-OEyg22jQbGzaBN9NtbiGdJU3', 'valid_file_id': None}
Uploaded file from /home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_103718/train.jsonl: file-OEyg22jQbGzaBN9NtbiGdJU3
Ran train size 50 and got MAE 1.11124, GPR baseline 1.0046781971868521
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ -0.10534 │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 41.4215  │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.16936 │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛
Upload progress:   0%|          | 0.00/18.7k [00:00<?, ?it/s]Upload progress: 100%|██████████| 18.7k/18.7k [00:00<00:00, 35.6Mit/s]
2023-01-31 11:59:47.454 | DEBUG    | gptchem.tuner:tune:188 - Requested fine tuning. {
  "created_at": 1675162787,
  "events": [
    {
      "created_at": 1675162787,
      "level": "info",
      "message": "Created fine-tune: ft-jqzPjU2GkqInvPviHpWhcYWv",
      "object": "fine-tune-event"
    }
  ],
  "fine_tuned_model": null,
  "hyperparams": {
    "batch_size": null,
    "learning_rate_multiplier": 0.02,
    "n_epochs": 8,
    "prompt_loss_weight": 0.01
  },
  "id": "ft-jqzPjU2GkqInvPviHpWhcYWv",
  "model": "ada",
  "object": "fine-tune",
  "organization_id": "org-TFRJXw3PPQocOWbu71eI2t9U",
  "result_files": [],
  "status": "pending",
  "training_files": [
    {
      "bytes": 18740,
      "created_at": 1675162787,
      "filename": "/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_115946/train.jsonl",
      "id": "file-IiTeqLITrpcwIxerriHRFf9H",
      "object": "file",
      "purpose": "fine-tune",
      "status": "uploaded",
      "status_details": null
    }
  ],
  "updated_at": 1675162787,
  "validation_files": []
}
2023-01-31 11:59:47.632 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:01:48.096 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:03:48.627 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:05:49.171 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:07:49.703 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:09:50.235 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:11:50.739 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:13:51.227 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:15:51.752 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:17:52.187 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:19:52.714 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:21:53.256 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:23:53.723 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:25:54.218 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:27:54.675 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:29:55.206 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:31:55.754 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:33:56.307 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:35:56.868 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:37:57.389 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:39:57.853 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:41:58.347 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:43:58.864 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:45:59.395 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:47:59.881 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:50:00.394 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:52:00.920 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:54:01.380 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:56:01.912 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:58:02.367 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:00:02.865 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:02:03.397 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:04:03.857 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:06:04.382 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:08:04.891 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:10:05.401 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:12:05.939 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:14:06.409 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:16:06.933 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:18:07.438 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:20:07.915 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:22:08.465 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:24:08.996 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:26:09.490 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:28:09.998 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:30:10.555 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:32:11.096 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:34:11.565 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:36:12.099 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:38:12.549 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:40:13.092 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:42:13.608 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:44:14.155 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:46:14.717 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:48:15.266 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:50:15.790 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:52:16.383 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:54:16.939 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:56:17.451 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:58:17.904 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:00:18.467 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:02:18.987 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:04:19.524 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:06:20.069 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:08:20.614 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:10:21.111 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:12:21.622 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:14:22.145 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:16:22.613 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:18:23.126 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:20:23.690 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:22:24.241 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:24:24.787 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:26:25.235 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:28:25.792 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:30:26.253 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:32:26.806 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:34:27.290 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:36:27.791 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:38:28.327 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:40:28.850 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:42:29.346 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:44:29.868 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:46:30.336 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:48:30.902 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:50:31.407 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:52:31.906 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:54:32.474 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-01-31 14:56:32.983 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: succeeded
2023-01-31 14:56:32.985 | DEBUG    | gptchem.tuner:tune:207 - Fine tuning completed. {'base_model': 'ada', 'batch_size': None, 'n_epochs': 8, 'learning_rate_multiplier': 0.02, 'run_name': None, 'wandb_sync': False, 'outdir': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_115946', 'train_filename': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_115946/train.jsonl', 'valid_filename': 'None', 'model_name': 'ada:ft-lsmoepfl-2023-01-31-13-55-16', 'ft_id': 'ft-jqzPjU2GkqInvPviHpWhcYWv', 'date': '20230131_145632', 'train_file_id': 'file-IiTeqLITrpcwIxerriHRFf9H', 'valid_file_id': None}
Uploaded file from /home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_115946/train.jsonl: file-IiTeqLITrpcwIxerriHRFf9H
Ran train size 100 and got MAE 0.9998800000000001, GPR baseline 0.7931916145829873
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ -1.86595 │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 35.4202  │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.21388 │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛
Upload progress:   0%|          | 0.00/37.9k [00:00<?, ?it/s]Upload progress: 100%|██████████| 37.9k/37.9k [00:00<00:00, 42.3Mit/s]
2023-01-31 14:56:40.138 | DEBUG    | gptchem.tuner:tune:188 - Requested fine tuning. {
  "created_at": 1675173400,
  "events": [
    {
      "created_at": 1675173400,
      "level": "info",
      "message": "Created fine-tune: ft-wU5N2ty7QlxAFvQuAKjJMgXS",
      "object": "fine-tune-event"
    }
  ],
  "fine_tuned_model": null,
  "hyperparams": {
    "batch_size": null,
    "learning_rate_multiplier": 0.02,
    "n_epochs": 8,
    "prompt_loss_weight": 0.01
  },
  "id": "ft-wU5N2ty7QlxAFvQuAKjJMgXS",
  "model": "ada",
  "object": "fine-tune",
  "organization_id": "org-TFRJXw3PPQocOWbu71eI2t9U",
  "result_files": [],
  "status": "pending",
  "training_files": [
    {
      "bytes": 37930,
      "created_at": 1675173399,
      "filename": "/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_145638/train.jsonl",
      "id": "file-C7P3q6OrvaSTNmwO2RFC5nZx",
      "object": "file",
      "purpose": "fine-tune",
      "status": "uploaded",
      "status_details": null
    }
  ],
  "updated_at": 1675173400,
  "validation_files": []
}
2023-01-31 14:56:40.319 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:58:40.866 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:00:41.401 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:02:41.865 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:04:42.400 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:06:42.876 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-01-31 15:08:43.340 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-01-31 15:10:43.832 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: succeeded
2023-01-31 15:10:43.833 | DEBUG    | gptchem.tuner:tune:207 - Fine tuning completed. {'base_model': 'ada', 'batch_size': None, 'n_epochs': 8, 'learning_rate_multiplier': 0.02, 'run_name': None, 'wandb_sync': False, 'outdir': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_145638', 'train_filename': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_145638/train.jsonl', 'valid_filename': 'None', 'model_name': 'ada:ft-lsmoepfl-2023-01-31-14-09-21', 'ft_id': 'ft-wU5N2ty7QlxAFvQuAKjJMgXS', 'date': '20230131_151043', 'train_file_id': 'file-C7P3q6OrvaSTNmwO2RFC5nZx', 'valid_file_id': None}
Uploaded file from /home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_145638/train.jsonl: file-C7P3q6OrvaSTNmwO2RFC5nZx
Ran train size 200 and got MAE 1.1602, GPR baseline 0.7593885353208226
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ -2.33066 │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 49.3405  │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.08734 │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛
Upload progress:   0%|          | 0.00/94.3k [00:00<?, ?it/s]Upload progress: 100%|██████████| 94.3k/94.3k [00:00<00:00, 175Mit/s]
2023-01-31 15:10:52.342 | DEBUG    | gptchem.tuner:tune:188 - Requested fine tuning. {
  "created_at": 1675174252,
  "events": [
    {
      "created_at": 1675174252,
      "level": "info",
      "message": "Created fine-tune: ft-CL6rRihVpgqDoeX6DI6cfxAb",
      "object": "fine-tune-event"
    }
  ],
  "fine_tuned_model": null,
  "hyperparams": {
    "batch_size": null,
    "learning_rate_multiplier": 0.02,
    "n_epochs": 8,
    "prompt_loss_weight": 0.01
  },
  "id": "ft-CL6rRihVpgqDoeX6DI6cfxAb",
  "model": "ada",
  "object": "fine-tune",
  "organization_id": "org-TFRJXw3PPQocOWbu71eI2t9U",
  "result_files": [],
  "status": "pending",
  "training_files": [
    {
      "bytes": 94262,
      "created_at": 1675174252,
      "filename": "/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_151050/train.jsonl",
      "id": "file-tcHrAvzQSvlNGzscD8toDivp",
      "object": "file",
      "purpose": "fine-tune",
      "status": "uploaded",
      "status_details": null
    }
  ],
  "updated_at": 1675174252,
  "validation_files": []
}
2023-01-31 15:10:52.519 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:12:53.037 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:14:53.561 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:16:54.085 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:18:54.624 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:20:55.141 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:22:55.640 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-01-31 15:24:56.168 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-01-31 15:26:56.708 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-01-31 15:28:57.269 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-01-31 15:30:57.801 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-01-31 15:32:58.371 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: succeeded
2023-01-31 15:32:58.372 | DEBUG    | gptchem.tuner:tune:207 - Fine tuning completed. {'base_model': 'ada', 'batch_size': None, 'n_epochs': 8, 'learning_rate_multiplier': 0.02, 'run_name': None, 'wandb_sync': False, 'outdir': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_151050', 'train_filename': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_151050/train.jsonl', 'valid_filename': 'None', 'model_name': 'ada:ft-lsmoepfl-2023-01-31-14-32-38', 'ft_id': 'ft-CL6rRihVpgqDoeX6DI6cfxAb', 'date': '20230131_153258', 'train_file_id': 'file-tcHrAvzQSvlNGzscD8toDivp', 'valid_file_id': None}
Uploaded file from /home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_151050/train.jsonl: file-tcHrAvzQSvlNGzscD8toDivp
Ran train size 500 and got MAE 0.8384799999999999, GPR baseline 0.6375235739715878
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤═════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │   value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪═════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │       0 │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │       0 │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │       1 │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧═════════╛
Upload progress:   0%|          | 0.00/3.61k [00:00<?, ?it/s]Upload progress: 100%|██████████| 3.61k/3.61k [00:00<00:00, 6.30Mit/s]
2023-01-31 15:33:05.518 | DEBUG    | gptchem.tuner:tune:188 - Requested fine tuning. {
  "created_at": 1675175585,
  "events": [
    {
      "created_at": 1675175585,
      "level": "info",
      "message": "Created fine-tune: ft-OyrWjPqwq6wAsIpcVbQL0sR0",
      "object": "fine-tune-event"
    }
  ],
  "fine_tuned_model": null,
  "hyperparams": {
    "batch_size": null,
    "learning_rate_multiplier": 0.02,
    "n_epochs": 8,
    "prompt_loss_weight": 0.01
  },
  "id": "ft-OyrWjPqwq6wAsIpcVbQL0sR0",
  "model": "ada",
  "object": "fine-tune",
  "organization_id": "org-TFRJXw3PPQocOWbu71eI2t9U",
  "result_files": [],
  "status": "pending",
  "training_files": [
    {
      "bytes": 3610,
      "created_at": 1675175585,
      "filename": "/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_153304/train.jsonl",
      "id": "file-HxKwM3zuKl77LdOwFejLtBDs",
      "object": "file",
      "purpose": "fine-tune",
      "status": "uploaded",
      "status_details": null
    }
  ],
  "updated_at": 1675175585,
  "validation_files": []
}
2023-01-31 15:33:05.703 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:35:06.239 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:37:06.791 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:39:07.299 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:41:07.808 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:43:08.272 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:45:08.840 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:47:09.382 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:49:09.916 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:51:10.433 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:53:10.960 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:55:11.489 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:57:12.002 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:59:12.525 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:01:13.092 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:03:13.599 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:05:14.137 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:07:14.591 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:09:15.070 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:11:15.609 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:13:16.120 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:15:16.634 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:17:17.154 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:19:17.701 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: succeeded
2023-01-31 16:19:17.702 | DEBUG    | gptchem.tuner:tune:207 - Fine tuning completed. {'base_model': 'ada', 'batch_size': None, 'n_epochs': 8, 'learning_rate_multiplier': 0.02, 'run_name': None, 'wandb_sync': False, 'outdir': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_153304', 'train_filename': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_153304/train.jsonl', 'valid_filename': 'None', 'model_name': 'ada:ft-lsmoepfl-2023-01-31-15-18-32', 'ft_id': 'ft-OyrWjPqwq6wAsIpcVbQL0sR0', 'date': '20230131_161917', 'train_file_id': 'file-HxKwM3zuKl77LdOwFejLtBDs', 'valid_file_id': None}
Uploaded file from /home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_153304/train.jsonl: file-HxKwM3zuKl77LdOwFejLtBDs
Ran train size 10 and got MAE nan, GPR baseline 0.9922560019573307
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ -1e-05   │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │  0       │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.99998 │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛
Upload progress:   0%|          | 0.00/17.7k [00:00<?, ?it/s]Upload progress: 100%|██████████| 17.7k/17.7k [00:00<00:00, 34.8Mit/s]
2023-01-31 16:19:26.260 | DEBUG    | gptchem.tuner:tune:188 - Requested fine tuning. {
  "created_at": 1675178366,
  "events": [
    {
      "created_at": 1675178366,
      "level": "info",
      "message": "Created fine-tune: ft-cpzCTt5gPrEwdMbqXd9edjel",
      "object": "fine-tune-event"
    }
  ],
  "fine_tuned_model": null,
  "hyperparams": {
    "batch_size": null,
    "learning_rate_multiplier": 0.02,
    "n_epochs": 8,
    "prompt_loss_weight": 0.01
  },
  "id": "ft-cpzCTt5gPrEwdMbqXd9edjel",
  "model": "ada",
  "object": "fine-tune",
  "organization_id": "org-TFRJXw3PPQocOWbu71eI2t9U",
  "result_files": [],
  "status": "pending",
  "training_files": [
    {
      "bytes": 17672,
      "created_at": 1675178365,
      "filename": "/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_161924/train.jsonl",
      "id": "file-8GPzgiVzULRbj2azAO5cnMrQ",
      "object": "file",
      "purpose": "fine-tune",
      "status": "uploaded",
      "status_details": null
    }
  ],
  "updated_at": 1675178366,
  "validation_files": []
}
2023-01-31 16:19:26.436 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:21:26.983 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:23:27.508 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:25:28.066 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:27:28.584 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:29:29.110 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:31:29.602 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:33:30.147 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:35:30.693 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:37:31.218 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:39:31.778 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:41:32.281 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:43:32.828 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:45:33.359 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:47:33.833 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:49:34.367 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:51:34.899 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:53:35.391 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:55:35.916 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:57:36.402 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:59:36.956 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:01:37.491 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:03:37.970 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:05:38.516 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:07:39.020 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:09:39.566 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:11:40.103 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:13:40.617 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:15:41.149 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:17:41.682 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:19:42.276 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:21:42.840 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:23:43.393 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:25:43.980 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:27:44.436 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:29:44.957 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:31:45.484 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:33:46.000 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:35:46.527 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:37:47.073 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:39:47.592 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:41:48.029 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:43:48.557 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:45:49.101 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:47:49.662 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:49:50.193 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:51:50.641 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:53:51.125 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:56:03.283 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:58:03.821 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 18:00:04.366 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 18:02:04.906 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-01-31 18:04:05.459 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-01-31 18:06:05.924 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: succeeded
2023-01-31 18:06:05.924 | DEBUG    | gptchem.tuner:tune:207 - Fine tuning completed. {'base_model': 'ada', 'batch_size': None, 'n_epochs': 8, 'learning_rate_multiplier': 0.02, 'run_name': None, 'wandb_sync': False, 'outdir': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_161924', 'train_filename': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_161924/train.jsonl', 'valid_filename': 'None', 'model_name': 'ada:ft-lsmoepfl-2023-01-31-17-04-07', 'ft_id': 'ft-cpzCTt5gPrEwdMbqXd9edjel', 'date': '20230131_180605', 'train_file_id': 'file-8GPzgiVzULRbj2azAO5cnMrQ', 'valid_file_id': None}
Uploaded file from /home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_161924/train.jsonl: file-8GPzgiVzULRbj2azAO5cnMrQ
Traceback (most recent call last):
  File "/home/kevin/anaconda3/envs/gptchem/lib/python3.9/site-packages/urllib3/connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/home/kevin/anaconda3/envs/gptchem/lib/python3.9/site-packages/urllib3/connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "/home/kevin/anaconda3/envs/gptchem/lib/python3.9/http/client.py", line 1377, in getresponse
    response.begin()
  File "/home/kevin/anaconda3/envs/gptchem/lib/python3.9/http/client.py", line 320, in begin
    version, status, reason = self._read_status()
  File "/home/kevin/anaconda3/envs/gptchem/lib/python3.9/http/client.py", line 281, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/home/kevin/anaconda3/envs/gptchem/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/kevin/anaconda3/envs/gptchem/lib/python3.9/ssl.py", line 1241, in recv_into
    return self.read(nbytes, buffer)
  File "/home/kevin/anaconda3/envs/gptchem/lib/python3.9/ssl.py", line 1099, in read
    return self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/kevin/anaconda3/envs/gptchem/lib/python3.9/site-packages/requests/adapters.py", line 489, in send
    resp = conn.urlopen(
  File "/home/kevin/anaconda3/envs/gptchem/lib/python3.9/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "/home/kevin/anaconda3/envs/gptchem/lib/python3.9/site-packages/urllib3/util/retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/kevin/anaconda3/envs/gptchem/lib/python3.9/site-packages/urllib3/packages/six.py", line 770, in reraise
    raise value
  File "/home/kevin/anaconda3/envs/gptchem/lib/python3.9/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/home/kevin/anaconda3/envs/gptchem/lib/python3.9/site-packages/urllib3/connectionpool.py", line 451, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "/home/kevin/anaconda3/envs/gptchem/lib/python3.9/site-packages/urllib3/connectionpool.py", line 340, in _raise_timeout
    raise ReadTimeoutError(
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/kevin/anaconda3/envs/gptchem/lib/python3.9/site-packages/openai/api_requestor.py", line 517, in request_raw
    result = _thread_context.session.request(
  File "/home/kevin/anaconda3/envs/gptchem/lib/python3.9/site-packages/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/kevin/anaconda3/envs/gptchem/lib/python3.9/site-packages/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/home/kevin/anaconda3/envs/gptchem/lib/python3.9/site-packages/requests/adapters.py", line 578, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/run_experiments.py", line 81, in <module>
    train_test_model(representation, num_train_points, seed + 3546)
  File "/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/run_experiments.py", line 57, in train_test_model
    completions = querier(test_formatted)
  File "/home/kevin/Documents/gptchem/src/gptchem/querier.py", line 123, in __call__
    return self.query(df, temperature, logprobs)
  File "/home/kevin/Documents/gptchem/src/gptchem/querier.py", line 98, in query
    completions_ = openai.Completion.create(
  File "/home/kevin/anaconda3/envs/gptchem/lib/python3.9/site-packages/openai/api_resources/completion.py", line 25, in create
    return super().create(*args, **kwargs)
  File "/home/kevin/anaconda3/envs/gptchem/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py", line 153, in create
    response, _, api_key = requestor.request(
  File "/home/kevin/anaconda3/envs/gptchem/lib/python3.9/site-packages/openai/api_requestor.py", line 217, in request
    result = self.request_raw(
  File "/home/kevin/anaconda3/envs/gptchem/lib/python3.9/site-packages/openai/api_requestor.py", line 527, in request_raw
    raise error.Timeout("Request timed out: {}".format(e)) from e
openai.error.Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Uploaded file from /home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_083424/train.jsonl: file-ZdD1LpV01ocnim9opdd6WVKD
Ran train size 200 and got MAE 1.10824, GPR baseline 0.7593885353208226
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ -2.33066 │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 49.3405  │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.08734 │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛
Upload progress:   0%|          | 0.00/124k [00:00<?, ?it/s]Upload progress: 100%|██████████| 124k/124k [00:00<00:00, 150Mit/s]
2023-01-31 09:00:43.087 | DEBUG    | gptchem.tuner:tune:188 - Requested fine tuning. {
  "created_at": 1675152042,
  "events": [
    {
      "created_at": 1675152042,
      "level": "info",
      "message": "Created fine-tune: ft-lsufAeX21Eo3zE2Nga36D3zv",
      "object": "fine-tune-event"
    }
  ],
  "fine_tuned_model": null,
  "hyperparams": {
    "batch_size": null,
    "learning_rate_multiplier": 0.02,
    "n_epochs": 8,
    "prompt_loss_weight": 0.01
  },
  "id": "ft-lsufAeX21Eo3zE2Nga36D3zv",
  "model": "ada",
  "object": "fine-tune",
  "organization_id": "org-TFRJXw3PPQocOWbu71eI2t9U",
  "result_files": [],
  "status": "pending",
  "training_files": [
    {
      "bytes": 124488,
      "created_at": 1675152042,
      "filename": "/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_090041/train.jsonl",
      "id": "file-q8Kjp8DF4PL16HA30vlUaDpI",
      "object": "file",
      "purpose": "fine-tune",
      "status": "uploaded",
      "status_details": null
    }
  ],
  "updated_at": 1675152042,
  "validation_files": []
}
2023-01-31 09:00:43.259 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:02:43.796 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:04:44.333 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:06:44.905 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:08:45.409 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:10:45.938 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:12:46.460 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:14:46.950 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:16:47.481 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:18:47.946 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:20:48.464 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:22:48.990 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:24:49.525 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:26:50.029 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:28:50.523 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:30:51.005 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:32:51.473 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:34:51.972 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:36:52.526 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:38:53.053 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:40:53.592 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:42:54.038 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:44:54.572 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:46:55.117 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:48:55.558 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:50:56.096 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:52:56.552 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:54:57.074 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:56:57.626 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 09:58:58.151 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:00:58.676 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:02:59.218 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:04:59.763 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:07:00.214 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:09:00.743 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:11:01.282 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:13:01.815 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:15:02.284 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:17:02.819 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:19:03.365 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:21:03.830 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:23:04.388 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:25:04.863 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-01-31 10:27:05.406 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-01-31 10:29:05.904 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-01-31 10:31:06.431 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-01-31 10:33:06.994 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-01-31 10:35:07.549 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: succeeded
2023-01-31 10:35:07.561 | DEBUG    | gptchem.tuner:tune:207 - Fine tuning completed. {'base_model': 'ada', 'batch_size': None, 'n_epochs': 8, 'learning_rate_multiplier': 0.02, 'run_name': None, 'wandb_sync': False, 'outdir': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_090041', 'train_filename': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_090041/train.jsonl', 'valid_filename': 'None', 'model_name': 'ada:ft-lsmoepfl-2023-01-31-09-33-54', 'ft_id': 'ft-lsufAeX21Eo3zE2Nga36D3zv', 'date': '20230131_103507', 'train_file_id': 'file-q8Kjp8DF4PL16HA30vlUaDpI', 'valid_file_id': None}
Uploaded file from /home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_090041/train.jsonl: file-q8Kjp8DF4PL16HA30vlUaDpI
Ran train size 500 and got MAE 0.9027200000000001, GPR baseline 0.6375235739715878
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤═════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │   value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪═════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │      -0 │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │       0 │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │       1 │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧═════════╛
Upload progress:   0%|          | 0.00/1.90k [00:00<?, ?it/s]Upload progress: 100%|██████████| 1.90k/1.90k [00:00<00:00, 3.47Mit/s]
2023-01-31 10:35:14.386 | DEBUG    | gptchem.tuner:tune:188 - Requested fine tuning. {
  "created_at": 1675157714,
  "events": [
    {
      "created_at": 1675157714,
      "level": "info",
      "message": "Created fine-tune: ft-yTNvsyoO6j43QYRKTNs250h0",
      "object": "fine-tune-event"
    }
  ],
  "fine_tuned_model": null,
  "hyperparams": {
    "batch_size": null,
    "learning_rate_multiplier": 0.02,
    "n_epochs": 8,
    "prompt_loss_weight": 0.01
  },
  "id": "ft-yTNvsyoO6j43QYRKTNs250h0",
  "model": "ada",
  "object": "fine-tune",
  "organization_id": "org-TFRJXw3PPQocOWbu71eI2t9U",
  "result_files": [],
  "status": "pending",
  "training_files": [
    {
      "bytes": 1900,
      "created_at": 1675157713,
      "filename": "/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_103512/train.jsonl",
      "id": "file-Ld9MlUuJBgGu3cTYFDzVshkq",
      "object": "file",
      "purpose": "fine-tune",
      "status": "uploaded",
      "status_details": null
    }
  ],
  "updated_at": 1675157714,
  "validation_files": []
}
2023-01-31 10:35:14.566 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:37:15.058 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:39:15.622 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:41:16.083 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:43:16.617 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:45:17.070 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:47:17.636 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:49:18.119 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:51:18.688 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:53:19.217 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:55:19.701 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:57:20.234 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 10:59:20.756 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:01:21.275 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:03:21.743 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:05:22.241 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:07:22.773 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:09:23.273 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:11:23.816 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:13:24.336 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:15:24.857 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:17:25.370 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:19:25.854 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:21:26.374 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:23:26.816 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:25:27.352 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:27:27.823 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:29:28.267 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:31:28.755 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:33:29.224 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:35:29.772 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:37:30.304 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:39:30.869 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:41:31.319 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:43:31.840 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:45:32.401 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:47:32.926 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:49:33.451 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:51:33.948 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:53:34.399 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:55:34.932 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-01-31 11:57:35.400 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: succeeded
2023-01-31 11:57:35.401 | DEBUG    | gptchem.tuner:tune:207 - Fine tuning completed. {'base_model': 'ada', 'batch_size': None, 'n_epochs': 8, 'learning_rate_multiplier': 0.02, 'run_name': None, 'wandb_sync': False, 'outdir': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_103512', 'train_filename': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_103512/train.jsonl', 'valid_filename': 'None', 'model_name': 'ada:ft-lsmoepfl-2023-01-31-10-56-11', 'ft_id': 'ft-yTNvsyoO6j43QYRKTNs250h0', 'date': '20230131_115735', 'train_file_id': 'file-Ld9MlUuJBgGu3cTYFDzVshkq', 'valid_file_id': None}
Uploaded file from /home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_103512/train.jsonl: file-Ld9MlUuJBgGu3cTYFDzVshkq
Ran train size 10 and got MAE 1.0776, GPR baseline 1.0124319576424698
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤═════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │   value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪═════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ 0       │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 0       │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │ 0.99998 │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧═════════╛
Upload progress:   0%|          | 0.00/9.58k [00:00<?, ?it/s]Upload progress: 100%|██████████| 9.58k/9.58k [00:00<00:00, 19.0Mit/s]
2023-01-31 11:57:41.619 | DEBUG    | gptchem.tuner:tune:188 - Requested fine tuning. {
  "created_at": 1675162661,
  "events": [
    {
      "created_at": 1675162661,
      "level": "info",
      "message": "Created fine-tune: ft-nAUUaz6fcT1KvXdtvteqaVbm",
      "object": "fine-tune-event"
    }
  ],
  "fine_tuned_model": null,
  "hyperparams": {
    "batch_size": null,
    "learning_rate_multiplier": 0.02,
    "n_epochs": 8,
    "prompt_loss_weight": 0.01
  },
  "id": "ft-nAUUaz6fcT1KvXdtvteqaVbm",
  "model": "ada",
  "object": "fine-tune",
  "organization_id": "org-TFRJXw3PPQocOWbu71eI2t9U",
  "result_files": [],
  "status": "pending",
  "training_files": [
    {
      "bytes": 9582,
      "created_at": 1675162661,
      "filename": "/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_115740/train.jsonl",
      "id": "file-T5FdrLEAynYKFFHpGPDnjsVP",
      "object": "file",
      "purpose": "fine-tune",
      "status": "uploaded",
      "status_details": null
    }
  ],
  "updated_at": 1675162661,
  "validation_files": []
}
2023-01-31 11:57:41.800 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 11:59:42.245 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:01:42.801 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:03:43.300 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:05:43.847 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:07:44.341 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:09:44.880 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:11:45.418 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:13:45.861 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:15:46.391 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:17:46.968 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:19:47.503 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:21:48.021 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:23:48.545 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:25:49.019 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:27:49.552 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:29:50.073 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:31:50.570 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:33:51.103 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:35:51.660 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:37:52.098 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:39:52.623 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:41:53.151 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:43:53.667 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:45:54.197 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:47:54.698 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:49:55.151 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:51:55.621 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:53:56.102 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:55:56.609 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:57:57.139 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 12:59:57.662 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:01:58.189 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:03:58.706 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:05:59.261 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:07:59.814 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:10:00.351 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:12:00.891 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:14:01.433 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:16:01.980 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:18:02.500 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:20:02.991 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:22:03.563 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:24:04.112 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:26:04.676 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:28:05.235 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:30:05.681 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:32:06.239 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:34:06.698 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:36:07.214 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:38:07.786 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:40:08.342 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:42:08.840 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:44:09.405 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:46:09.946 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:48:10.493 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:50:11.087 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:52:11.605 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:54:12.063 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:56:12.606 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 13:58:13.137 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:00:13.675 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:02:14.179 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:04:14.712 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:06:15.235 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:08:15.775 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:10:16.216 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:12:16.718 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:14:17.278 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:16:17.788 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:18:18.329 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:20:18.856 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:22:19.398 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:24:19.861 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:26:20.356 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:28:20.831 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:30:21.386 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:32:21.871 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:34:22.410 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:36:22.954 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:38:23.460 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:40:24.024 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:42:24.593 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:44:25.115 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:46:25.574 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:48:26.105 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:50:26.596 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:52:27.151 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: succeeded
2023-01-31 14:52:27.152 | DEBUG    | gptchem.tuner:tune:207 - Fine tuning completed. {'base_model': 'ada', 'batch_size': None, 'n_epochs': 8, 'learning_rate_multiplier': 0.02, 'run_name': None, 'wandb_sync': False, 'outdir': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_115740', 'train_filename': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_115740/train.jsonl', 'valid_filename': 'None', 'model_name': 'ada:ft-lsmoepfl-2023-01-31-13-52-00', 'ft_id': 'ft-nAUUaz6fcT1KvXdtvteqaVbm', 'date': '20230131_145227', 'train_file_id': 'file-T5FdrLEAynYKFFHpGPDnjsVP', 'valid_file_id': None}
Uploaded file from /home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_115740/train.jsonl: file-T5FdrLEAynYKFFHpGPDnjsVP
Ran train size 50 and got MAE 1.0104, GPR baseline 1.0207471837741522
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │  0.11486 │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 29.6061  │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.35857 │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛
Upload progress:   0%|          | 0.00/18.9k [00:00<?, ?it/s]Upload progress: 100%|██████████| 18.9k/18.9k [00:00<00:00, 20.1Mit/s]
2023-01-31 14:52:34.437 | DEBUG    | gptchem.tuner:tune:188 - Requested fine tuning. {
  "created_at": 1675173154,
  "events": [
    {
      "created_at": 1675173154,
      "level": "info",
      "message": "Created fine-tune: ft-NbQ3erZ5Ysdk3o4YS8vrwC8g",
      "object": "fine-tune-event"
    }
  ],
  "fine_tuned_model": null,
  "hyperparams": {
    "batch_size": null,
    "learning_rate_multiplier": 0.02,
    "n_epochs": 8,
    "prompt_loss_weight": 0.01
  },
  "id": "ft-NbQ3erZ5Ysdk3o4YS8vrwC8g",
  "model": "ada",
  "object": "fine-tune",
  "organization_id": "org-TFRJXw3PPQocOWbu71eI2t9U",
  "result_files": [],
  "status": "pending",
  "training_files": [
    {
      "bytes": 18932,
      "created_at": 1675173154,
      "filename": "/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_145233/train.jsonl",
      "id": "file-N5szk8FJTARW5ZKn2oHLcaRk",
      "object": "file",
      "purpose": "fine-tune",
      "status": "uploaded",
      "status_details": null
    }
  ],
  "updated_at": 1675173154,
  "validation_files": []
}
2023-01-31 14:52:34.617 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:54:35.093 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:56:35.624 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 14:58:36.152 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:00:36.699 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:02:37.158 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:04:37.674 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-01-31 15:06:38.169 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: succeeded
2023-01-31 15:06:38.169 | DEBUG    | gptchem.tuner:tune:207 - Fine tuning completed. {'base_model': 'ada', 'batch_size': None, 'n_epochs': 8, 'learning_rate_multiplier': 0.02, 'run_name': None, 'wandb_sync': False, 'outdir': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_145233', 'train_filename': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_145233/train.jsonl', 'valid_filename': 'None', 'model_name': 'ada:ft-lsmoepfl-2023-01-31-14-05-03', 'ft_id': 'ft-NbQ3erZ5Ysdk3o4YS8vrwC8g', 'date': '20230131_150638', 'train_file_id': 'file-N5szk8FJTARW5ZKn2oHLcaRk', 'valid_file_id': None}
Uploaded file from /home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_145233/train.jsonl: file-N5szk8FJTARW5ZKn2oHLcaRk
Ran train size 100 and got MAE 1.05056, GPR baseline 0.7992783406423993
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │  0.20386 │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 51.0142  │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0       │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛
Upload progress:   0%|          | 0.00/37.5k [00:00<?, ?it/s]Upload progress: 100%|██████████| 37.5k/37.5k [00:00<00:00, 60.3Mit/s]
2023-01-31 15:06:44.966 | DEBUG    | gptchem.tuner:tune:188 - Requested fine tuning. {
  "created_at": 1675174004,
  "events": [
    {
      "created_at": 1675174004,
      "level": "info",
      "message": "Created fine-tune: ft-MUvARC37xkQMzzpHQnJWGKmb",
      "object": "fine-tune-event"
    }
  ],
  "fine_tuned_model": null,
  "hyperparams": {
    "batch_size": null,
    "learning_rate_multiplier": 0.02,
    "n_epochs": 8,
    "prompt_loss_weight": 0.01
  },
  "id": "ft-MUvARC37xkQMzzpHQnJWGKmb",
  "model": "ada",
  "object": "fine-tune",
  "organization_id": "org-TFRJXw3PPQocOWbu71eI2t9U",
  "result_files": [],
  "status": "pending",
  "training_files": [
    {
      "bytes": 37532,
      "created_at": 1675174004,
      "filename": "/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_150643/train.jsonl",
      "id": "file-Lt6vvZFOQdeqQ8KiK5NppdBU",
      "object": "file",
      "purpose": "fine-tune",
      "status": "uploaded",
      "status_details": null
    }
  ],
  "updated_at": 1675174004,
  "validation_files": []
}
2023-01-31 15:06:45.142 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:08:45.647 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:10:46.164 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:12:46.725 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:14:47.247 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:16:47.780 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:18:48.344 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:20:48.862 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:22:49.381 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:24:49.847 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:26:50.397 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:28:50.960 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:30:51.500 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:32:52.032 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:34:52.583 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:36:53.124 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:38:53.653 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:40:54.134 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:42:54.654 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:44:55.170 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:46:55.732 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:48:56.219 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:50:56.743 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:52:57.173 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:54:57.694 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:56:58.188 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 15:58:58.702 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:00:59.247 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:02:59.767 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:05:00.313 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:07:00.800 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-01-31 16:09:01.246 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-01-31 16:11:01.783 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: succeeded
2023-01-31 16:11:01.783 | DEBUG    | gptchem.tuner:tune:207 - Fine tuning completed. {'base_model': 'ada', 'batch_size': None, 'n_epochs': 8, 'learning_rate_multiplier': 0.02, 'run_name': None, 'wandb_sync': False, 'outdir': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_150643', 'train_filename': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_150643/train.jsonl', 'valid_filename': 'None', 'model_name': 'ada:ft-lsmoepfl-2023-01-31-15-09-47', 'ft_id': 'ft-MUvARC37xkQMzzpHQnJWGKmb', 'date': '20230131_161101', 'train_file_id': 'file-Lt6vvZFOQdeqQ8KiK5NppdBU', 'valid_file_id': None}
Uploaded file from /home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_150643/train.jsonl: file-Lt6vvZFOQdeqQ8KiK5NppdBU
Ran train size 200 and got MAE 0.9075599999999999, GPR baseline 0.6679462123395089
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ -1.4658  │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 50.0305  │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.04625 │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛
Upload progress:   0%|          | 0.00/94.9k [00:00<?, ?it/s]Upload progress: 100%|██████████| 94.9k/94.9k [00:00<00:00, 166Mit/s]
2023-01-31 16:11:11.163 | DEBUG    | gptchem.tuner:tune:188 - Requested fine tuning. {
  "created_at": 1675177871,
  "events": [
    {
      "created_at": 1675177871,
      "level": "info",
      "message": "Created fine-tune: ft-KiazozexlabYjMHVmCyHgblZ",
      "object": "fine-tune-event"
    }
  ],
  "fine_tuned_model": null,
  "hyperparams": {
    "batch_size": null,
    "learning_rate_multiplier": 0.02,
    "n_epochs": 8,
    "prompt_loss_weight": 0.01
  },
  "id": "ft-KiazozexlabYjMHVmCyHgblZ",
  "model": "ada",
  "object": "fine-tune",
  "organization_id": "org-TFRJXw3PPQocOWbu71eI2t9U",
  "result_files": [],
  "status": "pending",
  "training_files": [
    {
      "bytes": 94906,
      "created_at": 1675177870,
      "filename": "/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_161109/train.jsonl",
      "id": "file-LbvcFIWaDLkRGWECa9qIb9YM",
      "object": "file",
      "purpose": "fine-tune",
      "status": "uploaded",
      "status_details": null
    }
  ],
  "updated_at": 1675177871,
  "validation_files": []
}
2023-01-31 16:11:11.333 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:13:11.789 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:15:12.229 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:17:12.758 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:19:13.214 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:21:13.739 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:23:14.281 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:25:14.790 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:27:15.325 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:29:15.855 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:31:16.406 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:33:16.958 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:35:17.393 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:37:17.880 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:39:18.418 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:41:18.960 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:43:19.474 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:45:19.996 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:47:20.531 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:49:20.993 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:51:21.521 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:53:22.050 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:55:22.595 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:57:23.134 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 16:59:23.575 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:01:24.109 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:03:24.630 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:05:25.091 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:07:25.609 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:09:26.102 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:11:26.665 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:13:27.176 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:15:27.718 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:17:28.203 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:19:28.729 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:21:29.277 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:23:29.808 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-01-31 17:25:30.313 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-01-31 17:27:30.860 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-01-31 17:29:31.422 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-01-31 17:31:31.976 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-01-31 17:33:32.472 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: succeeded
2023-01-31 17:33:32.472 | DEBUG    | gptchem.tuner:tune:207 - Fine tuning completed. {'base_model': 'ada', 'batch_size': None, 'n_epochs': 8, 'learning_rate_multiplier': 0.02, 'run_name': None, 'wandb_sync': False, 'outdir': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_161109', 'train_filename': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_161109/train.jsonl', 'valid_filename': 'None', 'model_name': 'ada:ft-lsmoepfl-2023-01-31-16-31-40', 'ft_id': 'ft-KiazozexlabYjMHVmCyHgblZ', 'date': '20230131_173332', 'train_file_id': 'file-LbvcFIWaDLkRGWECa9qIb9YM', 'valid_file_id': None}
Uploaded file from /home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_161109/train.jsonl: file-LbvcFIWaDLkRGWECa9qIb9YM
Ran train size 500 and got MAE 0.9558399999999999, GPR baseline 0.6248221601360314
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤═════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │   value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪═════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │      -0 │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │       0 │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │       1 │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧═════════╛
Upload progress:   0%|          | 0.00/3.85k [00:00<?, ?it/s]Upload progress: 100%|██████████| 3.85k/3.85k [00:00<00:00, 6.56Mit/s]
2023-01-31 17:33:39.157 | DEBUG    | gptchem.tuner:tune:188 - Requested fine tuning. {
  "created_at": 1675182819,
  "events": [
    {
      "created_at": 1675182819,
      "level": "info",
      "message": "Created fine-tune: ft-7Fx28s63ncnIifvom162BBmb",
      "object": "fine-tune-event"
    }
  ],
  "fine_tuned_model": null,
  "hyperparams": {
    "batch_size": null,
    "learning_rate_multiplier": 0.02,
    "n_epochs": 8,
    "prompt_loss_weight": 0.01
  },
  "id": "ft-7Fx28s63ncnIifvom162BBmb",
  "model": "ada",
  "object": "fine-tune",
  "organization_id": "org-TFRJXw3PPQocOWbu71eI2t9U",
  "result_files": [],
  "status": "pending",
  "training_files": [
    {
      "bytes": 3848,
      "created_at": 1675182818,
      "filename": "/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_173337/train.jsonl",
      "id": "file-EuVmnWkxrlAvqsZfrbyAFqvh",
      "object": "file",
      "purpose": "fine-tune",
      "status": "uploaded",
      "status_details": null
    }
  ],
  "updated_at": 1675182819,
  "validation_files": []
}
2023-01-31 17:33:39.333 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:35:39.907 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:37:40.457 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:39:41.002 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:41:41.546 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:43:42.086 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:45:42.631 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:47:43.164 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:49:43.635 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:51:44.165 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:53:44.692 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:55:56.773 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:57:57.278 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 17:59:57.803 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 18:01:58.285 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 18:03:58.819 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 18:05:59.350 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 18:07:59.829 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 18:10:00.358 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 18:12:00.838 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 18:14:01.342 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 18:16:01.892 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 18:18:02.338 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 18:20:02.844 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 18:22:03.378 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 18:24:03.909 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 18:26:04.363 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 18:28:04.867 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 18:30:05.323 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 18:32:05.876 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 18:34:06.416 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 18:36:06.973 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 18:38:07.528 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 18:40:08.058 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 18:42:08.548 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 18:44:09.083 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 18:46:09.606 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 18:48:10.149 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 18:50:10.678 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 18:52:11.204 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 18:54:11.763 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 18:56:12.317 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 18:58:12.852 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 19:00:13.337 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 19:02:13.821 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 19:04:14.273 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 19:06:14.761 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 19:08:15.318 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 19:10:15.781 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 19:12:16.301 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 19:14:16.850 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 19:16:17.329 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 19:18:17.898 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 19:20:18.457 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 19:22:19.014 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 19:24:19.571 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 19:26:20.093 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 19:28:20.615 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 19:30:21.129 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 19:32:21.663 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 19:34:22.132 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 19:36:22.685 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 19:38:23.181 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 19:40:23.672 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 19:42:24.140 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 19:44:24.600 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 19:46:25.138 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 19:48:25.696 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 19:50:26.142 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 19:52:26.595 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 19:54:27.155 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 19:56:27.694 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 19:58:28.197 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 20:00:28.726 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 20:02:29.259 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 20:04:29.781 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 20:06:30.335 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 20:08:30.847 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 20:10:31.389 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 20:12:31.928 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 20:14:32.402 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 20:16:32.863 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 20:18:33.356 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 20:20:33.826 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 20:22:34.380 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 20:24:34.917 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 20:26:35.439 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 20:28:35.996 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 20:30:36.535 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 20:32:37.059 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 20:34:37.591 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 20:36:38.120 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 20:38:38.561 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 20:40:39.030 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 20:42:39.551 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 20:44:40.074 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 20:46:40.557 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 20:48:41.034 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 20:50:41.520 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 20:52:42.009 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 20:54:42.527 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 20:56:43.054 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 20:58:43.521 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 21:00:44.041 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 21:02:44.562 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 21:04:45.078 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 21:06:45.624 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 21:08:46.094 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 21:10:46.603 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 21:12:47.117 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 21:14:47.658 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-01-31 21:16:48.094 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: succeeded
2023-01-31 21:16:48.095 | DEBUG    | gptchem.tuner:tune:207 - Fine tuning completed. {'base_model': 'ada', 'batch_size': None, 'n_epochs': 8, 'learning_rate_multiplier': 0.02, 'run_name': None, 'wandb_sync': False, 'outdir': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_173337', 'train_filename': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_173337/train.jsonl', 'valid_filename': 'None', 'model_name': 'ada:ft-lsmoepfl-2023-01-31-20-14-49', 'ft_id': 'ft-7Fx28s63ncnIifvom162BBmb', 'date': '20230131_211648', 'train_file_id': 'file-EuVmnWkxrlAvqsZfrbyAFqvh', 'valid_file_id': None}
Uploaded file from /home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_173337/train.jsonl: file-EuVmnWkxrlAvqsZfrbyAFqvh
Ran train size 10 and got MAE 1.43792, GPR baseline 1.0124319576424698
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤═════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │   value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪═════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ 0       │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 0       │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │ 0.99998 │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧═════════╛
Upload progress:   0%|          | 0.00/18.6k [00:00<?, ?it/s]Upload progress: 100%|██████████| 18.6k/18.6k [00:00<00:00, 40.4Mit/s]
2023-01-31 21:16:54.395 | DEBUG    | gptchem.tuner:tune:188 - Requested fine tuning. {
  "created_at": 1675196214,
  "events": [
    {
      "created_at": 1675196214,
      "level": "info",
      "message": "Created fine-tune: ft-9yNjVIDzjl8O54rxQcuNMn2Y",
      "object": "fine-tune-event"
    }
  ],
  "fine_tuned_model": null,
  "hyperparams": {
    "batch_size": null,
    "learning_rate_multiplier": 0.02,
    "n_epochs": 8,
    "prompt_loss_weight": 0.01
  },
  "id": "ft-9yNjVIDzjl8O54rxQcuNMn2Y",
  "model": "ada",
  "object": "fine-tune",
  "organization_id": "org-TFRJXw3PPQocOWbu71eI2t9U",
  "result_files": [],
  "status": "pending",
  "training_files": [
    {
      "bytes": 18562,
      "created_at": 1675196214,
      "filename": "/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_211652/train.jsonl",
      "id": "file-t1Wdm16CZ4JyM6aZniJrEPuC",
      "object": "file",
      "purpose": "fine-tune",
      "status": "uploaded",
      "status_details": null
    }
  ],
  "updated_at": 1675196214,
  "validation_files": []
}
2023-01-31 21:16:54.560 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 21:18:55.082 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 21:20:55.620 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 21:22:56.116 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 21:24:56.613 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 21:26:57.144 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 21:28:57.647 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 21:30:58.099 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 21:32:58.600 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 21:34:59.141 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 21:36:59.640 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 21:39:00.129 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 21:41:00.654 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 21:43:01.183 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 21:45:01.720 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 21:47:02.249 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 21:49:02.812 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 21:51:03.335 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 21:53:03.865 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 21:55:04.384 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 21:57:04.925 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 21:59:05.473 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 22:01:06.001 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 22:03:06.440 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 22:05:06.969 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 22:07:07.477 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 22:09:07.938 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 22:11:08.443 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 22:13:08.929 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 22:15:09.476 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 22:17:09.999 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 22:19:10.424 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 22:21:10.935 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 22:23:11.407 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 22:25:11.865 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 22:27:12.395 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 22:29:12.938 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 22:31:13.454 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 22:33:13.956 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 22:35:14.459 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 22:37:14.968 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 22:39:15.458 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 22:41:16.016 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-01-31 22:43:16.507 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: succeeded
2023-01-31 22:43:16.508 | DEBUG    | gptchem.tuner:tune:207 - Fine tuning completed. {'base_model': 'ada', 'batch_size': None, 'n_epochs': 8, 'learning_rate_multiplier': 0.02, 'run_name': None, 'wandb_sync': False, 'outdir': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_211652', 'train_filename': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_211652/train.jsonl', 'valid_filename': 'None', 'model_name': 'ada:ft-lsmoepfl-2023-01-31-21-42-41', 'ft_id': 'ft-9yNjVIDzjl8O54rxQcuNMn2Y', 'date': '20230131_224316', 'train_file_id': 'file-t1Wdm16CZ4JyM6aZniJrEPuC', 'valid_file_id': None}
Uploaded file from /home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_211652/train.jsonl: file-t1Wdm16CZ4JyM6aZniJrEPuC
Ran train size 50 and got MAE 1.1592799999999996, GPR baseline 1.0207471837741522
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │  0.11486 │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 29.6061  │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.35857 │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛
Upload progress:   0%|          | 0.00/36.9k [00:00<?, ?it/s]Upload progress: 100%|██████████| 36.9k/36.9k [00:00<00:00, 49.1Mit/s]
2023-01-31 22:43:23.086 | DEBUG    | gptchem.tuner:tune:188 - Requested fine tuning. {
  "created_at": 1675201402,
  "events": [
    {
      "created_at": 1675201402,
      "level": "info",
      "message": "Created fine-tune: ft-ZiPXL5DcAZXaVYay5HwOY8Ub",
      "object": "fine-tune-event"
    }
  ],
  "fine_tuned_model": null,
  "hyperparams": {
    "batch_size": null,
    "learning_rate_multiplier": 0.02,
    "n_epochs": 8,
    "prompt_loss_weight": 0.01
  },
  "id": "ft-ZiPXL5DcAZXaVYay5HwOY8Ub",
  "model": "ada",
  "object": "fine-tune",
  "organization_id": "org-TFRJXw3PPQocOWbu71eI2t9U",
  "result_files": [],
  "status": "pending",
  "training_files": [
    {
      "bytes": 36872,
      "created_at": 1675201402,
      "filename": "/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_224321/train.jsonl",
      "id": "file-pS6fu29y4NZAYuqMGpY9SLkx",
      "object": "file",
      "purpose": "fine-tune",
      "status": "uploaded",
      "status_details": null
    }
  ],
  "updated_at": 1675201402,
  "validation_files": []
}
2023-01-31 22:43:23.250 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 22:45:23.783 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 22:47:24.290 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 22:49:24.821 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 22:51:25.377 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 22:53:25.881 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 22:55:26.409 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 22:57:26.905 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 22:59:27.404 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 23:01:27.921 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 23:03:28.366 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 23:05:28.871 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 23:07:29.424 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 23:09:29.968 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 23:11:30.524 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 23:13:31.050 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 23:15:31.608 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 23:17:32.176 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 23:19:32.724 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 23:21:33.261 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 23:23:33.816 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 23:25:34.348 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 23:27:34.888 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 23:29:35.411 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 23:31:35.907 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 23:33:36.380 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 23:35:36.871 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 23:37:37.378 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 23:39:37.891 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 23:41:38.363 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 23:43:38.873 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 23:45:39.410 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 23:47:39.973 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 23:49:40.497 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 23:51:40.957 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 23:53:41.458 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 23:55:41.973 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 23:57:42.524 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-01-31 23:59:42.979 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 00:01:43.421 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 00:03:43.943 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 00:05:44.491 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 00:07:45.030 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 00:09:45.617 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 00:11:46.154 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 00:13:46.689 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 00:15:47.246 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 00:17:47.743 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 00:19:48.193 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 00:21:48.727 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 00:23:49.270 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 00:25:49.713 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 00:27:50.186 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 00:29:50.698 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 00:31:51.134 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 00:33:51.659 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 00:35:52.188 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 00:37:52.669 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 00:39:53.194 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 00:41:53.625 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 00:43:54.178 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 00:45:54.651 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 00:47:55.143 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 00:49:55.651 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 00:51:56.174 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 00:53:56.684 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 00:55:57.186 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 00:57:57.692 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 00:59:58.188 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 01:01:58.698 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 01:03:59.152 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 01:05:59.639 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 01:08:00.170 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 01:10:00.700 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 01:12:01.186 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 01:14:01.680 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 01:16:02.148 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 01:18:02.684 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-02-01 01:20:03.184 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: succeeded
2023-02-01 01:20:03.184 | DEBUG    | gptchem.tuner:tune:207 - Fine tuning completed. {'base_model': 'ada', 'batch_size': None, 'n_epochs': 8, 'learning_rate_multiplier': 0.02, 'run_name': None, 'wandb_sync': False, 'outdir': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_224321', 'train_filename': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_224321/train.jsonl', 'valid_filename': 'None', 'model_name': 'ada:ft-lsmoepfl-2023-02-01-00-18-46', 'ft_id': 'ft-ZiPXL5DcAZXaVYay5HwOY8Ub', 'date': '20230201_012003', 'train_file_id': 'file-pS6fu29y4NZAYuqMGpY9SLkx', 'valid_file_id': None}
Uploaded file from /home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230131_224321/train.jsonl: file-pS6fu29y4NZAYuqMGpY9SLkx
Ran train size 100 and got MAE 1.1529200000000002, GPR baseline 0.7992783406423993
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │  0.20386 │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 51.0142  │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0       │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛
Upload progress:   0%|          | 0.00/72.5k [00:00<?, ?it/s]Upload progress: 100%|██████████| 72.5k/72.5k [00:00<00:00, 154Mit/s]
2023-02-01 01:20:10.570 | DEBUG    | gptchem.tuner:tune:188 - Requested fine tuning. {
  "created_at": 1675210810,
  "events": [
    {
      "created_at": 1675210810,
      "level": "info",
      "message": "Created fine-tune: ft-FLyiNQmkFnHzECaTaBlHfPOM",
      "object": "fine-tune-event"
    }
  ],
  "fine_tuned_model": null,
  "hyperparams": {
    "batch_size": null,
    "learning_rate_multiplier": 0.02,
    "n_epochs": 8,
    "prompt_loss_weight": 0.01
  },
  "id": "ft-FLyiNQmkFnHzECaTaBlHfPOM",
  "model": "ada",
  "object": "fine-tune",
  "organization_id": "org-TFRJXw3PPQocOWbu71eI2t9U",
  "result_files": [],
  "status": "pending",
  "training_files": [
    {
      "bytes": 72490,
      "created_at": 1675210810,
      "filename": "/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230201_012008/train.jsonl",
      "id": "file-PVZzDJh346AGoF7rQV9pdlFT",
      "object": "file",
      "purpose": "fine-tune",
      "status": "uploaded",
      "status_details": null
    }
  ],
  "updated_at": 1675210810,
  "validation_files": []
}
2023-02-01 01:20:10.735 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 01:22:11.195 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 01:24:11.757 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 01:26:12.235 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 01:28:12.749 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 01:30:13.207 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 01:32:13.704 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 01:34:14.211 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 01:36:14.753 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 01:38:15.197 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 01:40:15.640 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 01:42:16.135 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 01:44:16.608 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 01:46:17.129 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 01:48:17.589 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 01:50:18.033 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 01:52:18.551 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 01:54:19.068 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 01:56:19.597 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 01:58:20.128 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 02:00:20.569 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 02:02:21.026 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 02:04:21.567 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 02:06:22.128 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 02:08:22.599 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 02:10:23.151 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 02:12:23.653 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 02:14:24.157 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 02:16:24.668 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 02:18:33.644 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 02:20:34.188 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 02:22:34.722 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 02:24:35.268 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 02:26:35.771 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 02:28:36.258 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 02:30:36.778 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 02:32:37.303 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 02:34:37.803 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 02:36:38.301 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 02:38:38.823 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 02:40:39.355 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 02:42:39.873 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 02:44:40.398 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 02:46:40.882 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 02:48:41.330 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 02:50:41.852 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 02:52:42.374 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 02:54:42.913 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 02:56:43.436 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 02:58:43.888 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 03:00:44.339 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 03:02:44.893 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 03:04:45.388 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 03:06:45.929 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 03:08:46.424 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 03:10:46.949 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 03:12:47.497 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 03:14:47.986 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 03:16:48.486 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 03:18:48.984 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 03:20:49.513 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 03:22:49.969 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 03:24:50.518 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 03:26:51.059 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 03:28:51.587 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 03:30:52.094 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 03:32:52.615 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 03:34:53.135 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 03:36:53.645 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 03:38:54.131 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 03:40:54.654 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 03:42:55.139 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 03:44:55.652 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 03:46:56.091 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 03:48:56.564 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 03:50:57.085 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 03:52:57.609 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 03:54:58.125 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 03:56:58.656 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 03:58:59.185 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 04:00:59.708 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 04:03:00.250 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 04:05:00.738 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 04:07:01.223 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 04:09:01.719 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 04:11:02.266 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 04:13:02.809 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-02-01 04:15:03.308 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-02-01 04:17:03.856 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: succeeded
2023-02-01 04:17:03.856 | DEBUG    | gptchem.tuner:tune:207 - Fine tuning completed. {'base_model': 'ada', 'batch_size': None, 'n_epochs': 8, 'learning_rate_multiplier': 0.02, 'run_name': None, 'wandb_sync': False, 'outdir': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230201_012008', 'train_filename': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230201_012008/train.jsonl', 'valid_filename': 'None', 'model_name': 'ada:ft-lsmoepfl-2023-02-01-03-16-38', 'ft_id': 'ft-FLyiNQmkFnHzECaTaBlHfPOM', 'date': '20230201_041703', 'train_file_id': 'file-PVZzDJh346AGoF7rQV9pdlFT', 'valid_file_id': None}
Uploaded file from /home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230201_012008/train.jsonl: file-PVZzDJh346AGoF7rQV9pdlFT
Ran train size 200 and got MAE 1.0603600000000002, GPR baseline 0.6679462123395089
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ -1.4658  │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 50.0305  │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.04625 │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛
Upload progress:   0%|          | 0.00/185k [00:00<?, ?it/s]Upload progress: 100%|██████████| 185k/185k [00:00<00:00, 247Mit/s]
2023-02-01 04:17:12.658 | DEBUG    | gptchem.tuner:tune:188 - Requested fine tuning. {
  "created_at": 1675221432,
  "events": [
    {
      "created_at": 1675221432,
      "level": "info",
      "message": "Created fine-tune: ft-igHHb7dDWoJtAZtXb9VbqjV2",
      "object": "fine-tune-event"
    }
  ],
  "fine_tuned_model": null,
  "hyperparams": {
    "batch_size": null,
    "learning_rate_multiplier": 0.02,
    "n_epochs": 8,
    "prompt_loss_weight": 0.01
  },
  "id": "ft-igHHb7dDWoJtAZtXb9VbqjV2",
  "model": "ada",
  "object": "fine-tune",
  "organization_id": "org-TFRJXw3PPQocOWbu71eI2t9U",
  "result_files": [],
  "status": "pending",
  "training_files": [
    {
      "bytes": 184808,
      "created_at": 1675221432,
      "filename": "/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230201_041710/train.jsonl",
      "id": "file-n3NARavxkqCc3WRJMLeCCeKa",
      "object": "file",
      "purpose": "fine-tune",
      "status": "uploaded",
      "status_details": null
    }
  ],
  "updated_at": 1675221432,
  "validation_files": []
}
2023-02-01 04:17:12.833 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 04:19:13.284 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 04:21:13.827 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 04:23:14.363 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 04:25:14.874 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 04:27:15.349 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 04:29:15.874 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 04:31:16.417 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 04:33:16.939 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 04:35:17.468 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 04:37:17.979 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 04:39:18.461 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 04:41:19.010 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 04:43:19.566 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 04:45:20.107 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 04:47:20.580 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 04:49:21.119 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 04:51:21.560 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 04:53:22.040 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 04:55:22.549 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 04:57:22.980 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 04:59:23.488 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 05:01:24.029 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 05:03:24.481 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 05:05:25.014 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 05:07:25.569 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 05:09:26.077 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 05:11:26.615 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 05:13:27.170 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 05:15:27.702 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 05:17:28.226 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 05:19:28.756 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 05:21:29.281 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 05:23:29.768 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 05:25:30.333 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 05:27:30.853 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 05:29:31.377 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 05:31:31.928 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 05:33:32.458 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 05:35:32.980 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 05:37:33.516 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 05:39:34.027 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 05:41:34.543 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 05:43:35.030 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 05:45:35.478 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 05:47:35.968 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 05:49:36.452 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 05:51:36.974 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 05:53:37.503 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 05:55:38.050 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 05:57:38.583 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 05:59:39.096 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 06:01:39.624 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 06:03:40.162 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 06:05:40.705 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 06:07:41.235 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 06:09:41.732 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 06:11:42.291 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 06:13:42.739 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 06:15:43.189 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-02-01 06:17:43.630 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-02-01 06:19:44.157 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-02-01 06:21:44.689 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-02-01 06:23:45.202 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-02-01 06:25:45.730 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: succeeded
2023-02-01 06:25:45.731 | DEBUG    | gptchem.tuner:tune:207 - Fine tuning completed. {'base_model': 'ada', 'batch_size': None, 'n_epochs': 8, 'learning_rate_multiplier': 0.02, 'run_name': None, 'wandb_sync': False, 'outdir': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230201_041710', 'train_filename': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230201_041710/train.jsonl', 'valid_filename': 'None', 'model_name': 'ada:ft-lsmoepfl-2023-02-01-05-24-26', 'ft_id': 'ft-igHHb7dDWoJtAZtXb9VbqjV2', 'date': '20230201_062545', 'train_file_id': 'file-n3NARavxkqCc3WRJMLeCCeKa', 'valid_file_id': None}
Uploaded file from /home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230201_041710/train.jsonl: file-n3NARavxkqCc3WRJMLeCCeKa
Ran train size 500 and got MAE 1.04104, GPR baseline 0.6248221601360314
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤═════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │   value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪═════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │      -0 │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │       0 │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │       1 │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧═════════╛
Upload progress:   0%|          | 0.00/5.01k [00:00<?, ?it/s]Upload progress: 100%|██████████| 5.01k/5.01k [00:00<00:00, 9.28Mit/s]
2023-02-01 06:25:52.212 | DEBUG    | gptchem.tuner:tune:188 - Requested fine tuning. {
  "created_at": 1675229152,
  "events": [
    {
      "created_at": 1675229152,
      "level": "info",
      "message": "Created fine-tune: ft-fOWHnWw2OzXfqzf0WXhCL6Yu",
      "object": "fine-tune-event"
    }
  ],
  "fine_tuned_model": null,
  "hyperparams": {
    "batch_size": null,
    "learning_rate_multiplier": 0.02,
    "n_epochs": 8,
    "prompt_loss_weight": 0.01
  },
  "id": "ft-fOWHnWw2OzXfqzf0WXhCL6Yu",
  "model": "ada",
  "object": "fine-tune",
  "organization_id": "org-TFRJXw3PPQocOWbu71eI2t9U",
  "result_files": [],
  "status": "pending",
  "training_files": [
    {
      "bytes": 5014,
      "created_at": 1675229151,
      "filename": "/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230201_062550/train.jsonl",
      "id": "file-NFo6PHMErKsFY7kfV7M7RiML",
      "object": "file",
      "purpose": "fine-tune",
      "status": "uploaded",
      "status_details": null
    }
  ],
  "updated_at": 1675229152,
  "validation_files": []
}
2023-02-01 06:25:52.388 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 06:27:52.910 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 06:29:53.453 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 06:31:53.960 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 06:33:54.512 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 06:35:55.089 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 06:37:55.637 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 06:39:56.179 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 06:41:56.740 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 06:43:57.174 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 06:45:57.634 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 06:47:58.165 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 06:49:58.701 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 06:51:59.212 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 06:53:59.711 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 06:56:00.199 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 06:58:00.746 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 07:00:01.261 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 07:02:01.759 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 07:04:02.224 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 07:06:02.742 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 07:08:03.246 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 07:10:03.803 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 07:12:04.394 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 07:14:04.909 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 07:16:05.421 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 07:18:05.959 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 07:20:06.495 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 07:22:07.009 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 07:24:07.486 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 07:26:08.024 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 07:28:08.501 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 07:30:09.005 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 07:32:09.546 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 07:34:09.985 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 07:36:10.489 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 07:38:11.068 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 07:40:11.648 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 07:42:12.202 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 07:44:12.741 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 07:46:13.285 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 07:48:13.795 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 07:50:14.320 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 07:52:14.867 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 07:54:15.394 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: succeeded
2023-02-01 07:54:15.394 | DEBUG    | gptchem.tuner:tune:207 - Fine tuning completed. {'base_model': 'ada', 'batch_size': None, 'n_epochs': 8, 'learning_rate_multiplier': 0.02, 'run_name': None, 'wandb_sync': False, 'outdir': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230201_062550', 'train_filename': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230201_062550/train.jsonl', 'valid_filename': 'None', 'model_name': 'ada:ft-lsmoepfl-2023-02-01-06-53-47', 'ft_id': 'ft-fOWHnWw2OzXfqzf0WXhCL6Yu', 'date': '20230201_075415', 'train_file_id': 'file-NFo6PHMErKsFY7kfV7M7RiML', 'valid_file_id': None}
Uploaded file from /home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230201_062550/train.jsonl: file-NFo6PHMErKsFY7kfV7M7RiML
Ran train size 10 and got MAE 1.1288000000000002, GPR baseline 1.0124319576424698
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤═════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │   value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪═════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │ 0       │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 0       │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │ 0.99998 │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧═════════╛
Upload progress:   0%|          | 0.00/25.0k [00:00<?, ?it/s]Upload progress: 100%|██████████| 25.0k/25.0k [00:00<00:00, 60.2Mit/s]
2023-02-01 07:54:22.356 | DEBUG    | gptchem.tuner:tune:188 - Requested fine tuning. {
  "created_at": 1675234462,
  "events": [
    {
      "created_at": 1675234462,
      "level": "info",
      "message": "Created fine-tune: ft-lVqZcDVpZVFzBMOwQ6lbDKgY",
      "object": "fine-tune-event"
    }
  ],
  "fine_tuned_model": null,
  "hyperparams": {
    "batch_size": null,
    "learning_rate_multiplier": 0.02,
    "n_epochs": 8,
    "prompt_loss_weight": 0.01
  },
  "id": "ft-lVqZcDVpZVFzBMOwQ6lbDKgY",
  "model": "ada",
  "object": "fine-tune",
  "organization_id": "org-TFRJXw3PPQocOWbu71eI2t9U",
  "result_files": [],
  "status": "pending",
  "training_files": [
    {
      "bytes": 25034,
      "created_at": 1675234462,
      "filename": "/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230201_075420/train.jsonl",
      "id": "file-CelxIeDWyOP5iDYitrRDGgC7",
      "object": "file",
      "purpose": "fine-tune",
      "status": "uploaded",
      "status_details": null
    }
  ],
  "updated_at": 1675234462,
  "validation_files": []
}
2023-02-01 07:54:22.523 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 07:56:23.079 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 07:58:23.578 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 08:00:24.101 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 08:02:24.592 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 08:04:25.090 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 08:06:25.582 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 08:08:26.080 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 08:10:26.592 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 08:12:27.128 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 08:14:27.665 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 08:16:28.192 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 08:18:28.680 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 08:20:29.119 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 08:22:29.626 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 08:24:30.164 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 08:26:30.686 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 08:28:31.193 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 08:30:31.617 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 08:32:32.143 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 08:34:32.690 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 08:36:33.213 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 08:38:33.733 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 08:40:34.266 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 08:42:34.807 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 08:44:35.342 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 08:46:35.868 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 08:48:36.397 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 08:50:36.844 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 08:52:37.289 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 08:54:37.787 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 08:56:38.327 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 08:58:38.764 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 09:00:39.255 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 09:02:39.773 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 09:04:40.298 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 09:06:40.839 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 09:08:41.366 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 09:10:41.908 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 09:12:42.379 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 09:14:42.843 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 09:16:43.346 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 09:18:43.887 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 09:20:44.383 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 09:22:44.809 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 09:24:45.322 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 09:26:45.822 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 09:28:46.274 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 09:30:46.732 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 09:32:47.195 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 09:34:47.739 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 09:36:48.254 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 09:38:48.758 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 09:40:49.241 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 09:42:49.737 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 09:44:50.261 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 09:46:50.728 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 09:48:51.269 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 09:50:51.782 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 09:52:52.296 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 09:54:52.800 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 09:56:53.327 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 09:58:53.832 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 10:00:54.339 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 10:02:54.866 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 10:04:55.381 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 10:06:55.830 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 10:08:56.311 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 10:10:56.810 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 10:12:57.358 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 10:14:57.803 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 10:16:58.349 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 10:18:58.905 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 10:20:59.452 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 10:22:59.993 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 10:25:00.457 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 10:27:00.992 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 10:29:01.590 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 10:31:02.191 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 10:33:02.700 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 10:35:03.211 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 10:37:03.642 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 10:39:04.089 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 10:41:04.602 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 10:43:05.132 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 10:45:05.603 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 10:47:06.156 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 10:49:06.683 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 10:51:07.202 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 10:53:07.729 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 10:55:08.182 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 10:57:08.702 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 10:59:09.232 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 11:01:09.669 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 11:03:10.123 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 11:05:10.640 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 11:07:11.163 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 11:09:11.622 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 11:11:12.168 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 11:13:12.695 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 11:15:13.143 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 11:17:13.665 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 11:19:14.191 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 11:21:14.747 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 11:23:15.287 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 11:25:15.737 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 11:27:16.281 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 11:31:47.375 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 11:33:47.921 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 11:35:48.449 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 11:37:48.980 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 11:39:49.508 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 11:41:50.053 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 11:43:50.598 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 11:45:51.138 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 11:47:51.664 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 11:49:52.164 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 11:51:52.666 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 11:53:53.187 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 11:55:53.728 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 11:57:54.244 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 11:59:54.776 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 12:01:55.313 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 12:03:55.854 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 12:05:56.392 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 12:07:56.923 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 12:09:57.466 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 12:11:58.000 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 12:13:58.526 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 12:15:58.980 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 12:17:59.514 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 12:20:00.007 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 12:22:00.546 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 12:24:01.050 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 12:26:01.616 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 12:28:02.143 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 12:30:02.660 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-02-01 12:32:03.227 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: succeeded
2023-02-01 12:32:03.227 | DEBUG    | gptchem.tuner:tune:207 - Fine tuning completed. {'base_model': 'ada', 'batch_size': None, 'n_epochs': 8, 'learning_rate_multiplier': 0.02, 'run_name': None, 'wandb_sync': False, 'outdir': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230201_075420', 'train_filename': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230201_075420/train.jsonl', 'valid_filename': 'None', 'model_name': 'ada:ft-lsmoepfl-2023-02-01-11-30-19', 'ft_id': 'ft-lVqZcDVpZVFzBMOwQ6lbDKgY', 'date': '20230201_123203', 'train_file_id': 'file-CelxIeDWyOP5iDYitrRDGgC7', 'valid_file_id': None}
Uploaded file from /home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230201_075420/train.jsonl: file-CelxIeDWyOP5iDYitrRDGgC7
Ran train size 50 and got MAE 1.07904, GPR baseline 1.0207471837741522
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │  0.11486 │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 29.6061  │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0.35857 │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛
Upload progress:   0%|          | 0.00/49.7k [00:00<?, ?it/s]Upload progress: 100%|██████████| 49.7k/49.7k [00:00<00:00, 86.5Mit/s]
2023-02-01 12:32:09.611 | DEBUG    | gptchem.tuner:tune:188 - Requested fine tuning. {
  "created_at": 1675251129,
  "events": [
    {
      "created_at": 1675251129,
      "level": "info",
      "message": "Created fine-tune: ft-34Gpl5Si9uUxRJVuIDYKC6HN",
      "object": "fine-tune-event"
    }
  ],
  "fine_tuned_model": null,
  "hyperparams": {
    "batch_size": null,
    "learning_rate_multiplier": 0.02,
    "n_epochs": 8,
    "prompt_loss_weight": 0.01
  },
  "id": "ft-34Gpl5Si9uUxRJVuIDYKC6HN",
  "model": "ada",
  "object": "fine-tune",
  "organization_id": "org-TFRJXw3PPQocOWbu71eI2t9U",
  "result_files": [],
  "status": "pending",
  "training_files": [
    {
      "bytes": 49730,
      "created_at": 1675251129,
      "filename": "/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230201_123208/train.jsonl",
      "id": "file-llTqamqA19ramiDms5kWLgD8",
      "object": "file",
      "purpose": "fine-tune",
      "status": "uploaded",
      "status_details": null
    }
  ],
  "updated_at": 1675251129,
  "validation_files": []
}
2023-02-01 12:32:09.839 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 12:34:10.363 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 12:36:10.929 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 12:38:11.415 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 12:40:11.966 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 12:42:12.508 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 12:44:13.027 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 12:46:13.547 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 12:48:14.074 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 12:50:14.602 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 12:52:15.150 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 12:54:15.676 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 12:56:16.218 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 12:58:16.715 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 13:00:17.221 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 13:02:17.743 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 13:04:18.206 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 13:06:18.758 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 13:08:19.201 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 13:10:19.746 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 13:12:20.273 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 13:14:20.807 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 13:16:21.308 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 13:18:21.828 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 13:20:22.369 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 13:22:22.859 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 13:24:23.395 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 13:26:23.912 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 13:28:24.412 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 13:30:24.938 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 13:32:25.442 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 13:34:25.969 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 13:36:26.421 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 13:38:26.945 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 13:40:27.427 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 13:42:27.938 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 13:44:28.456 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 13:46:28.982 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 13:48:29.515 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 13:50:30.055 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 13:52:30.538 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 13:54:31.045 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 13:56:31.574 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 13:58:32.121 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 14:00:32.646 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 14:02:33.183 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 14:04:33.677 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 14:06:34.197 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 14:08:34.689 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 14:10:35.229 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 14:12:35.711 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 14:14:36.154 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 14:16:36.689 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 14:18:37.157 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 14:20:37.682 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: running
2023-02-01 14:22:38.228 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: succeeded
2023-02-01 14:22:38.228 | DEBUG    | gptchem.tuner:tune:207 - Fine tuning completed. {'base_model': 'ada', 'batch_size': None, 'n_epochs': 8, 'learning_rate_multiplier': 0.02, 'run_name': None, 'wandb_sync': False, 'outdir': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230201_123208', 'train_filename': '/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230201_123208/train.jsonl', 'valid_filename': 'None', 'model_name': 'ada:ft-lsmoepfl-2023-02-01-13-21-49', 'ft_id': 'ft-34Gpl5Si9uUxRJVuIDYKC6HN', 'date': '20230201_142238', 'train_file_id': 'file-llTqamqA19ramiDms5kWLgD8', 'valid_file_id': None}
Uploaded file from /home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230201_123208/train.jsonl: file-llTqamqA19ramiDms5kWLgD8
Ran train size 100 and got MAE 1.04892, GPR baseline 0.7992783406423993
╒═════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤══════════╕
│ name                    │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │    value │
╞═════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪══════════╡
│ GPR.mean_function.c     │ Parameter │ Identity         │         │ True        │ ()      │ float64 │  0.20386 │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │ 51.0142  │
├─────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼──────────┤
│ GPR.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │  0       │
╘═════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧══════════╛
Upload progress:   0%|          | 0.00/97.6k [00:00<?, ?it/s]Upload progress: 100%|██████████| 97.6k/97.6k [00:00<00:00, 173Mit/s]
2023-02-01 14:22:46.071 | DEBUG    | gptchem.tuner:tune:188 - Requested fine tuning. {
  "created_at": 1675257765,
  "events": [
    {
      "created_at": 1675257765,
      "level": "info",
      "message": "Created fine-tune: ft-YZwpIu3ra5I9LscvVSOy7rDo",
      "object": "fine-tune-event"
    }
  ],
  "fine_tuned_model": null,
  "hyperparams": {
    "batch_size": null,
    "learning_rate_multiplier": 0.02,
    "n_epochs": 8,
    "prompt_loss_weight": 0.01
  },
  "id": "ft-YZwpIu3ra5I9LscvVSOy7rDo",
  "model": "ada",
  "object": "fine-tune",
  "organization_id": "org-TFRJXw3PPQocOWbu71eI2t9U",
  "result_files": [],
  "status": "pending",
  "training_files": [
    {
      "bytes": 97642,
      "created_at": 1675257765,
      "filename": "/home/kevin/Documents/gptchem/experiments/04_regression/lipophilicity/out/20230201_142244/train.jsonl",
      "id": "file-KaaDoEeHSW3d3DnjgGX6upmL",
      "object": "file",
      "purpose": "fine-tune",
      "status": "uploaded",
      "status_details": null
    }
  ],
  "updated_at": 1675257765,
  "validation_files": []
}
2023-02-01 14:22:46.240 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 14:24:46.709 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 14:26:47.261 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 14:28:47.756 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 14:30:48.296 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 14:32:48.828 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 14:34:49.348 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 14:36:49.825 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 14:38:50.356 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 14:40:50.886 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 14:42:51.432 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 14:44:51.981 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 14:46:52.515 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 14:48:53.050 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 14:50:53.639 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 14:52:54.094 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 14:54:54.603 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 14:56:55.132 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 14:58:55.673 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 15:00:56.174 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 15:02:56.694 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 15:04:57.200 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 15:06:57.732 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 15:08:58.259 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 15:10:58.835 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 15:12:59.362 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 15:14:59.896 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 15:17:00.406 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 15:19:00.929 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 15:21:01.431 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 15:23:01.975 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 15:25:02.483 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 15:27:03.015 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 15:29:03.452 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 15:31:03.930 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 15:33:04.435 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 15:35:04.928 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 15:37:05.455 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 15:39:05.998 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 15:41:06.534 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 15:43:07.026 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 15:45:07.518 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 15:47:08.030 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 15:49:08.528 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 15:51:09.055 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 15:53:09.608 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 15:55:10.113 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 15:57:10.623 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 15:59:11.164 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 16:01:11.659 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 16:03:12.188 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 16:05:12.718 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 16:07:13.221 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 16:09:13.750 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 16:11:14.255 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 16:13:14.778 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 16:15:15.211 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 16:17:15.674 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 16:19:16.211 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 16:21:16.705 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 16:23:17.174 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 16:25:18.364 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 16:27:18.804 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 16:29:19.345 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 16:31:19.873 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 16:33:20.309 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 16:35:23.515 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 16:37:23.987 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 16:39:24.409 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 16:41:24.968 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 16:43:25.431 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 16:45:25.989 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 16:47:26.461 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 16:49:26.997 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 16:51:27.450 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 16:53:27.988 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 16:55:31.063 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 16:57:31.594 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 16:59:32.080 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 17:01:32.621 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 17:03:33.111 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 17:05:39.293 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 17:07:39.827 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 17:09:40.360 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 17:11:40.868 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 17:13:41.390 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 17:15:41.878 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 17:17:42.404 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 17:19:42.843 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 17:21:43.412 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 17:23:43.946 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 17:25:44.442 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 17:27:44.925 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 17:29:45.432 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 17:31:45.971 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 17:33:46.537 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 17:35:47.476 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 17:37:48.022 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 17:39:48.541 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 17:41:49.044 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 17:43:49.581 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 17:46:10.168 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 17:48:10.641 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 17:50:11.198 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 17:52:11.734 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 17:54:12.241 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 17:56:12.766 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 17:58:13.221 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
2023-02-01 18:00:13.764 | DEBUG    | gptchem.tuner:get_ft_model_name:29 - Fine tuning status: pending
